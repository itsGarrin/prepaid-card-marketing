{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Paid Card Marketing",
   "id": "d23dfd07df5dd1ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "32f19a1ea749c7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:32.432851Z",
     "start_time": "2024-11-07T04:39:32.418348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "87737fadcfa28cc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:47:07.718157Z",
     "start_time": "2024-11-08T19:47:07.597515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import utils"
   ],
   "id": "ef6cd793ecbb6e2",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:34.413382Z",
     "start_time": "2024-11-07T04:39:34.280887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/Financial Wellness Data.csv')\n",
    "df"
   ],
   "id": "792a4852451d1550",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      PUF_ID  sample  fpl  SWB_1  SWB_2  SWB_3  FWBscore  FWB1_1  FWB1_2  \\\n",
       "0      10350       2    3      5      5      6        55       3       3   \n",
       "1       7740       1    3      6      6      6        51       2       2   \n",
       "2      13699       1    3      4      3      4        49       3       3   \n",
       "3       7267       1    3      6      6      6        49       3       3   \n",
       "4       7375       1    3      4      4      4        49       3       3   \n",
       "...      ...     ...  ...    ...    ...    ...       ...     ...     ...   \n",
       "6389   11220       3    3      6      7      7        61       3       3   \n",
       "6390   13118       3    2      7      7      7        59       3       4   \n",
       "6391    8709       1    3      5      6      6        59       3       4   \n",
       "6392    8515       1    3      5      5      5        46       2       2   \n",
       "6393    8516       3    2      4      6      4        49       3       3   \n",
       "\n",
       "      FWB1_3  ...  PPMSACAT  PPREG4  PPREG9  PPT01  PPT25  PPT612  PPT1317  \\\n",
       "0          3  ...         1       4       8      0      0       0        0   \n",
       "1          3  ...         1       2       3      0      0       0        0   \n",
       "2          3  ...         1       4       9      0      0       0        1   \n",
       "3          3  ...         1       3       7      0      0       0        0   \n",
       "4          3  ...         1       2       4      0      0       1        0   \n",
       "...      ...  ...       ...     ...     ...    ...    ...     ...      ...   \n",
       "6389       1  ...         1       2       3      0      0       0        1   \n",
       "6390       2  ...         1       3       6      0      0       0        0   \n",
       "6391       3  ...         1       1       2      0      0       0        0   \n",
       "6392       3  ...         1       4       9      0      0       0        0   \n",
       "6393       3  ...         0       3       5      0      0       1        0   \n",
       "\n",
       "      PPT18OV  PCTLT200FPL   finalwt  \n",
       "0           1            0  0.367292  \n",
       "1           2            0  1.327561  \n",
       "2           2            1  0.835156  \n",
       "3           1            0  1.410871  \n",
       "4           4            1  4.260668  \n",
       "...       ...          ...       ...  \n",
       "6389        2           -5  0.522504  \n",
       "6390        3           -5  1.015219  \n",
       "6391        2            0  1.136270  \n",
       "6392        2            0  1.224941  \n",
       "6393        2           -5  0.626489  \n",
       "\n",
       "[6394 rows x 217 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUF_ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "      <th>finalwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10350</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7740</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.327561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13699</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7267</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.410871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7375</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.260668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>11220</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.522504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>13118</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.015219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>8709</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>8515</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.224941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>8516</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.626489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 217 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:34.570044Z",
     "start_time": "2024-11-07T04:39:34.524450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find duplicates\n",
    "df[df.duplicated()]"
   ],
   "id": "da3dd49842efe2bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PUF_ID, sample, fpl, SWB_1, SWB_2, SWB_3, FWBscore, FWB1_1, FWB1_2, FWB1_3, FWB1_4, FWB1_5, FWB1_6, FWB2_1, FWB2_2, FWB2_3, FWB2_4, FSscore, FS1_1, FS1_2, FS1_3, FS1_4, FS1_5, FS1_6, FS1_7, FS2_1, FS2_2, FS2_3, SUBKNOWL1, ACT1_1, ACT1_2, FINGOALS, PROPPLAN_1, PROPPLAN_2, PROPPLAN_3, PROPPLAN_4, MANAGE1_1, MANAGE1_2, MANAGE1_3, MANAGE1_4, SAVEHABIT, FRUGALITY, AUTOMATED_1, AUTOMATED_2, ASK1_1, ASK1_2, SUBNUMERACY2, SUBNUMERACY1, CHANGEABLE, GOALCONF, LMscore, FINKNOWL1, FINKNOWL2, FINKNOWL3, FK1correct, FK2correct, FK3correct, KHscore, KHKNOWL1, KHKNOWL2, KHKNOWL3, KHKNOWL4, KHKNOWL5, KHKNOWL6, KHKNOWL7, KHKNOWL8, KHKNOWL9, KH1correct, KH2correct, KH3correct, KH4correct, KH5correct, KH6correct, KH7correct, KH8correct, KH9correct, ENDSMEET, HOUSING, LIVINGARRANGEMENT, HOUSERANGES, IMPUTATION_FLAG, VALUERANGES, MORTGAGE, SAVINGSRANGES, PRODHAVE_1, PRODHAVE_2, PRODHAVE_3, PRODHAVE_4, PRODHAVE_5, PRODHAVE_6, PRODHAVE_7, PRODHAVE_8, PRODHAVE_9, PRODUSE_1, PRODUSE_2, PRODUSE_3, PRODUSE_4, PRODUSE_5, PRODUSE_6, CONSPROTECT1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 217 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUF_ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "      <th>finalwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 217 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:34.670914Z",
     "start_time": "2024-11-07T04:39:34.641227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ],
   "id": "944df5ac1501abbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUF_ID         0\n",
       "sample         0\n",
       "fpl            0\n",
       "SWB_1          0\n",
       "SWB_2          0\n",
       "              ..\n",
       "PPT612         0\n",
       "PPT1317        0\n",
       "PPT18OV        0\n",
       "PCTLT200FPL    0\n",
       "finalwt        0\n",
       "Length: 217, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:34.773828Z",
     "start_time": "2024-11-07T04:39:34.757213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check the data types\n",
    "df.dtypes"
   ],
   "id": "f576bea7448521ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUF_ID           int64\n",
       "sample           int64\n",
       "fpl              int64\n",
       "SWB_1            int64\n",
       "SWB_2            int64\n",
       "                ...   \n",
       "PPT612           int64\n",
       "PPT1317          int64\n",
       "PPT18OV          int64\n",
       "PCTLT200FPL      int64\n",
       "finalwt        float64\n",
       "Length: 217, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:34.965957Z",
     "start_time": "2024-11-07T04:39:34.944704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check if any features have zero variance\n",
    "df.var() == 0"
   ],
   "id": "d25ec616fcb4e729",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUF_ID         False\n",
       "sample         False\n",
       "fpl            False\n",
       "SWB_1          False\n",
       "SWB_2          False\n",
       "               ...  \n",
       "PPT612         False\n",
       "PPT1317        False\n",
       "PPT18OV        False\n",
       "PCTLT200FPL    False\n",
       "finalwt        False\n",
       "Length: 217, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exploratory Data Analysis",
   "id": "a9224405e60a98a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:35.283978Z",
     "start_time": "2024-11-07T04:39:35.166196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Describe the data\n",
    "df.describe()"
   ],
   "id": "3463184112032bba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             PUF_ID       sample          fpl        SWB_1        SWB_2  \\\n",
       "count   6394.000000  6394.000000  6394.000000  6394.000000  6394.000000   \n",
       "mean   10892.392712     1.279794     2.658899     5.353769     5.362215   \n",
       "std     1967.854493     0.570187     0.656944     1.500913     1.544942   \n",
       "min     7123.000000     1.000000     1.000000    -4.000000    -4.000000   \n",
       "25%     9235.250000     1.000000     3.000000     5.000000     5.000000   \n",
       "50%    10901.500000     1.000000     3.000000     6.000000     6.000000   \n",
       "75%    12570.750000     1.000000     3.000000     6.000000     7.000000   \n",
       "max    14400.000000     3.000000     3.000000     7.000000     7.000000   \n",
       "\n",
       "             SWB_3     FWBscore       FWB1_1       FWB1_2       FWB1_3  ...  \\\n",
       "count  6394.000000  6394.000000  6394.000000  6394.000000  6394.000000  ...   \n",
       "mean      5.432280    56.034094     3.048014     3.191899     2.531279  ...   \n",
       "std       1.613876    14.154676     1.235221     1.114130     1.196235  ...   \n",
       "min      -4.000000    -4.000000    -4.000000    -4.000000    -4.000000  ...   \n",
       "25%       5.000000    48.000000     2.000000     3.000000     2.000000  ...   \n",
       "50%       6.000000    56.000000     3.000000     3.000000     2.000000  ...   \n",
       "75%       7.000000    65.000000     4.000000     4.000000     3.000000  ...   \n",
       "max       7.000000    95.000000     5.000000     5.000000     5.000000  ...   \n",
       "\n",
       "          PPMSACAT       PPREG4       PPREG9        PPT01        PPT25  \\\n",
       "count  6394.000000  6394.000000  6394.000000  6394.000000  6394.000000   \n",
       "mean      0.866124     2.644823     5.145605     0.035815     0.078511   \n",
       "std       0.340545     1.032583     2.529397     0.185843     0.268995   \n",
       "min       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "25%       1.000000     2.000000     3.000000     0.000000     0.000000   \n",
       "50%       1.000000     3.000000     5.000000     0.000000     0.000000   \n",
       "75%       1.000000     3.000000     7.000000     0.000000     0.000000   \n",
       "max       1.000000     4.000000     9.000000     1.000000     1.000000   \n",
       "\n",
       "            PPT612      PPT1317      PPT18OV  PCTLT200FPL      finalwt  \n",
       "count  6394.000000  6394.000000  6394.000000  6394.000000  6394.000000  \n",
       "mean      0.129653     0.122928     2.084298    -0.081952     1.000000  \n",
       "std       0.335947     0.328380     0.814345     1.328498     0.585406  \n",
       "min       0.000000     0.000000     1.000000    -5.000000     0.165567  \n",
       "25%       0.000000     0.000000     2.000000     0.000000     0.600582  \n",
       "50%       0.000000     0.000000     2.000000     0.000000     0.845213  \n",
       "75%       0.000000     0.000000     2.000000     0.000000     1.251415  \n",
       "max       1.000000     1.000000     4.000000     1.000000     6.638674  \n",
       "\n",
       "[8 rows x 217 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUF_ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "      <th>finalwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10892.392712</td>\n",
       "      <td>1.279794</td>\n",
       "      <td>2.658899</td>\n",
       "      <td>5.353769</td>\n",
       "      <td>5.362215</td>\n",
       "      <td>5.432280</td>\n",
       "      <td>56.034094</td>\n",
       "      <td>3.048014</td>\n",
       "      <td>3.191899</td>\n",
       "      <td>2.531279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866124</td>\n",
       "      <td>2.644823</td>\n",
       "      <td>5.145605</td>\n",
       "      <td>0.035815</td>\n",
       "      <td>0.078511</td>\n",
       "      <td>0.129653</td>\n",
       "      <td>0.122928</td>\n",
       "      <td>2.084298</td>\n",
       "      <td>-0.081952</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1967.854493</td>\n",
       "      <td>0.570187</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>1.500913</td>\n",
       "      <td>1.544942</td>\n",
       "      <td>1.613876</td>\n",
       "      <td>14.154676</td>\n",
       "      <td>1.235221</td>\n",
       "      <td>1.114130</td>\n",
       "      <td>1.196235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340545</td>\n",
       "      <td>1.032583</td>\n",
       "      <td>2.529397</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>0.268995</td>\n",
       "      <td>0.335947</td>\n",
       "      <td>0.328380</td>\n",
       "      <td>0.814345</td>\n",
       "      <td>1.328498</td>\n",
       "      <td>0.585406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.165567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9235.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10901.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12570.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.251415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.638674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 217 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Engineering",
   "id": "f45b820753314972"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:35.428544Z",
     "start_time": "2024-11-07T04:39:35.399446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into features and target\n",
    "X = df.drop(columns=['PUF_ID', 'PRODUSE_3'])\n",
    "y = df['PRODUSE_3']"
   ],
   "id": "a85c2174fba61a0e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:55:28.274603Z",
     "start_time": "2024-11-08T18:55:28.129006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the distribution of the target variable\n",
    "y.value_counts().plot(kind='bar')"
   ],
   "id": "5985d666b7fa9fce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='PRODUSE_3'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dummify the categorical variables",
   "id": "991fb3c9b83c3b1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:35.763750Z",
     "start_time": "2024-11-07T04:39:35.518991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dummify any integer columns\n",
    "integer_variables = X.select_dtypes(include=['int64']).columns\n",
    "df_categorical = X[integer_variables].astype('object')\n",
    "df_numeric = X.drop(columns=integer_variables)\n",
    "\n",
    "# dummify the categorical variables\n",
    "df_dummies = pd.get_dummies(df_categorical, drop_first=True)\n",
    "X = pd.concat([df_numeric, df_dummies], axis=1)\n",
    "X"
   ],
   "id": "5750372aa00eb141",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      KHscore   finalwt  sample_2  sample_3  fpl_2  fpl_3  SWB_1_-1  SWB_1_1  \\\n",
       "0       1.267  0.367292      True     False  False   True     False    False   \n",
       "1      -0.570  1.327561     False     False  False   True     False    False   \n",
       "2      -0.188  0.835156     False     False  False   True     False    False   \n",
       "3      -1.485  1.410871     False     False  False   True     False    False   \n",
       "4      -1.900  4.260668     False     False  False   True     False    False   \n",
       "...       ...       ...       ...       ...    ...    ...       ...      ...   \n",
       "6389    1.267  0.522504     False      True  False   True     False    False   \n",
       "6390   -1.215  1.015219     False      True   True  False     False    False   \n",
       "6391   -1.215  1.136270     False     False  False   True     False    False   \n",
       "6392   -1.215  1.224941     False     False  False   True     False    False   \n",
       "6393   -1.215  0.626489     False      True   True  False     False    False   \n",
       "\n",
       "      SWB_1_2  SWB_1_3  ...  PPREG9_9  PPT01_1  PPT25_1  PPT612_1  PPT1317_1  \\\n",
       "0       False    False  ...     False    False    False     False      False   \n",
       "1       False    False  ...     False    False    False     False      False   \n",
       "2       False    False  ...      True    False    False     False       True   \n",
       "3       False    False  ...     False    False    False     False      False   \n",
       "4       False    False  ...     False    False    False      True      False   \n",
       "...       ...      ...  ...       ...      ...      ...       ...        ...   \n",
       "6389    False    False  ...     False    False    False     False       True   \n",
       "6390    False    False  ...     False    False    False     False      False   \n",
       "6391    False    False  ...     False    False    False     False      False   \n",
       "6392    False    False  ...      True    False    False     False      False   \n",
       "6393    False    False  ...     False    False    False      True      False   \n",
       "\n",
       "      PPT18OV_2  PPT18OV_3  PPT18OV_4  PCTLT200FPL_0  PCTLT200FPL_1  \n",
       "0         False      False      False           True          False  \n",
       "1          True      False      False           True          False  \n",
       "2          True      False      False          False           True  \n",
       "3         False      False      False           True          False  \n",
       "4         False      False       True          False           True  \n",
       "...         ...        ...        ...            ...            ...  \n",
       "6389       True      False      False          False          False  \n",
       "6390      False       True      False          False          False  \n",
       "6391       True      False      False           True          False  \n",
       "6392       True      False      False           True          False  \n",
       "6393       True      False      False          False          False  \n",
       "\n",
       "[6394 rows x 984 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KHscore</th>\n",
       "      <th>finalwt</th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>fpl_3</th>\n",
       "      <th>SWB_1_-1</th>\n",
       "      <th>SWB_1_1</th>\n",
       "      <th>SWB_1_2</th>\n",
       "      <th>SWB_1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT01_1</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_2</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_0</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.267</td>\n",
       "      <td>0.367292</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.570</td>\n",
       "      <td>1.327561</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.835156</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.485</td>\n",
       "      <td>1.410871</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.900</td>\n",
       "      <td>4.260668</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>1.267</td>\n",
       "      <td>0.522504</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>1.015219</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>1.136270</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>1.224941</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>0.626489</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 984 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:39:35.904950Z",
     "start_time": "2024-11-07T04:39:35.860609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert the one-hot encoded data to integers\n",
    "X = X.astype('float64')\n",
    "X"
   ],
   "id": "9603119c80ac19c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      KHscore   finalwt  sample_2  sample_3  fpl_2  fpl_3  SWB_1_-1  SWB_1_1  \\\n",
       "0       1.267  0.367292       1.0       0.0    0.0    1.0       0.0      0.0   \n",
       "1      -0.570  1.327561       0.0       0.0    0.0    1.0       0.0      0.0   \n",
       "2      -0.188  0.835156       0.0       0.0    0.0    1.0       0.0      0.0   \n",
       "3      -1.485  1.410871       0.0       0.0    0.0    1.0       0.0      0.0   \n",
       "4      -1.900  4.260668       0.0       0.0    0.0    1.0       0.0      0.0   \n",
       "...       ...       ...       ...       ...    ...    ...       ...      ...   \n",
       "6389    1.267  0.522504       0.0       1.0    0.0    1.0       0.0      0.0   \n",
       "6390   -1.215  1.015219       0.0       1.0    1.0    0.0       0.0      0.0   \n",
       "6391   -1.215  1.136270       0.0       0.0    0.0    1.0       0.0      0.0   \n",
       "6392   -1.215  1.224941       0.0       0.0    0.0    1.0       0.0      0.0   \n",
       "6393   -1.215  0.626489       0.0       1.0    1.0    0.0       0.0      0.0   \n",
       "\n",
       "      SWB_1_2  SWB_1_3  ...  PPREG9_9  PPT01_1  PPT25_1  PPT612_1  PPT1317_1  \\\n",
       "0         0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "1         0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "2         0.0      0.0  ...       1.0      0.0      0.0       0.0        1.0   \n",
       "3         0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "4         0.0      0.0  ...       0.0      0.0      0.0       1.0        0.0   \n",
       "...       ...      ...  ...       ...      ...      ...       ...        ...   \n",
       "6389      0.0      0.0  ...       0.0      0.0      0.0       0.0        1.0   \n",
       "6390      0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "6391      0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "6392      0.0      0.0  ...       1.0      0.0      0.0       0.0        0.0   \n",
       "6393      0.0      0.0  ...       0.0      0.0      0.0       1.0        0.0   \n",
       "\n",
       "      PPT18OV_2  PPT18OV_3  PPT18OV_4  PCTLT200FPL_0  PCTLT200FPL_1  \n",
       "0           0.0        0.0        0.0            1.0            0.0  \n",
       "1           1.0        0.0        0.0            1.0            0.0  \n",
       "2           1.0        0.0        0.0            0.0            1.0  \n",
       "3           0.0        0.0        0.0            1.0            0.0  \n",
       "4           0.0        0.0        1.0            0.0            1.0  \n",
       "...         ...        ...        ...            ...            ...  \n",
       "6389        1.0        0.0        0.0            0.0            0.0  \n",
       "6390        0.0        1.0        0.0            0.0            0.0  \n",
       "6391        1.0        0.0        0.0            1.0            0.0  \n",
       "6392        1.0        0.0        0.0            1.0            0.0  \n",
       "6393        1.0        0.0        0.0            0.0            0.0  \n",
       "\n",
       "[6394 rows x 984 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KHscore</th>\n",
       "      <th>finalwt</th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>fpl_3</th>\n",
       "      <th>SWB_1_-1</th>\n",
       "      <th>SWB_1_1</th>\n",
       "      <th>SWB_1_2</th>\n",
       "      <th>SWB_1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT01_1</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_2</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_0</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.267</td>\n",
       "      <td>0.367292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.570</td>\n",
       "      <td>1.327561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.835156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.485</td>\n",
       "      <td>1.410871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.900</td>\n",
       "      <td>4.260668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>1.267</td>\n",
       "      <td>0.522504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>1.015219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>1.136270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>1.224941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>-1.215</td>\n",
       "      <td>0.626489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 984 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove Highly Correlated Features",
   "id": "425f5fd84aeb5e2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:42:31.228071Z",
     "start_time": "2024-11-07T04:39:36.245729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove columns with high multicollinearity\n",
    "X_vif = utils.calculate_vif(X, correlation_threshold=0.9, variance_threshold=0.05)\n",
    "X_vif"
   ],
   "id": "654a84e8c6c13885",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed highly correlated variables: ['DISCOUNT_2', 'BENEFITS_1_1', 'KHKNOWL5_2', 'KHKNOWL4_2', 'KH6correct_1', 'KH3correct_1', 'EMPLOY1_8_1', 'SOCSEC2_-2', 'FK3correct_1', 'FINSOC2_1_1', 'FINSOC2_3_1', 'KH5correct_1', 'FINSOC2_2_1', 'BORROW_1_1', 'KH4correct_1', 'KH8correct_1', 'KH7correct_1', 'PAIDHELP_0', 'EMPLOY1_4_1', 'BENEFITS_5_1', 'KHKNOWL9_2', 'KH9correct_1', 'FINSOC2_5_1', 'FINSOC2_4_1', 'FINSOC2_7_1', 'MEMLOSS_1', 'FK2correct_1', 'EMPLOY1_2_1', 'Military_Status_5', 'BENEFITS_4_1', 'FINGOALS_1', 'REJECTED_1_1', 'FK1correct_1', 'BENEFITS_2_1', 'CONSPROTECT3_1', 'FINKNOWL3_2', 'KHKNOWL6_2', 'KH2correct_1', 'BENEFITS_3_1', 'KH1correct_1', 'ON1correct_1', 'REJECTED_2_1', 'FINSOC2_6_1', 'MILITARY_1', 'BORROW_2_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Removing high VIF and correlated variables', max=508.0, s…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede9b8f6b4b549a4bb164d1bcb4f90e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed variable: PCTLT200FPL_0 with VIF: 666911995237093.50\n",
      "Removed variable: PPREG4_4 with VIF: 533151394272280.44\n",
      "Removed variable: FWB2_2_3 with VIF: 3280.82\n",
      "Removed variable: LMscore_3 with VIF: 2022.52\n",
      "Removed variable: FWB1_4_3 with VIF: 1330.20\n",
      "Removed variable: FWB2_1_2 with VIF: 1119.18\n",
      "Removed variable: MANAGE1_3_5 with VIF: 558.36\n",
      "Removed variable: FWB1_5_3 with VIF: 511.65\n",
      "Removed variable: FWB2_4_3 with VIF: 420.01\n",
      "Removed variable: FWB1_1_3 with VIF: 347.94\n",
      "Removed variable: FS1_5_3 with VIF: 278.11\n",
      "Removed variable: FWB1_2_3 with VIF: 263.54\n",
      "Removed variable: KHKNOWL1_3 with VIF: 242.06\n",
      "Removed variable: FINKNOWL2_3 with VIF: 216.04\n",
      "Removed variable: SOCSEC1_1 with VIF: 140.42\n",
      "Removed variable: KHKNOWL2_3 with VIF: 125.13\n",
      "Removed variable: KIDS_4_0 with VIF: 121.44\n",
      "Removed variable: KHKNOWL8_2 with VIF: 91.11\n",
      "Removed variable: HOUSING_1 with VIF: 89.93\n",
      "Removed variable: DISTRESS_3 with VIF: 72.66\n",
      "Removed variable: OUTLOOK_1_4 with VIF: 71.70\n",
      "Removed variable: FINKNOWL1_1 with VIF: 71.51\n",
      "Removed variable: FRAUD2_0 with VIF: 70.06\n",
      "Removed variable: KHscore with VIF: 61.68\n",
      "Removed variable: CONSPROTECT2_1 with VIF: 56.69\n",
      "Removed variable: ENDSMEET_1 with VIF: 55.30\n",
      "Removed variable: SUBNUMERACY2_4 with VIF: 40.28\n",
      "Removed variable: generation_4 with VIF: 40.07\n",
      "Removed variable: MANAGE2_3 with VIF: 37.79\n",
      "Removed variable: PAREDUC_2 with VIF: 36.71\n",
      "Removed variable: VOLATILITY_1 with VIF: 36.06\n",
      "Removed variable: FS2_1_4 with VIF: 31.61\n",
      "Removed variable: EARNERS_2 with VIF: 31.41\n",
      "Removed variable: PROPPLAN_2_4 with VIF: 29.71\n",
      "Removed variable: KHKNOWL3_2 with VIF: 28.73\n",
      "Removed variable: PROPPLAN_3_4 with VIF: 26.07\n",
      "Removed variable: OUTLOOK_2_4 with VIF: 25.98\n",
      "Removed variable: AUTOMATED_1_1 with VIF: 24.75\n",
      "Removed variable: SCFHORIZON_3 with VIF: 24.37\n",
      "Removed variable: ACT1_2_4 with VIF: 24.02\n",
      "Removed variable: FS1_6_4 with VIF: 23.62\n",
      "Removed variable: FS1_1_4 with VIF: 22.54\n",
      "Removed variable: PPHHSIZE_5 with VIF: 21.46\n",
      "Removed variable: AUTOMATED_2_1 with VIF: 19.13\n",
      "Removed variable: FS1_7_4 with VIF: 18.15\n",
      "Removed variable: GOALCONF_4 with VIF: 17.47\n",
      "Removed variable: FS2_2_4 with VIF: 16.35\n",
      "Removed variable: SELFCONTROL_3_3 with VIF: 14.64\n",
      "Removed variable: FS1_4_3 with VIF: 13.39\n",
      "Removed variable: LIVINGARRANGEMENT_2 with VIF: 13.25\n",
      "Removed variable: MATERIALISM_3_2 with VIF: 13.03\n",
      "Removed variable: PROPPLAN_1_4 with VIF: 12.62\n",
      "Removed variable: FWB2_3_1 with VIF: 12.59\n",
      "Removed variable: agecat_4 with VIF: 12.36\n",
      "Removed variable: fpl_3 with VIF: 12.19\n",
      "Removed variable: HHEDUC_5 with VIF: 12.06\n",
      "Removed variable: EMPLOY_8 with VIF: 11.85\n",
      "Removed variable: HOUSING_2 with VIF: 11.46\n",
      "Removed variable: HEALTH_4 with VIF: 10.92\n",
      "Removed variable: MATHARDSHIP_2_1 with VIF: 10.58\n",
      "Removed variable: PPREG4_3 with VIF: 10.47\n",
      "Removed variable: HOUSESAT_4 with VIF: 10.37\n",
      "Removed variable: ACT1_1_5 with VIF: 10.36\n",
      "Removed variable: SELFCONTROL_2_3 with VIF: 10.20\n",
      "Removed variable: KIDS_NoChildren_0 with VIF: 9.96\n",
      "Removed variable: ASK1_1_4 with VIF: 9.94\n",
      "Removed variable: FS1_2_4 with VIF: 9.64\n",
      "Removed variable: CONSPROTECT1_1 with VIF: 9.56\n",
      "Removed variable: FS2_3_2 with VIF: 9.28\n",
      "Removed variable: PPT18OV_2 with VIF: 8.95\n",
      "Removed variable: FS1_3_3 with VIF: 8.51\n",
      "Removed variable: SELFCONTROL_1_2 with VIF: 8.44\n",
      "Removed variable: SAVEHABIT_6 with VIF: 8.37\n",
      "Removed variable: MATHARDSHIP_5_1 with VIF: 8.09\n",
      "Removed variable: OBJNUMERACY1_2 with VIF: 7.95\n",
      "Removed variable: MANAGE1_2_4 with VIF: 7.92\n",
      "Removed variable: MILITARY_0 with VIF: 7.91\n",
      "Removed variable: PPEDUC_3 with VIF: 7.89\n",
      "Removed variable: FRUGALITY_6 with VIF: 7.79\n",
      "Removed variable: ABSORBSHOCK_4 with VIF: 7.78\n",
      "Removed variable: PROPPLAN_4_3 with VIF: 7.77\n",
      "Removed variable: MANAGE1_1_5 with VIF: 7.63\n",
      "Removed variable: MATHARDSHIP_6_1 with VIF: 7.45\n",
      "Removed variable: MATHARDSHIP_1_1 with VIF: 7.08\n",
      "Removed variable: MATERIALISM_1_3 with VIF: 7.05\n",
      "Removed variable: KHKNOWL7_4 with VIF: 6.85\n",
      "Removed variable: SAVINGSRANGES_5 with VIF: 6.78\n",
      "Removed variable: generation_2 with VIF: 6.53\n",
      "Removed variable: SNAP_0 with VIF: 6.18\n",
      "Removed variable: ASK1_2_3 with VIF: 6.02\n",
      "Removed variable: CHANGEABLE_4 with VIF: 5.93\n",
      "Removed variable: KIDS_3_0 with VIF: 5.71\n",
      "Removed variable: MATHARDSHIP_4_1 with VIF: 5.66\n",
      "Removed variable: COVERCOSTS_2 with VIF: 5.64\n",
      "Removed variable: MORTGAGE_1 with VIF: 5.53\n",
      "Removed variable: SUBNUMERACY1_6 with VIF: 5.47\n",
      "Removed variable: KIDS_1_0 with VIF: 5.41\n",
      "Removed variable: SWB_1_7 with VIF: 5.38\n",
      "Removed variable: PEM_5 with VIF: 5.22\n",
      "Removed variable: KIDS_2_0 with VIF: 5.16\n",
      "\n",
      "Removed variables with high VIF:\n",
      "PCTLT200FPL_0: 666911995237093.50\n",
      "PPREG4_4: 533151394272280.44\n",
      "FWB2_2_3: 3280.82\n",
      "LMscore_3: 2022.52\n",
      "FWB1_4_3: 1330.20\n",
      "FWB2_1_2: 1119.18\n",
      "MANAGE1_3_5: 558.36\n",
      "FWB1_5_3: 511.65\n",
      "FWB2_4_3: 420.01\n",
      "FWB1_1_3: 347.94\n",
      "FS1_5_3: 278.11\n",
      "FWB1_2_3: 263.54\n",
      "KHKNOWL1_3: 242.06\n",
      "FINKNOWL2_3: 216.04\n",
      "SOCSEC1_1: 140.42\n",
      "KHKNOWL2_3: 125.13\n",
      "KIDS_4_0: 121.44\n",
      "KHKNOWL8_2: 91.11\n",
      "HOUSING_1: 89.93\n",
      "DISTRESS_3: 72.66\n",
      "OUTLOOK_1_4: 71.70\n",
      "FINKNOWL1_1: 71.51\n",
      "FRAUD2_0: 70.06\n",
      "KHscore: 61.68\n",
      "CONSPROTECT2_1: 56.69\n",
      "ENDSMEET_1: 55.30\n",
      "SUBNUMERACY2_4: 40.28\n",
      "generation_4: 40.07\n",
      "MANAGE2_3: 37.79\n",
      "PAREDUC_2: 36.71\n",
      "VOLATILITY_1: 36.06\n",
      "FS2_1_4: 31.61\n",
      "EARNERS_2: 31.41\n",
      "PROPPLAN_2_4: 29.71\n",
      "KHKNOWL3_2: 28.73\n",
      "PROPPLAN_3_4: 26.07\n",
      "OUTLOOK_2_4: 25.98\n",
      "AUTOMATED_1_1: 24.75\n",
      "SCFHORIZON_3: 24.37\n",
      "ACT1_2_4: 24.02\n",
      "FS1_6_4: 23.62\n",
      "FS1_1_4: 22.54\n",
      "PPHHSIZE_5: 21.46\n",
      "AUTOMATED_2_1: 19.13\n",
      "FS1_7_4: 18.15\n",
      "GOALCONF_4: 17.47\n",
      "FS2_2_4: 16.35\n",
      "SELFCONTROL_3_3: 14.64\n",
      "FS1_4_3: 13.39\n",
      "LIVINGARRANGEMENT_2: 13.25\n",
      "MATERIALISM_3_2: 13.03\n",
      "PROPPLAN_1_4: 12.62\n",
      "FWB2_3_1: 12.59\n",
      "agecat_4: 12.36\n",
      "fpl_3: 12.19\n",
      "HHEDUC_5: 12.06\n",
      "EMPLOY_8: 11.85\n",
      "HOUSING_2: 11.46\n",
      "HEALTH_4: 10.92\n",
      "MATHARDSHIP_2_1: 10.58\n",
      "PPREG4_3: 10.47\n",
      "HOUSESAT_4: 10.37\n",
      "ACT1_1_5: 10.36\n",
      "SELFCONTROL_2_3: 10.20\n",
      "KIDS_NoChildren_0: 9.96\n",
      "ASK1_1_4: 9.94\n",
      "FS1_2_4: 9.64\n",
      "CONSPROTECT1_1: 9.56\n",
      "FS2_3_2: 9.28\n",
      "PPT18OV_2: 8.95\n",
      "FS1_3_3: 8.51\n",
      "SELFCONTROL_1_2: 8.44\n",
      "SAVEHABIT_6: 8.37\n",
      "MATHARDSHIP_5_1: 8.09\n",
      "OBJNUMERACY1_2: 7.95\n",
      "MANAGE1_2_4: 7.92\n",
      "MILITARY_0: 7.91\n",
      "PPEDUC_3: 7.89\n",
      "FRUGALITY_6: 7.79\n",
      "ABSORBSHOCK_4: 7.78\n",
      "PROPPLAN_4_3: 7.77\n",
      "MANAGE1_1_5: 7.63\n",
      "MATHARDSHIP_6_1: 7.45\n",
      "MATHARDSHIP_1_1: 7.08\n",
      "MATERIALISM_1_3: 7.05\n",
      "KHKNOWL7_4: 6.85\n",
      "SAVINGSRANGES_5: 6.78\n",
      "generation_2: 6.53\n",
      "SNAP_0: 6.18\n",
      "ASK1_2_3: 6.02\n",
      "CHANGEABLE_4: 5.93\n",
      "KIDS_3_0: 5.71\n",
      "MATHARDSHIP_4_1: 5.66\n",
      "COVERCOSTS_2: 5.64\n",
      "MORTGAGE_1: 5.53\n",
      "SUBNUMERACY1_6: 5.47\n",
      "KIDS_1_0: 5.41\n",
      "SWB_1_7: 5.38\n",
      "PEM_5: 5.22\n",
      "KIDS_2_0: 5.16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       finalwt  sample_2  sample_3  fpl_2  SWB_1_4  SWB_1_5  SWB_1_6  SWB_2_4  \\\n",
       "0     0.367292       1.0       0.0    0.0      0.0      1.0      0.0      0.0   \n",
       "1     1.327561       0.0       0.0    0.0      0.0      0.0      1.0      0.0   \n",
       "2     0.835156       0.0       0.0    0.0      1.0      0.0      0.0      0.0   \n",
       "3     1.410871       0.0       0.0    0.0      0.0      0.0      1.0      0.0   \n",
       "4     4.260668       0.0       0.0    0.0      1.0      0.0      0.0      1.0   \n",
       "...        ...       ...       ...    ...      ...      ...      ...      ...   \n",
       "6389  0.522504       0.0       1.0    0.0      0.0      0.0      1.0      0.0   \n",
       "6390  1.015219       0.0       1.0    1.0      0.0      0.0      0.0      0.0   \n",
       "6391  1.136270       0.0       0.0    0.0      0.0      1.0      0.0      0.0   \n",
       "6392  1.224941       0.0       0.0    0.0      0.0      1.0      0.0      0.0   \n",
       "6393  0.626489       0.0       1.0    1.0      1.0      0.0      0.0      0.0   \n",
       "\n",
       "      SWB_2_5  SWB_2_6  ...  PPREG9_5  PPREG9_7  PPREG9_8  PPREG9_9  PPT25_1  \\\n",
       "0         1.0      0.0  ...       0.0       0.0       1.0       0.0      0.0   \n",
       "1         0.0      1.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "2         0.0      0.0  ...       0.0       0.0       0.0       1.0      0.0   \n",
       "3         0.0      1.0  ...       0.0       1.0       0.0       0.0      0.0   \n",
       "4         0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...      ...   \n",
       "6389      0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "6390      0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "6391      0.0      1.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "6392      1.0      0.0  ...       0.0       0.0       0.0       1.0      0.0   \n",
       "6393      0.0      1.0  ...       1.0       0.0       0.0       0.0      0.0   \n",
       "\n",
       "      PPT612_1  PPT1317_1  PPT18OV_3  PPT18OV_4  PCTLT200FPL_1  \n",
       "0          0.0        0.0        0.0        0.0            0.0  \n",
       "1          0.0        0.0        0.0        0.0            0.0  \n",
       "2          0.0        1.0        0.0        0.0            1.0  \n",
       "3          0.0        0.0        0.0        0.0            0.0  \n",
       "4          1.0        0.0        0.0        1.0            1.0  \n",
       "...        ...        ...        ...        ...            ...  \n",
       "6389       0.0        1.0        0.0        0.0            0.0  \n",
       "6390       0.0        0.0        1.0        0.0            0.0  \n",
       "6391       0.0        0.0        0.0        0.0            0.0  \n",
       "6392       0.0        0.0        0.0        0.0            0.0  \n",
       "6393       1.0        0.0        0.0        0.0            0.0  \n",
       "\n",
       "[6394 rows x 408 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finalwt</th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>SWB_1_4</th>\n",
       "      <th>SWB_1_5</th>\n",
       "      <th>SWB_1_6</th>\n",
       "      <th>SWB_2_4</th>\n",
       "      <th>SWB_2_5</th>\n",
       "      <th>SWB_2_6</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_5</th>\n",
       "      <th>PPREG9_7</th>\n",
       "      <th>PPREG9_8</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.327561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.835156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.410871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.260668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>0.522504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>1.015219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>1.136270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>1.224941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>0.626489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 408 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split the Data",
   "id": "58c746770d12d4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:42:31.615249Z",
     "start_time": "2024-11-07T04:42:31.551995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vif, y, test_size=0.2, stratify=y, random_state=42)"
   ],
   "id": "f7b846c92d84f403",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Standardize the Data",
   "id": "5c613cc3b08c8b6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:42:31.852061Z",
     "start_time": "2024-11-07T04:42:31.788619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# standardize the data\n",
    "# only standardize the \"finalwt\" column\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled['finalwt'] = scaler.fit_transform(X_train[['finalwt']])\n",
    "X_test_scaled['finalwt'] = scaler.transform(X_test[['finalwt']])\n",
    "\n",
    "# reset index\n",
    "X_train_scaled.reset_index(drop=True, inplace=True)\n",
    "X_test_scaled.reset_index(drop=True, inplace=True)\n",
    "X_train_scaled"
   ],
   "id": "22409a2213e01fc4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       finalwt  sample_2  sample_3  fpl_2  SWB_1_4  SWB_1_5  SWB_1_6  SWB_2_4  \\\n",
       "0    -0.665352       1.0       0.0    0.0      0.0      0.0      1.0      0.0   \n",
       "1     0.995296       0.0       0.0    0.0      0.0      0.0      0.0      0.0   \n",
       "2    -0.788317       0.0       0.0    0.0      1.0      0.0      0.0      1.0   \n",
       "3     0.490516       0.0       0.0    0.0      0.0      1.0      0.0      0.0   \n",
       "4     1.082103       0.0       0.0    0.0      0.0      0.0      0.0      0.0   \n",
       "...        ...       ...       ...    ...      ...      ...      ...      ...   \n",
       "5110 -0.564364       1.0       0.0    0.0      0.0      0.0      0.0      1.0   \n",
       "5111  0.357857       0.0       0.0    0.0      0.0      1.0      0.0      0.0   \n",
       "5112  0.244296       0.0       0.0    0.0      0.0      0.0      1.0      0.0   \n",
       "5113 -0.897709       0.0       0.0    0.0      0.0      0.0      0.0      0.0   \n",
       "5114 -0.290821       0.0       0.0    1.0      1.0      0.0      0.0      0.0   \n",
       "\n",
       "      SWB_2_5  SWB_2_6  ...  PPREG9_5  PPREG9_7  PPREG9_8  PPREG9_9  PPT25_1  \\\n",
       "0         0.0      1.0  ...       0.0       0.0       0.0       1.0      0.0   \n",
       "1         0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "2         0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "3         1.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "4         0.0      1.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...      ...   \n",
       "5110      0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "5111      0.0      1.0  ...       1.0       0.0       0.0       0.0      0.0   \n",
       "5112      0.0      1.0  ...       0.0       1.0       0.0       0.0      0.0   \n",
       "5113      0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "5114      0.0      1.0  ...       0.0       0.0       1.0       0.0      0.0   \n",
       "\n",
       "      PPT612_1  PPT1317_1  PPT18OV_3  PPT18OV_4  PCTLT200FPL_1  \n",
       "0          0.0        0.0        0.0        0.0            1.0  \n",
       "1          0.0        0.0        0.0        0.0            1.0  \n",
       "2          0.0        0.0        1.0        0.0            0.0  \n",
       "3          1.0        0.0        0.0        0.0            0.0  \n",
       "4          0.0        0.0        1.0        0.0            0.0  \n",
       "...        ...        ...        ...        ...            ...  \n",
       "5110       0.0        0.0        0.0        0.0            0.0  \n",
       "5111       0.0        0.0        0.0        0.0            1.0  \n",
       "5112       0.0        0.0        0.0        0.0            1.0  \n",
       "5113       1.0        1.0        0.0        0.0            0.0  \n",
       "5114       0.0        0.0        0.0        0.0            0.0  \n",
       "\n",
       "[5115 rows x 408 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finalwt</th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>SWB_1_4</th>\n",
       "      <th>SWB_1_5</th>\n",
       "      <th>SWB_1_6</th>\n",
       "      <th>SWB_2_4</th>\n",
       "      <th>SWB_2_5</th>\n",
       "      <th>SWB_2_6</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_5</th>\n",
       "      <th>PPREG9_7</th>\n",
       "      <th>PPREG9_8</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.665352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.082103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>-0.564364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>0.357857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>0.244296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>-0.897709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>-0.290821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5115 rows × 408 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression to Find Important Features",
   "id": "bd2155617d4b81ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:47:47.581371Z",
     "start_time": "2024-11-07T04:42:31.866216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reset the index of y_train to match X_train_scaled_const\n",
    "y_train_scaled = y_train.reset_index(drop=True)\n",
    "\n",
    "X_train_scaled_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "logit_model = sm.Logit(y_train_scaled, X_train_scaled_const).fit_regularized(method='l1', alpha=3)\n",
    "print(logit_model.summary())"
   ],
   "id": "29e905fd7bee60d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.11362476605075092\n",
      "            Iterations: 289\n",
      "            Function evaluations: 290\n",
      "            Gradient evaluations: 289\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              PRODUSE_3   No. Observations:                 5115\n",
      "Model:                          Logit   Df Residuals:                     4915\n",
      "Method:                           MLE   Df Model:                          199\n",
      "Date:                Wed, 06 Nov 2024   Pseudo R-squ.:                  0.6944\n",
      "Time:                        23:47:47   Log-Likelihood:                -464.13\n",
      "converged:                       True   LL-Null:                       -1518.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                          0        nan        nan        nan         nan         nan\n",
      "finalwt                   0.0539      0.083      0.646      0.518      -0.110       0.217\n",
      "sample_2                 -0.1053      0.317     -0.333      0.739      -0.726       0.515\n",
      "sample_3                       0        nan        nan        nan         nan         nan\n",
      "fpl_2                          0        nan        nan        nan         nan         nan\n",
      "SWB_1_4                        0        nan        nan        nan         nan         nan\n",
      "SWB_1_5                   0.1275      0.228      0.558      0.577      -0.320       0.575\n",
      "SWB_1_6                   0.0102      0.238      0.043      0.966      -0.457       0.477\n",
      "SWB_2_4                        0        nan        nan        nan         nan         nan\n",
      "SWB_2_5                   0.3683      0.249      1.477      0.140      -0.120       0.857\n",
      "SWB_2_6                   0.0867      0.274      0.317      0.751      -0.449       0.623\n",
      "SWB_2_7                  -0.0958      0.251     -0.381      0.703      -0.588       0.397\n",
      "SWB_3_4                   0.0061      0.265      0.023      0.981      -0.512       0.525\n",
      "SWB_3_5                  -0.1575      0.256     -0.615      0.539      -0.659       0.344\n",
      "SWB_3_6                  -0.0922      0.244     -0.378      0.705      -0.570       0.385\n",
      "SWB_3_7                        0        nan        nan        nan         nan         nan\n",
      "FWB1_1_1                       0        nan        nan        nan         nan         nan\n",
      "FWB1_1_2                       0        nan        nan        nan         nan         nan\n",
      "FWB1_1_4                       0        nan        nan        nan         nan         nan\n",
      "FWB1_1_5                 -0.2362      0.330     -0.715      0.475      -0.884       0.411\n",
      "FWB1_2_1                       0        nan        nan        nan         nan         nan\n",
      "FWB1_2_2               1.711e-17      0.224   7.65e-17      1.000      -0.438       0.438\n",
      "FWB1_2_4                       0        nan        nan        nan         nan         nan\n",
      "FWB1_2_5                       0        nan        nan        nan         nan         nan\n",
      "FWB1_3_1                  0.0545      0.272      0.200      0.841      -0.479       0.588\n",
      "FWB1_3_2                       0        nan        nan        nan         nan         nan\n",
      "FWB1_3_3                 -0.0319      0.198     -0.161      0.872      -0.421       0.357\n",
      "FWB1_3_4                       0        nan        nan        nan         nan         nan\n",
      "FWB1_3_5                       0        nan        nan        nan         nan         nan\n",
      "FWB1_4_1                       0        nan        nan        nan         nan         nan\n",
      "FWB1_4_2                       0        nan        nan        nan         nan         nan\n",
      "FWB1_4_4                  0.1163      0.236      0.492      0.623      -0.347       0.580\n",
      "FWB1_4_5                 -0.0666      0.332     -0.201      0.841      -0.718       0.584\n",
      "FWB1_5_1                       0        nan        nan        nan         nan         nan\n",
      "FWB1_5_2                 -0.2437      0.237     -1.030      0.303      -0.708       0.220\n",
      "FWB1_5_4                  0.0128      0.216      0.059      0.953      -0.411       0.436\n",
      "FWB1_5_5                       0        nan        nan        nan         nan         nan\n",
      "FWB1_6_1                  0.0655      0.403      0.162      0.871      -0.725       0.855\n",
      "FWB1_6_2               1.686e-17      0.298   5.66e-17      1.000      -0.584       0.584\n",
      "FWB1_6_3                  0.1891      0.239      0.792      0.428      -0.279       0.657\n",
      "FWB1_6_4                 -0.2445      0.270     -0.907      0.364      -0.773       0.284\n",
      "FWB1_6_5                       0        nan        nan        nan         nan         nan\n",
      "FWB2_1_1                       0        nan        nan        nan         nan         nan\n",
      "FWB2_1_3                  0.0869      0.194      0.447      0.655      -0.294       0.468\n",
      "FWB2_1_4                       0        nan        nan        nan         nan         nan\n",
      "FWB2_1_5                       0        nan        nan        nan         nan         nan\n",
      "FWB2_2_1                       0        nan        nan        nan         nan         nan\n",
      "FWB2_2_2                 -0.1433      0.218     -0.658      0.510      -0.570       0.283\n",
      "FWB2_2_4                       0        nan        nan        nan         nan         nan\n",
      "FWB2_2_5                       0        nan        nan        nan         nan         nan\n",
      "FWB2_3_2                       0        nan        nan        nan         nan         nan\n",
      "FWB2_3_3                 -0.0064      0.226     -0.028      0.977      -0.449       0.436\n",
      "FWB2_3_4                  0.5750      0.288      1.994      0.046       0.010       1.140\n",
      "FWB2_4_1                       0        nan        nan        nan         nan         nan\n",
      "FWB2_4_2                  0.0508      0.219      0.232      0.816      -0.378       0.479\n",
      "FWB2_4_4                 -0.0054      0.224     -0.024      0.981      -0.444       0.434\n",
      "FWB2_4_5                       0        nan        nan        nan         nan         nan\n",
      "FSscore_42                     0        nan        nan        nan         nan         nan\n",
      "FS1_1_2                        0        nan        nan        nan         nan         nan\n",
      "FS1_1_3                        0        nan        nan        nan         nan         nan\n",
      "FS1_1_5                        0        nan        nan        nan         nan         nan\n",
      "FS1_2_2                  -0.1955      0.282     -0.692      0.489      -0.749       0.358\n",
      "FS1_2_3                   0.0412      0.211      0.196      0.845      -0.372       0.454\n",
      "FS1_2_5                  -0.2648      0.285     -0.929      0.353      -0.823       0.294\n",
      "FS1_3_2                        0        nan        nan        nan         nan         nan\n",
      "FS1_3_4                        0        nan        nan        nan         nan         nan\n",
      "FS1_3_5                        0        nan        nan        nan         nan         nan\n",
      "FS1_4_2                        0        nan        nan        nan         nan         nan\n",
      "FS1_4_4                  -0.3509      0.212     -1.659      0.097      -0.766       0.064\n",
      "FS1_4_5                        0        nan        nan        nan         nan         nan\n",
      "FS1_5_1                        0        nan        nan        nan         nan         nan\n",
      "FS1_5_2                        0        nan        nan        nan         nan         nan\n",
      "FS1_5_4                        0        nan        nan        nan         nan         nan\n",
      "FS1_5_5                  -0.1535      0.364     -0.422      0.673      -0.867       0.560\n",
      "FS1_6_2                  -0.0436      0.334     -0.131      0.896      -0.697       0.610\n",
      "FS1_6_3                        0        nan        nan        nan         nan         nan\n",
      "FS1_6_5                        0        nan        nan        nan         nan         nan\n",
      "FS1_7_2                2.859e-17      0.324   8.83e-17      1.000      -0.635       0.635\n",
      "FS1_7_3                  -0.0024      0.220     -0.011      0.991      -0.433       0.428\n",
      "FS1_7_5                   0.1484      0.266      0.558      0.577      -0.373       0.669\n",
      "FS2_1_2                        0        nan        nan        nan         nan         nan\n",
      "FS2_1_3                  -0.0452      0.193     -0.234      0.815      -0.424       0.334\n",
      "FS2_1_5                  -0.0646      0.250     -0.259      0.796      -0.554       0.425\n",
      "FS2_2_2                   0.0137      0.275      0.050      0.960      -0.525       0.552\n",
      "FS2_2_3                        0        nan        nan        nan         nan         nan\n",
      "FS2_2_5                        0        nan        nan        nan         nan         nan\n",
      "FS2_3_1                        0        nan        nan        nan         nan         nan\n",
      "FS2_3_3                   0.1533      0.191      0.803      0.422      -0.221       0.527\n",
      "FS2_3_4                  -0.0688      0.258     -0.266      0.790      -0.575       0.438\n",
      "SUBKNOWL1_3               0.0319      0.303      0.105      0.916      -0.561       0.625\n",
      "SUBKNOWL1_4            1.637e-17      0.251   6.52e-17      1.000      -0.492       0.492\n",
      "SUBKNOWL1_5               0.1651      0.221      0.749      0.454      -0.267       0.597\n",
      "SUBKNOWL1_6                    0        nan        nan        nan         nan         nan\n",
      "ACT1_1_3                       0        nan        nan        nan         nan         nan\n",
      "ACT1_1_4                       0        nan        nan        nan         nan         nan\n",
      "ACT1_2_2                       0        nan        nan        nan         nan         nan\n",
      "ACT1_2_3                       0        nan        nan        nan         nan         nan\n",
      "ACT1_2_5                       0        nan        nan        nan         nan         nan\n",
      "FINGOALS_0               -0.4219      0.181     -2.330      0.020      -0.777      -0.067\n",
      "PROPPLAN_1_2                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_1_3                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_1_5              0.1829      0.226      0.810      0.418      -0.260       0.625\n",
      "PROPPLAN_2_2                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_2_3                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_2_5                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_3_2              0.0508      0.334      0.152      0.879      -0.605       0.706\n",
      "PROPPLAN_3_3             -0.0133      0.214     -0.062      0.950      -0.433       0.407\n",
      "PROPPLAN_3_5                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_4_2                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_4_4              0.3217      0.189      1.703      0.088      -0.048       0.692\n",
      "PROPPLAN_4_5                   0        nan        nan        nan         nan         nan\n",
      "MANAGE1_1_3              -0.1395      0.277     -0.503      0.615      -0.683       0.404\n",
      "MANAGE1_1_4               0.1858      0.223      0.834      0.404      -0.251       0.622\n",
      "MANAGE1_2_2                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_2_3                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_2_5               0.0084      0.231      0.036      0.971      -0.445       0.462\n",
      "MANAGE1_3_1                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_3_2                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_3_3               0.2250      0.229      0.984      0.325      -0.223       0.673\n",
      "MANAGE1_3_4              -0.1866      0.250     -0.745      0.456      -0.677       0.304\n",
      "MANAGE1_4_3                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_4_4                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_4_5               0.1089      0.197      0.552      0.581      -0.278       0.496\n",
      "SAVEHABIT_2                    0        nan        nan        nan         nan         nan\n",
      "SAVEHABIT_3              -0.1164      0.249     -0.468      0.640      -0.604       0.371\n",
      "SAVEHABIT_4                    0        nan        nan        nan         nan         nan\n",
      "SAVEHABIT_5                    0        nan        nan        nan         nan         nan\n",
      "FRUGALITY_4              -0.0374      0.240     -0.156      0.876      -0.508       0.433\n",
      "FRUGALITY_5                    0        nan        nan        nan         nan         nan\n",
      "AUTOMATED_1_0                  0        nan        nan        nan         nan         nan\n",
      "AUTOMATED_1_7            -0.0767      0.210     -0.366      0.715      -0.488       0.334\n",
      "AUTOMATED_2_0            -0.0176      0.183     -0.096      0.923      -0.376       0.341\n",
      "AUTOMATED_2_7                  0        nan        nan        nan         nan         nan\n",
      "ASK1_1_2                 -0.0841      0.289     -0.291      0.771      -0.650       0.482\n",
      "ASK1_1_3                       0        nan        nan        nan         nan         nan\n",
      "ASK1_1_5                       0        nan        nan        nan         nan         nan\n",
      "ASK1_2_1                       0        nan        nan        nan         nan         nan\n",
      "ASK1_2_2                 -0.0305      0.206     -0.148      0.883      -0.435       0.374\n",
      "ASK1_2_4                       0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY2_1           -0.1428      0.219     -0.653      0.513      -0.571       0.286\n",
      "SUBNUMERACY2_2                 0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY2_3                 0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY2_5                 0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY2_6           -0.3664      0.236     -1.551      0.121      -0.829       0.097\n",
      "SUBNUMERACY1_1                 0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY1_3                 0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY1_4           -0.0340      0.199     -0.171      0.864      -0.423       0.355\n",
      "SUBNUMERACY1_5            0.0314      0.218      0.144      0.885      -0.395       0.458\n",
      "CHANGEABLE_1                   0        nan        nan        nan         nan         nan\n",
      "CHANGEABLE_2                   0        nan        nan        nan         nan         nan\n",
      "CHANGEABLE_3              0.0560      0.251      0.223      0.823      -0.436       0.548\n",
      "CHANGEABLE_5              0.0383      0.209      0.184      0.854      -0.371       0.447\n",
      "CHANGEABLE_6                   0        nan        nan        nan         nan         nan\n",
      "GOALCONF_2                     0        nan        nan        nan         nan         nan\n",
      "GOALCONF_3               -0.0455      0.173     -0.263      0.793      -0.384       0.294\n",
      "LMscore_1                      0        nan        nan        nan         nan         nan\n",
      "LMscore_2                -0.1625      0.178     -0.912      0.362      -0.512       0.187\n",
      "FINKNOWL1_2              -0.2504      0.258     -0.971      0.332      -0.756       0.255\n",
      "FINKNOWL1_3                    0        nan        nan        nan         nan         nan\n",
      "FINKNOWL2_1                    0        nan        nan        nan         nan         nan\n",
      "FINKNOWL2_2              -0.1577      0.211     -0.749      0.454      -0.571       0.255\n",
      "FINKNOWL3_1              -0.0689      0.207     -0.333      0.739      -0.475       0.337\n",
      "KHKNOWL1_1                     0        nan        nan        nan         nan         nan\n",
      "KHKNOWL1_2                0.3752      0.179      2.098      0.036       0.025       0.726\n",
      "KHKNOWL2_1               -0.1447      0.261     -0.554      0.580      -0.657       0.367\n",
      "KHKNOWL2_2               -0.0847      0.251     -0.337      0.736      -0.577       0.408\n",
      "KHKNOWL3_1                     0        nan        nan        nan         nan         nan\n",
      "KHKNOWL3_3                     0        nan        nan        nan         nan         nan\n",
      "KHKNOWL4_1                0.0934      0.191      0.490      0.624      -0.280       0.467\n",
      "KHKNOWL5_1               -0.1041      0.186     -0.559      0.576      -0.469       0.261\n",
      "KHKNOWL6_1               -0.1140      0.239     -0.477      0.634      -0.583       0.355\n",
      "KHKNOWL7_2                     0        nan        nan        nan         nan         nan\n",
      "KHKNOWL7_3               -0.2372      0.185     -1.282      0.200      -0.600       0.125\n",
      "KHKNOWL8_1                     0        nan        nan        nan         nan         nan\n",
      "KHKNOWL8_3               -0.3735      0.237     -1.573      0.116      -0.839       0.092\n",
      "KHKNOWL8_4                0.2785      0.198      1.409      0.159      -0.109       0.666\n",
      "KHKNOWL9_1                0.0987      0.213      0.464      0.643      -0.319       0.516\n",
      "ENDSMEET_2               -0.0379      0.227     -0.167      0.867      -0.482       0.407\n",
      "ENDSMEET_3                0.0846      0.310      0.273      0.785      -0.523       0.693\n",
      "HOUSING_3                 0.2009      0.284      0.708      0.479      -0.355       0.757\n",
      "LIVINGARRANGEMENT_1      -0.0732      0.263     -0.279      0.780      -0.588       0.441\n",
      "LIVINGARRANGEMENT_3       0.0761      0.348      0.219      0.827      -0.606       0.758\n",
      "LIVINGARRANGEMENT_4            0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_1             0.2021      0.259      0.780      0.435      -0.305       0.710\n",
      "HOUSERANGES_2             0.2052      0.281      0.731      0.465      -0.345       0.756\n",
      "HOUSERANGES_3                  0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_4            -0.0041      0.222     -0.018      0.985      -0.440       0.432\n",
      "HOUSERANGES_5                  0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_6                  0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_7                  0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_99                 0        nan        nan        nan         nan         nan\n",
      "IMPUTATION_FLAG_1              0        nan        nan        nan         nan         nan\n",
      "VALUERANGES_1                  0        nan        nan        nan         nan         nan\n",
      "VALUERANGES_2                  0        nan        nan        nan         nan         nan\n",
      "VALUERANGES_3             0.2221      0.319      0.697      0.486      -0.403       0.847\n",
      "VALUERANGES_4                  0        nan        nan        nan         nan         nan\n",
      "MORTGAGE_2               -0.2270      0.264     -0.861      0.389      -0.744       0.290\n",
      "MORTGAGE_3               -0.4007      0.396     -1.011      0.312      -1.177       0.376\n",
      "MORTGAGE_99                    0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_1           0.0393      0.248      0.158      0.874      -0.447       0.526\n",
      "SAVINGSRANGES_2                0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_3                0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_4                0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_6                0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_7                0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_99               0        nan        nan        nan         nan         nan\n",
      "PRODHAVE_1_1             -0.3325      0.203     -1.641      0.101      -0.730       0.065\n",
      "PRODHAVE_2_1             -0.2636      0.192     -1.372      0.170      -0.640       0.113\n",
      "PRODHAVE_3_1              0.2217      0.191      1.159      0.247      -0.153       0.597\n",
      "PRODHAVE_4_1                   0        nan        nan        nan         nan         nan\n",
      "PRODHAVE_5_1              0.1771      0.252      0.703      0.482      -0.317       0.671\n",
      "PRODHAVE_6_1              0.5832      0.251      2.322      0.020       0.091       1.075\n",
      "PRODHAVE_7_1                   0        nan        nan        nan         nan         nan\n",
      "PRODHAVE_8_1                   0        nan        nan        nan         nan         nan\n",
      "PRODUSE_5_1              -2.1272      0.204    -10.433      0.000      -2.527      -1.728\n",
      "PRODUSE_6_1              -8.0257      0.601    -13.351      0.000      -9.204      -6.848\n",
      "CONSPROTECT1_2           -0.1390      0.172     -0.808      0.419      -0.476       0.198\n",
      "CONSPROTECT1_3                 0        nan        nan        nan         nan         nan\n",
      "CONSPROTECT2_2            0.1532      0.174      0.881      0.378      -0.188       0.494\n",
      "CONSPROTECT2_3                 0        nan        nan        nan         nan         nan\n",
      "CONSPROTECT3_0            0.1439      0.256      0.563      0.574      -0.357       0.645\n",
      "EARNERS_1                      0        nan        nan        nan         nan         nan\n",
      "EARNERS_3                -0.5369      0.298     -1.801      0.072      -1.121       0.047\n",
      "VOLATILITY_2              0.0288      0.188      0.153      0.879      -0.340       0.398\n",
      "VOLATILITY_3                   0        nan        nan        nan         nan         nan\n",
      "SNAP_1                    0.3640      0.219      1.661      0.097      -0.065       0.793\n",
      "MATHARDSHIP_1_2        6.597e-17      0.200    3.3e-16      1.000      -0.391       0.391\n",
      "MATHARDSHIP_2_2                0        nan        nan        nan         nan         nan\n",
      "MATHARDSHIP_3_1                0        nan        nan        nan         nan         nan\n",
      "MATHARDSHIP_3_2                0        nan        nan        nan         nan         nan\n",
      "MATHARDSHIP_4_2          -0.1261      0.213     -0.592      0.554      -0.544       0.292\n",
      "MATHARDSHIP_5_2                0        nan        nan        nan         nan         nan\n",
      "MATHARDSHIP_6_2                0        nan        nan        nan         nan         nan\n",
      "COLLECT_0                      0        nan        nan        nan         nan         nan\n",
      "COLLECT_1                 0.0094      0.222      0.042      0.966      -0.427       0.445\n",
      "REJECTED_1_0                   0        nan        nan        nan         nan         nan\n",
      "REJECTED_2_0          -2.433e-17      0.207  -1.18e-16      1.000      -0.405       0.405\n",
      "ABSORBSHOCK_1                  0        nan        nan        nan         nan         nan\n",
      "ABSORBSHOCK_2                  0        nan        nan        nan         nan         nan\n",
      "ABSORBSHOCK_3                  0        nan        nan        nan         nan         nan\n",
      "BENEFITS_1_0             -0.0903      0.208     -0.435      0.664      -0.498       0.317\n",
      "BENEFITS_2_0              0.0518      0.236      0.220      0.826      -0.410       0.513\n",
      "BENEFITS_3_0             -0.1105      0.232     -0.477      0.633      -0.564       0.343\n",
      "BENEFITS_4_0              0.2117      0.272      0.777      0.437      -0.322       0.746\n",
      "BENEFITS_5_0              0.3184      0.237      1.345      0.179      -0.146       0.783\n",
      "FRAUD2_1              -3.564e-17      0.200  -1.78e-16      1.000      -0.391       0.391\n",
      "FRAUD2_8                 -0.2951      0.255     -1.155      0.248      -0.796       0.206\n",
      "COVERCOSTS_1              0.1608      0.216      0.745      0.456      -0.262       0.584\n",
      "COVERCOSTS_3              0.0955      0.244      0.391      0.696      -0.384       0.575\n",
      "BORROW_1_0               -0.1718      0.176     -0.976      0.329      -0.517       0.173\n",
      "BORROW_2_0               -0.1432      0.178     -0.804      0.421      -0.492       0.206\n",
      "SHOCKS_1_1                     0        nan        nan        nan         nan         nan\n",
      "SHOCKS_2_1               -0.2772      0.257     -1.079      0.280      -0.781       0.226\n",
      "SHOCKS_4_1                0.1704      0.210      0.812      0.417      -0.241       0.582\n",
      "SHOCKS_5_1                0.0259      0.217      0.119      0.905      -0.400       0.452\n",
      "SHOCKS_9_1                0.2427      0.366      0.663      0.507      -0.474       0.960\n",
      "SHOCKS_11_1              -0.1135      0.229     -0.497      0.619      -0.562       0.335\n",
      "SHOCKS_12_1               0.1116      0.239      0.468      0.640      -0.356       0.579\n",
      "MANAGE2_1                 0.2672      0.281      0.951      0.341      -0.283       0.818\n",
      "MANAGE2_2                 0.0146      0.199      0.073      0.942      -0.376       0.406\n",
      "HSLOC_1                   0.0323      0.233      0.138      0.890      -0.425       0.489\n",
      "HSLOC_2                  -0.2645      0.360     -0.735      0.463      -0.970       0.441\n",
      "PAREDUC_1                -0.0815      0.267     -0.305      0.760      -0.605       0.442\n",
      "PAREDUC_3                 0.1633      0.203      0.806      0.420      -0.234       0.561\n",
      "PAREDUC_4                      0        nan        nan        nan         nan         nan\n",
      "PAREDUC_5                      0        nan        nan        nan         nan         nan\n",
      "FINSOC2_1_0               0.0423      0.198      0.214      0.831      -0.345       0.430\n",
      "FINSOC2_2_0                    0        nan        nan        nan         nan         nan\n",
      "FINSOC2_3_0                    0        nan        nan        nan         nan         nan\n",
      "FINSOC2_4_0              -0.1688      0.186     -0.910      0.363      -0.533       0.195\n",
      "FINSOC2_5_0                    0        nan        nan        nan         nan         nan\n",
      "FINSOC2_6_0                    0        nan        nan        nan         nan         nan\n",
      "FINSOC2_7_0              -0.1597      0.196     -0.814      0.415      -0.544       0.225\n",
      "OBJNUMERACY1_1                 0        nan        nan        nan         nan         nan\n",
      "OBJNUMERACY1_3            0.0073      0.228      0.032      0.974      -0.439       0.454\n",
      "ON2correct_1                   0        nan        nan        nan         nan         nan\n",
      "MATERIALISM_1_1        6.346e-17      0.299   2.12e-16      1.000      -0.586       0.586\n",
      "MATERIALISM_1_2          -0.0270      0.223     -0.121      0.904      -0.464       0.410\n",
      "MATERIALISM_1_4           0.0079      0.252      0.031      0.975      -0.487       0.503\n",
      "MATERIALISM_2_1           0.1157      0.341      0.340      0.734      -0.552       0.783\n",
      "MATERIALISM_2_2                0        nan        nan        nan         nan         nan\n",
      "MATERIALISM_2_3          -0.1694      0.216     -0.784      0.433      -0.593       0.254\n",
      "MATERIALISM_2_4          -0.0723      0.239     -0.302      0.763      -0.541       0.397\n",
      "MATERIALISM_3_1          -0.1426      0.271     -0.527      0.598      -0.673       0.388\n",
      "MATERIALISM_3_3          -0.0390      0.215     -0.181      0.856      -0.461       0.383\n",
      "MATERIALISM_3_4          -0.7516      0.302     -2.486      0.013      -1.344      -0.159\n",
      "CONNECT_50                     0        nan        nan        nan         nan         nan\n",
      "CONNECT_75                0.1057      0.393      0.269      0.788      -0.665       0.877\n",
      "CONNECT_80                     0        nan        nan        nan         nan         nan\n",
      "CONNECT_90               -0.4821      0.324     -1.486      0.137      -1.118       0.154\n",
      "CONNECT_100              -0.1215      0.229     -0.531      0.596      -0.570       0.327\n",
      "HEALTH_2                  0.3697      0.227      1.628      0.103      -0.075       0.815\n",
      "HEALTH_3                       0        nan        nan        nan         nan         nan\n",
      "HEALTH_5                       0        nan        nan        nan         nan         nan\n",
      "SCFHORIZON_1                   0        nan        nan        nan         nan         nan\n",
      "SCFHORIZON_2                   0        nan        nan        nan         nan         nan\n",
      "SCFHORIZON_4              0.1616      0.211      0.767      0.443      -0.252       0.575\n",
      "SCFHORIZON_5                   0        nan        nan        nan         nan         nan\n",
      "DISCOUNT_1                     0        nan        nan        nan         nan         nan\n",
      "MEMLOSS_0                      0        nan        nan        nan         nan         nan\n",
      "DISTRESS_1               -0.3452      0.335     -1.031      0.303      -1.002       0.311\n",
      "DISTRESS_2                     0        nan        nan        nan         nan         nan\n",
      "DISTRESS_4                0.2041      0.205      0.993      0.321      -0.199       0.607\n",
      "DISTRESS_5               -0.0213      0.261     -0.082      0.935      -0.533       0.490\n",
      "SELFCONTROL_1_1                0        nan        nan        nan         nan         nan\n",
      "SELFCONTROL_1_3                0        nan        nan        nan         nan         nan\n",
      "SELFCONTROL_2_2           0.0345      0.206      0.167      0.867      -0.370       0.439\n",
      "SELFCONTROL_2_4           0.0521      0.244      0.214      0.831      -0.425       0.530\n",
      "SELFCONTROL_3_2                0        nan        nan        nan         nan         nan\n",
      "SELFCONTROL_3_4                0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_1_1                    0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_1_2                    0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_1_3                    0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_1_5               0.2914      0.214      1.359      0.174      -0.129       0.712\n",
      "OUTLOOK_2_1                    0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_2_2                    0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_2_3               0.0994      0.199      0.499      0.618      -0.291       0.490\n",
      "OUTLOOK_2_5                    0        nan        nan        nan         nan         nan\n",
      "INTERCONNECTIONS_1_1      0.1315      0.222      0.592      0.554      -0.304       0.567\n",
      "INTERCONNECTIONS_2_1      0.0824      0.205      0.402      0.688      -0.320       0.484\n",
      "INTERCONNECTIONS_3_1      0.1729      0.235      0.737      0.461      -0.287       0.633\n",
      "INTERCONNECTIONS_4_1      0.0829      0.307      0.270      0.787      -0.519       0.685\n",
      "INTERCONNECTIONS_5_1      0.2544      0.199      1.276      0.202      -0.136       0.645\n",
      "INTERCONNECTIONS_7_1      0.0804      0.230      0.350      0.726      -0.370       0.531\n",
      "INTERCONNECTIONS_8_1           0        nan        nan        nan         nan         nan\n",
      "INTERCONNECTIONS_10_1     0.1452      0.286      0.507      0.612      -0.416       0.706\n",
      "PEM_2                    -0.0662      0.316     -0.210      0.834      -0.685       0.553\n",
      "PEM_3                          0        nan        nan        nan         nan         nan\n",
      "PEM_4                    -0.0839      0.259     -0.324      0.746      -0.591       0.424\n",
      "PEM_6                          0        nan        nan        nan         nan         nan\n",
      "PEM_7                          0        nan        nan        nan         nan         nan\n",
      "HOUSESAT_2                     0        nan        nan        nan         nan         nan\n",
      "HOUSESAT_3                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC1_0                      0        nan        nan        nan         nan         nan\n",
      "SOCSEC2_62                0.1059      0.342      0.310      0.757      -0.565       0.776\n",
      "SOCSEC2_65                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC3_-2                0.1143      0.330      0.347      0.729      -0.532       0.760\n",
      "SOCSEC3_61                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC3_62                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC3_65                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC3_67               -0.1786      0.387     -0.462      0.644      -0.936       0.579\n",
      "SOCSEC3_70                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC3_71                     0        nan        nan        nan         nan         nan\n",
      "LIFEEXPECT_50                  0        nan        nan        nan         nan         nan\n",
      "LIFEEXPECT_75            -0.1574      0.365     -0.431      0.667      -0.874       0.559\n",
      "LIFEEXPECT_80                  0        nan        nan        nan         nan         nan\n",
      "LIFEEXPECT_90                  0        nan        nan        nan         nan         nan\n",
      "LIFEEXPECT_100                 0        nan        nan        nan         nan         nan\n",
      "HHEDUC_2                       0        nan        nan        nan         nan         nan\n",
      "HHEDUC_3                       0        nan        nan        nan         nan         nan\n",
      "HHEDUC_4                       0        nan        nan        nan         nan         nan\n",
      "KIDS_NoChildren_1         0.0857      0.192      0.446      0.656      -0.291       0.462\n",
      "KIDS_1_1                  0.4150      0.325      1.275      0.202      -0.223       1.053\n",
      "KIDS_2_1                       0        nan        nan        nan         nan         nan\n",
      "KIDS_3_1                       0        nan        nan        nan         nan         nan\n",
      "KIDS_4_1                       0        nan        nan        nan         nan         nan\n",
      "KIDS_4_2                       0        nan        nan        nan         nan         nan\n",
      "EMPLOY_2                       0        nan        nan        nan         nan         nan\n",
      "EMPLOY_3                       0        nan        nan        nan         nan         nan\n",
      "EMPLOY_4                       0        nan        nan        nan         nan         nan\n",
      "EMPLOY1_1_1                    0        nan        nan        nan         nan         nan\n",
      "EMPLOY1_3_1              -0.0549      0.266     -0.207      0.836      -0.576       0.466\n",
      "RETIRE_1                       0        nan        nan        nan         nan         nan\n",
      "RETIRE_2                       0        nan        nan        nan         nan         nan\n",
      "Military_Status_2              0        nan        nan        nan         nan         nan\n",
      "Military_Status_4              0        nan        nan        nan         nan         nan\n",
      "agecat_2                       0        nan        nan        nan         nan         nan\n",
      "agecat_3                       0        nan        nan        nan         nan         nan\n",
      "agecat_5                 -0.0895      0.329     -0.272      0.786      -0.734       0.555\n",
      "agecat_6                       0        nan        nan        nan         nan         nan\n",
      "agecat_7                       0        nan        nan        nan         nan         nan\n",
      "agecat_8                  0.2110      0.337      0.626      0.531      -0.450       0.872\n",
      "generation_3                   0        nan        nan        nan         nan         nan\n",
      "PPEDUC_2                  0.2871      0.204      1.408      0.159      -0.112       0.687\n",
      "PPEDUC_4                       0        nan        nan        nan         nan         nan\n",
      "PPEDUC_5                       0        nan        nan        nan         nan         nan\n",
      "PPETHM_2                 -0.0256      0.245     -0.104      0.917      -0.507       0.455\n",
      "PPETHM_4                 -0.1653      0.250     -0.661      0.509      -0.656       0.325\n",
      "PPGENDER_2               -0.1128      0.172     -0.656      0.512      -0.450       0.224\n",
      "PPHHSIZE_2               -0.3482      0.211     -1.647      0.099      -0.763       0.066\n",
      "PPHHSIZE_3                     0        nan        nan        nan         nan         nan\n",
      "PPHHSIZE_4                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_2                0.2022      0.261      0.774      0.439      -0.310       0.714\n",
      "PPINCIMP_3                0.1913      0.280      0.683      0.494      -0.357       0.740\n",
      "PPINCIMP_4               -0.1159      0.298     -0.389      0.698      -0.700       0.469\n",
      "PPINCIMP_5                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_6                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_7                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_8                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_9               -0.1984      0.394     -0.504      0.614      -0.970       0.573\n",
      "PPMARIT_2                      0        nan        nan        nan         nan         nan\n",
      "PPMARIT_3                 0.0316      0.270      0.117      0.907      -0.497       0.560\n",
      "PPMARIT_4                 0.0890      0.264      0.337      0.736      -0.429       0.607\n",
      "PPMARIT_5                 0.1092      0.338      0.324      0.746      -0.552       0.771\n",
      "PPMSACAT_1                     0        nan        nan        nan         nan         nan\n",
      "PPREG4_2                       0        nan        nan        nan         nan         nan\n",
      "PPREG9_2                  0.0052      0.275      0.019      0.985      -0.533       0.543\n",
      "PPREG9_3                 -0.2221      0.267     -0.831      0.406      -0.746       0.302\n",
      "PPREG9_4                       0        nan        nan        nan         nan         nan\n",
      "PPREG9_5                  0.0135      0.230      0.059      0.953      -0.437       0.464\n",
      "PPREG9_7                       0        nan        nan        nan         nan         nan\n",
      "PPREG9_8                 -0.2607      0.363     -0.718      0.473      -0.973       0.451\n",
      "PPREG9_9                 -0.2351      0.269     -0.875      0.381      -0.762       0.291\n",
      "PPT25_1                  -0.1581      0.311     -0.508      0.611      -0.768       0.452\n",
      "PPT612_1                 -0.0423      0.249     -0.170      0.865      -0.530       0.445\n",
      "PPT1317_1                 0.0340      0.243      0.140      0.889      -0.443       0.511\n",
      "PPT18OV_3                -0.3692      0.251     -1.470      0.141      -0.861       0.123\n",
      "PPT18OV_4                      0        nan        nan        nan         nan         nan\n",
      "PCTLT200FPL_1             0.4397      0.189      2.323      0.020       0.069       0.811\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:18:03.429391Z",
     "start_time": "2024-11-07T16:18:03.243093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the coefficients and p-values\n",
    "coefficients = logit_model.params\n",
    "p_values = logit_model.pvalues\n",
    "\n",
    "# Create a DataFrame to hold coefficients and p-values for easier processing\n",
    "coef_df = pd.DataFrame({\n",
    "    'Coefficient': coefficients,\n",
    "    'P-Value': p_values\n",
    "})\n",
    "\n",
    "# Filter out statistically significant coefficients (e.g., p-value < 0.05)\n",
    "significant_coefs = coef_df[coef_df['P-Value'] < 0.05]\n",
    "\n",
    "# Sort coefficients by absolute value (to find the top 20 largest), keeping the sign\n",
    "top_coefs = significant_coefs['Coefficient'].abs().sort_values(ascending=False).head(20).index\n",
    "\n",
    "# Filter the original coefficients DataFrame to get the top 20 largest coefficients (with signs)\n",
    "top_coefs_with_signs = significant_coefs.loc[top_coefs]\n",
    "\n",
    "# Plot the top 20 largest coefficients with their signs\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_coefs_with_signs['Coefficient'].plot(kind='barh', color=['skyblue' if coeff >= 0 else 'salmon' for coeff in\n",
    "                                                             top_coefs_with_signs['Coefficient']])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Top Statistically Significant Coefficients')\n",
    "plt.show()"
   ],
   "id": "8e1621ed75389387",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PRODUSE_6 is endogenous, since these are respondents who did not select any items in PRODUSE bank.",
   "id": "4e8221efe7113219"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:14:38.565596Z",
     "start_time": "2024-11-08T05:14:38.495262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# take the top coefficients and create a new dataframe\n",
    "top_features = top_coefs_with_signs.index\n",
    "\n",
    "# drop produse_6\n",
    "top_features = top_features.drop('PRODUSE_6_1')\n",
    "\n",
    "X_train_top_features = X_train_scaled[top_features]\n",
    "X_test_top_features = X_test_scaled[top_features]\n",
    "X_train_top_features"
   ],
   "id": "22164219614a80ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      PRODUSE_5_1  MATERIALISM_3_4  PRODHAVE_6_1  FWB2_3_4  PCTLT200FPL_1  \\\n",
       "0             0.0              0.0           1.0       0.0            1.0   \n",
       "1             0.0              0.0           1.0       0.0            1.0   \n",
       "2             0.0              0.0           0.0       0.0            0.0   \n",
       "3             0.0              0.0           0.0       0.0            0.0   \n",
       "4             0.0              1.0           1.0       0.0            0.0   \n",
       "...           ...              ...           ...       ...            ...   \n",
       "5110          1.0              1.0           1.0       0.0            0.0   \n",
       "5111          1.0              0.0           1.0       1.0            1.0   \n",
       "5112          0.0              0.0           0.0       0.0            1.0   \n",
       "5113          0.0              0.0           1.0       0.0            0.0   \n",
       "5114          0.0              1.0           0.0       0.0            0.0   \n",
       "\n",
       "      FINGOALS_0  KHKNOWL1_2  \n",
       "0            0.0         0.0  \n",
       "1            0.0         0.0  \n",
       "2            0.0         1.0  \n",
       "3            0.0         0.0  \n",
       "4            0.0         0.0  \n",
       "...          ...         ...  \n",
       "5110         0.0         0.0  \n",
       "5111         1.0         0.0  \n",
       "5112         1.0         1.0  \n",
       "5113         0.0         0.0  \n",
       "5114         0.0         1.0  \n",
       "\n",
       "[5115 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUSE_5_1</th>\n",
       "      <th>MATERIALISM_3_4</th>\n",
       "      <th>PRODHAVE_6_1</th>\n",
       "      <th>FWB2_3_4</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "      <th>FINGOALS_0</th>\n",
       "      <th>KHKNOWL1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5115 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Building",
   "id": "d95d8b565b832dc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scoring and Cross-Validation",
   "id": "a9f48986580df6d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:20.665468Z",
     "start_time": "2024-11-08T19:52:20.609249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a custom scorer\n",
    "scorer = make_scorer(roc_auc_score)"
   ],
   "id": "90dc4be2e51aa209",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:21.268376Z",
     "start_time": "2024-11-08T19:52:21.231206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a stratified k-fold object to ensure class balance across folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ],
   "id": "e1d1bd52a978f9f7",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression",
   "id": "8875547d2fc4d351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:21.939366Z",
     "start_time": "2024-11-08T19:52:21.914670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)"
   ],
   "id": "524cec388ebd0adc",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:22.221508Z",
     "start_time": "2024-11-08T19:52:22.188890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist_lr = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Regularization type\n",
    "    'C': loguniform(1e-4, 1e4),  # Regularization strength (inverse of alpha)\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],  # Solver options\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],  # ElasticNet mixing (only for 'elasticnet' penalty)\n",
    "    'max_iter': [100, 500, 1000]  # Max iterations\n",
    "}\n"
   ],
   "id": "a81b29a3ad211441",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RandomizedSearchCV",
   "id": "e27a016e25967dcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:53:52.519996Z",
     "start_time": "2024-11-08T19:52:22.690887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform GridSearchCV\n",
    "# Create a GridSearchCV object\n",
    "logit_random_search = RandomizedSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_distributions=param_dist_lr,\n",
    "    n_iter=100,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "logit_random_search.fit(X_train_scaled, y_train_scaled)"
   ],
   "id": "2ea6a6d7799703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "235 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70297792 0.74162053 0.74584877 0.53059075\n",
      "        nan        nan 0.74304093 0.74438378        nan 0.74438378\n",
      " 0.74238829 0.72663562 0.74438378        nan 0.74345683        nan\n",
      " 0.5               nan        nan        nan        nan        nan\n",
      "        nan 0.74207423        nan        nan        nan        nan\n",
      "        nan 0.5        0.74449096 0.5        0.5        0.74434121\n",
      " 0.74340217 0.5        0.6849937  0.74428419 0.72964753        nan\n",
      " 0.74228134        nan        nan        nan        nan 0.73689734\n",
      "        nan        nan 0.5               nan        nan        nan\n",
      "        nan 0.74438378 0.72964753        nan 0.49989282 0.5\n",
      " 0.73188224 0.50168655 0.71693674 0.74626713        nan 0.74171512\n",
      "        nan        nan        nan 0.5               nan 0.5\n",
      " 0.50503236 0.73910708 0.5               nan        nan        nan\n",
      " 0.5        0.74894051        nan        nan 0.72422912        nan\n",
      "        nan 0.54943011 0.5        0.72964753        nan 0.5\n",
      " 0.74423403        nan 0.73938594 0.5               nan 0.70779604\n",
      " 0.7579451  0.5               nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=42), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x38f04d950>,\n",
       "                                        'l1_ratio': [0.1, 0.5, 0.9],\n",
       "                                        'max_iter': [100, 500, 1000],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    'none'],\n",
       "                                        'solver': ['liblinear', 'saga',\n",
       "                                                   'lbfgs']},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(roc_auc_score, response_method='predict'),\n",
       "                   verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=42), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x38f04d950&gt;,\n",
       "                                        &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.9],\n",
       "                                        &#x27;max_iter&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                    &#x27;none&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;,\n",
       "                                                   &#x27;lbfgs&#x27;]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(roc_auc_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=42), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x38f04d950&gt;,\n",
       "                                        &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.9],\n",
       "                                        &#x27;max_iter&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                    &#x27;none&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;,\n",
       "                                                   &#x27;lbfgs&#x27;]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(roc_auc_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.15418349117772073, l1_ratio=0.5, max_iter=500,\n",
       "                   penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;saga&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.15418349117772073, l1_ratio=0.5, max_iter=500,\n",
       "                   penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best Parameters and Best Score",
   "id": "8ab7ad1e1f0ed2aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:53:52.693889Z",
     "start_time": "2024-11-08T19:53:52.562775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Parameters: \", logit_random_search.best_params_)\n",
    "print(\"Best Score: \", logit_random_search.best_score_)"
   ],
   "id": "8b390e6f94c2b2c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.15418349117772073, 'l1_ratio': 0.5, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Score:  0.7579450983371387\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:53:52.882949Z",
     "start_time": "2024-11-08T19:53:52.782028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with the best hyperparameters\n",
    "y_pred_lr_hyper = logit_random_search.predict(X_test_scaled)"
   ],
   "id": "1dc0fb228bdc3f72",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classification Report",
   "id": "b7499306d45c8078"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:53:52.957571Z",
     "start_time": "2024-11-08T19:53:52.923119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_lr_hyper))"
   ],
   "id": "7dc990b639abe1dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1167\n",
      "           1       0.54      0.52      0.53       112\n",
      "\n",
      "    accuracy                           0.92      1279\n",
      "   macro avg       0.75      0.74      0.74      1279\n",
      "weighted avg       0.92      0.92      0.92      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost",
   "id": "1303c63da30789c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:53:53.042528Z",
     "start_time": "2024-11-08T19:53:52.988427Z"
    }
   },
   "cell_type": "code",
   "source": "xgb_model = XGBClassifier(random_state=42)",
   "id": "254d95c2d034bdf",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:53:53.127709Z",
     "start_time": "2024-11-08T19:53:53.100221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter distribution for GridSearchCV\n",
    "param_distributions_xgb = {\n",
    "    'n_estimators': randint(100, 1000),  # Number of boosting rounds\n",
    "    'learning_rate': uniform(0.01, 0.3),  # Step size shrinkage\n",
    "    'max_depth': randint(3, 15),  # Maximum depth of a tree\n",
    "    'min_child_weight': randint(1, 10),  # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'gamma': uniform(0, 0.5),  # Minimum loss reduction to make a split\n",
    "    'subsample': uniform(0.1, 0.9),  # Subsample ratio of the training data\n",
    "    'colsample_bytree': uniform(0.1, 0.9),  # Subsample ratio of columns when constructing each tree\n",
    "    'scale_pos_weight': randint(1, 10),  # Controls the balance of positive and negative classes\n",
    "}"
   ],
   "id": "f7ec186df532afad",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RandomizedSearchCV",
   "id": "1b5759573ff8c773"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:56:12.827096Z",
     "start_time": "2024-11-08T19:53:53.144289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions_xgb,\n",
    "    n_iter=100,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_random_search.fit(X_train, y_train, verbose=False)"
   ],
   "id": "85f66c8003ad48fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importan...\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x35fbe4ed0>,\n",
       "                                        'scale_pos_weight': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x38f0aced0>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x38f079a90>},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(roc_auc_score, response_method='predict'),\n",
       "                   verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importan...\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x35fbe4ed0&gt;,\n",
       "                                        &#x27;scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x38f0aced0&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x38f079a90&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(roc_auc_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importan...\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x35fbe4ed0&gt;,\n",
       "                                        &#x27;scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x38f0aced0&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x38f079a90&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(roc_auc_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7561064512368886, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.38563517334297287,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.03221339552022711,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=9, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=127, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7561064512368886, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.38563517334297287,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.03221339552022711,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=9, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=127, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best Parameters and Best Score",
   "id": "aabbb72d1b6a56a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:56:12.991178Z",
     "start_time": "2024-11-08T19:56:12.908228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Parameters: \", xgb_random_search.best_params_)\n",
    "print(\"Best Score: \", xgb_random_search.best_score_)"
   ],
   "id": "dcd8287cdb3e1a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'colsample_bytree': 0.7561064512368886, 'gamma': 0.38563517334297287, 'learning_rate': 0.03221339552022711, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 127, 'scale_pos_weight': 7, 'subsample': 0.8650347200108194}\n",
      "Best Score:  0.9136334508295224\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:56:13.055112Z",
     "start_time": "2024-11-08T19:56:12.998409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with the best hyperparameters\n",
    "y_pred_xgb_hyper = xgb_random_search.predict(X_test)"
   ],
   "id": "86df415a4daf3016",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classification Report",
   "id": "29d585ba54893191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:56:13.103338Z",
     "start_time": "2024-11-08T19:56:13.070578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_xgb_hyper))"
   ],
   "id": "ba3cb5ff9b12feca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96      1167\n",
      "           1       0.53      0.93      0.68       112\n",
      "\n",
      "    accuracy                           0.92      1279\n",
      "   macro avg       0.76      0.92      0.82      1279\n",
      "weighted avg       0.95      0.92      0.93      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ANN",
   "id": "28b1d2ab1ee0f2b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:02.982952Z",
     "start_time": "2024-11-08T19:50:56.958204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use keras to build an ANN\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout rate of 30%\n",
    "model.add(Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=20)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['AUC'])\n",
    "ann = model.fit(X_train, y_train, epochs=1000, callbacks=[early_stop], validation_split=0.3, verbose=0)\n",
    "model.summary()"
   ],
   "id": "834e7c11bbfb73bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_22\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_87 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │         \u001B[38;5;34m6,544\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │           \u001B[38;5;34m136\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)              │            \u001B[38;5;34m36\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_90 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m5\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m20,165\u001B[0m (78.77 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,165</span> (78.77 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m6,721\u001B[0m (26.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,721</span> (26.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m13,444\u001B[0m (52.52 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,444</span> (52.52 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:03.299198Z",
     "start_time": "2024-11-08T19:52:03.111201Z"
    }
   },
   "cell_type": "code",
   "source": "utils.plot_loss(ann)",
   "id": "129561b3dcb3b04c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classification Report",
   "id": "ea8e3f7c11482559"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:52:06.861124Z",
     "start_time": "2024-11-08T19:52:06.650754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_proba_ann = model.predict(X_test)\n",
    "y_pred_ann = [1 if prob > 0.5 else 0 for prob in y_pred_proba_ann]\n",
    "print(classification_report(y_test, y_pred_ann))"
   ],
   "id": "23af8b16eb56864",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1167\n",
      "           1       0.52      0.42      0.47       112\n",
      "\n",
      "    accuracy                           0.92      1279\n",
      "   macro avg       0.73      0.69      0.71      1279\n",
      "weighted avg       0.91      0.92      0.91      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4202e25786b121b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
