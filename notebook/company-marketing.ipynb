{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Paid Card Marketing (Card Company)",
   "id": "d23dfd07df5dd1ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "32f19a1ea749c7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:41.437164Z",
     "start_time": "2024-11-10T22:35:41.424578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "87737fadcfa28cc6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:47.407983Z",
     "start_time": "2024-11-10T22:35:41.463002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, classification_report, f1_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import utils"
   ],
   "id": "ef6cd793ecbb6e2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:47.506898Z",
     "start_time": "2024-11-10T22:35:47.419870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/Financial Wellness Data.csv')\n",
    "df"
   ],
   "id": "792a4852451d1550",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      PUF_ID  sample  fpl  SWB_1  SWB_2  SWB_3  FWBscore  FWB1_1  FWB1_2  \\\n",
       "0      10350       2    3      5      5      6        55       3       3   \n",
       "1       7740       1    3      6      6      6        51       2       2   \n",
       "2      13699       1    3      4      3      4        49       3       3   \n",
       "3       7267       1    3      6      6      6        49       3       3   \n",
       "4       7375       1    3      4      4      4        49       3       3   \n",
       "...      ...     ...  ...    ...    ...    ...       ...     ...     ...   \n",
       "6389   11220       3    3      6      7      7        61       3       3   \n",
       "6390   13118       3    2      7      7      7        59       3       4   \n",
       "6391    8709       1    3      5      6      6        59       3       4   \n",
       "6392    8515       1    3      5      5      5        46       2       2   \n",
       "6393    8516       3    2      4      6      4        49       3       3   \n",
       "\n",
       "      FWB1_3  ...  PPMSACAT  PPREG4  PPREG9  PPT01  PPT25  PPT612  PPT1317  \\\n",
       "0          3  ...         1       4       8      0      0       0        0   \n",
       "1          3  ...         1       2       3      0      0       0        0   \n",
       "2          3  ...         1       4       9      0      0       0        1   \n",
       "3          3  ...         1       3       7      0      0       0        0   \n",
       "4          3  ...         1       2       4      0      0       1        0   \n",
       "...      ...  ...       ...     ...     ...    ...    ...     ...      ...   \n",
       "6389       1  ...         1       2       3      0      0       0        1   \n",
       "6390       2  ...         1       3       6      0      0       0        0   \n",
       "6391       3  ...         1       1       2      0      0       0        0   \n",
       "6392       3  ...         1       4       9      0      0       0        0   \n",
       "6393       3  ...         0       3       5      0      0       1        0   \n",
       "\n",
       "      PPT18OV  PCTLT200FPL   finalwt  \n",
       "0           1            0  0.367292  \n",
       "1           2            0  1.327561  \n",
       "2           2            1  0.835156  \n",
       "3           1            0  1.410871  \n",
       "4           4            1  4.260668  \n",
       "...       ...          ...       ...  \n",
       "6389        2           -5  0.522504  \n",
       "6390        3           -5  1.015219  \n",
       "6391        2            0  1.136270  \n",
       "6392        2            0  1.224941  \n",
       "6393        2           -5  0.626489  \n",
       "\n",
       "[6394 rows x 217 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUF_ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "      <th>finalwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10350</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7740</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.327561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13699</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7267</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.410871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7375</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.260668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>11220</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.522504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>13118</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.015219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>8709</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>8515</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.224941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>8516</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.626489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 217 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:47.623440Z",
     "start_time": "2024-11-10T22:35:47.567547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find duplicates\n",
    "df[df.duplicated()]"
   ],
   "id": "da3dd49842efe2bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PUF_ID, sample, fpl, SWB_1, SWB_2, SWB_3, FWBscore, FWB1_1, FWB1_2, FWB1_3, FWB1_4, FWB1_5, FWB1_6, FWB2_1, FWB2_2, FWB2_3, FWB2_4, FSscore, FS1_1, FS1_2, FS1_3, FS1_4, FS1_5, FS1_6, FS1_7, FS2_1, FS2_2, FS2_3, SUBKNOWL1, ACT1_1, ACT1_2, FINGOALS, PROPPLAN_1, PROPPLAN_2, PROPPLAN_3, PROPPLAN_4, MANAGE1_1, MANAGE1_2, MANAGE1_3, MANAGE1_4, SAVEHABIT, FRUGALITY, AUTOMATED_1, AUTOMATED_2, ASK1_1, ASK1_2, SUBNUMERACY2, SUBNUMERACY1, CHANGEABLE, GOALCONF, LMscore, FINKNOWL1, FINKNOWL2, FINKNOWL3, FK1correct, FK2correct, FK3correct, KHscore, KHKNOWL1, KHKNOWL2, KHKNOWL3, KHKNOWL4, KHKNOWL5, KHKNOWL6, KHKNOWL7, KHKNOWL8, KHKNOWL9, KH1correct, KH2correct, KH3correct, KH4correct, KH5correct, KH6correct, KH7correct, KH8correct, KH9correct, ENDSMEET, HOUSING, LIVINGARRANGEMENT, HOUSERANGES, IMPUTATION_FLAG, VALUERANGES, MORTGAGE, SAVINGSRANGES, PRODHAVE_1, PRODHAVE_2, PRODHAVE_3, PRODHAVE_4, PRODHAVE_5, PRODHAVE_6, PRODHAVE_7, PRODHAVE_8, PRODHAVE_9, PRODUSE_1, PRODUSE_2, PRODUSE_3, PRODUSE_4, PRODUSE_5, PRODUSE_6, CONSPROTECT1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 217 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUF_ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "      <th>finalwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 217 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:47.757773Z",
     "start_time": "2024-11-10T22:35:47.701508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ],
   "id": "944df5ac1501abbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUF_ID         0\n",
       "sample         0\n",
       "fpl            0\n",
       "SWB_1          0\n",
       "SWB_2          0\n",
       "              ..\n",
       "PPT612         0\n",
       "PPT1317        0\n",
       "PPT18OV        0\n",
       "PCTLT200FPL    0\n",
       "finalwt        0\n",
       "Length: 217, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:47.903584Z",
     "start_time": "2024-11-10T22:35:47.875743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check the data types\n",
    "df.dtypes"
   ],
   "id": "f576bea7448521ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUF_ID           int64\n",
       "sample           int64\n",
       "fpl              int64\n",
       "SWB_1            int64\n",
       "SWB_2            int64\n",
       "                ...   \n",
       "PPT612           int64\n",
       "PPT1317          int64\n",
       "PPT18OV          int64\n",
       "PCTLT200FPL      int64\n",
       "finalwt        float64\n",
       "Length: 217, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:48.104951Z",
     "start_time": "2024-11-10T22:35:48.076143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check if any features have zero variance\n",
    "df.var() == 0"
   ],
   "id": "d25ec616fcb4e729",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUF_ID         False\n",
       "sample         False\n",
       "fpl            False\n",
       "SWB_1          False\n",
       "SWB_2          False\n",
       "               ...  \n",
       "PPT612         False\n",
       "PPT1317        False\n",
       "PPT18OV        False\n",
       "PCTLT200FPL    False\n",
       "finalwt        False\n",
       "Length: 217, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exploratory Data Analysis",
   "id": "a9224405e60a98a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:48.428430Z",
     "start_time": "2024-11-10T22:35:48.300188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Describe the data\n",
    "df.describe()"
   ],
   "id": "3463184112032bba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             PUF_ID       sample          fpl        SWB_1        SWB_2  \\\n",
       "count   6394.000000  6394.000000  6394.000000  6394.000000  6394.000000   \n",
       "mean   10892.392712     1.279794     2.658899     5.353769     5.362215   \n",
       "std     1967.854493     0.570187     0.656944     1.500913     1.544942   \n",
       "min     7123.000000     1.000000     1.000000    -4.000000    -4.000000   \n",
       "25%     9235.250000     1.000000     3.000000     5.000000     5.000000   \n",
       "50%    10901.500000     1.000000     3.000000     6.000000     6.000000   \n",
       "75%    12570.750000     1.000000     3.000000     6.000000     7.000000   \n",
       "max    14400.000000     3.000000     3.000000     7.000000     7.000000   \n",
       "\n",
       "             SWB_3     FWBscore       FWB1_1       FWB1_2       FWB1_3  ...  \\\n",
       "count  6394.000000  6394.000000  6394.000000  6394.000000  6394.000000  ...   \n",
       "mean      5.432280    56.034094     3.048014     3.191899     2.531279  ...   \n",
       "std       1.613876    14.154676     1.235221     1.114130     1.196235  ...   \n",
       "min      -4.000000    -4.000000    -4.000000    -4.000000    -4.000000  ...   \n",
       "25%       5.000000    48.000000     2.000000     3.000000     2.000000  ...   \n",
       "50%       6.000000    56.000000     3.000000     3.000000     2.000000  ...   \n",
       "75%       7.000000    65.000000     4.000000     4.000000     3.000000  ...   \n",
       "max       7.000000    95.000000     5.000000     5.000000     5.000000  ...   \n",
       "\n",
       "          PPMSACAT       PPREG4       PPREG9        PPT01        PPT25  \\\n",
       "count  6394.000000  6394.000000  6394.000000  6394.000000  6394.000000   \n",
       "mean      0.866124     2.644823     5.145605     0.035815     0.078511   \n",
       "std       0.340545     1.032583     2.529397     0.185843     0.268995   \n",
       "min       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "25%       1.000000     2.000000     3.000000     0.000000     0.000000   \n",
       "50%       1.000000     3.000000     5.000000     0.000000     0.000000   \n",
       "75%       1.000000     3.000000     7.000000     0.000000     0.000000   \n",
       "max       1.000000     4.000000     9.000000     1.000000     1.000000   \n",
       "\n",
       "            PPT612      PPT1317      PPT18OV  PCTLT200FPL      finalwt  \n",
       "count  6394.000000  6394.000000  6394.000000  6394.000000  6394.000000  \n",
       "mean      0.129653     0.122928     2.084298    -0.081952     1.000000  \n",
       "std       0.335947     0.328380     0.814345     1.328498     0.585406  \n",
       "min       0.000000     0.000000     1.000000    -5.000000     0.165567  \n",
       "25%       0.000000     0.000000     2.000000     0.000000     0.600582  \n",
       "50%       0.000000     0.000000     2.000000     0.000000     0.845213  \n",
       "75%       0.000000     0.000000     2.000000     0.000000     1.251415  \n",
       "max       1.000000     1.000000     4.000000     1.000000     6.638674  \n",
       "\n",
       "[8 rows x 217 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUF_ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "      <th>finalwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "      <td>6394.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10892.392712</td>\n",
       "      <td>1.279794</td>\n",
       "      <td>2.658899</td>\n",
       "      <td>5.353769</td>\n",
       "      <td>5.362215</td>\n",
       "      <td>5.432280</td>\n",
       "      <td>56.034094</td>\n",
       "      <td>3.048014</td>\n",
       "      <td>3.191899</td>\n",
       "      <td>2.531279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866124</td>\n",
       "      <td>2.644823</td>\n",
       "      <td>5.145605</td>\n",
       "      <td>0.035815</td>\n",
       "      <td>0.078511</td>\n",
       "      <td>0.129653</td>\n",
       "      <td>0.122928</td>\n",
       "      <td>2.084298</td>\n",
       "      <td>-0.081952</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1967.854493</td>\n",
       "      <td>0.570187</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>1.500913</td>\n",
       "      <td>1.544942</td>\n",
       "      <td>1.613876</td>\n",
       "      <td>14.154676</td>\n",
       "      <td>1.235221</td>\n",
       "      <td>1.114130</td>\n",
       "      <td>1.196235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340545</td>\n",
       "      <td>1.032583</td>\n",
       "      <td>2.529397</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>0.268995</td>\n",
       "      <td>0.335947</td>\n",
       "      <td>0.328380</td>\n",
       "      <td>0.814345</td>\n",
       "      <td>1.328498</td>\n",
       "      <td>0.585406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.165567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9235.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10901.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12570.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.251415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.638674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 217 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Engineering",
   "id": "f45b820753314972"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:48.582413Z",
     "start_time": "2024-11-10T22:35:48.555497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into features and target\n",
    "X = df.drop(columns=['PUF_ID', 'PRODUSE_3'])\n",
    "y = df['PRODUSE_3']"
   ],
   "id": "a85c2174fba61a0e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:48.770924Z",
     "start_time": "2024-11-10T22:35:48.716350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop some variables\n",
    "X = X.drop(columns=['finalwt', 'PRODUSE_6'])\n",
    "X"
   ],
   "id": "dcf164d82348823a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      sample  fpl  SWB_1  SWB_2  SWB_3  FWBscore  FWB1_1  FWB1_2  FWB1_3  \\\n",
       "0          2    3      5      5      6        55       3       3       3   \n",
       "1          1    3      6      6      6        51       2       2       3   \n",
       "2          1    3      4      3      4        49       3       3       3   \n",
       "3          1    3      6      6      6        49       3       3       3   \n",
       "4          1    3      4      4      4        49       3       3       3   \n",
       "...      ...  ...    ...    ...    ...       ...     ...     ...     ...   \n",
       "6389       3    3      6      7      7        61       3       3       1   \n",
       "6390       3    2      7      7      7        59       3       4       2   \n",
       "6391       1    3      5      6      6        59       3       4       3   \n",
       "6392       1    3      5      5      5        46       2       2       3   \n",
       "6393       3    2      4      6      4        49       3       3       3   \n",
       "\n",
       "      FWB1_4  ...  PPMARIT  PPMSACAT  PPREG4  PPREG9  PPT01  PPT25  PPT612  \\\n",
       "0          3  ...        3         1       4       8      0      0       0   \n",
       "1          3  ...        3         1       2       3      0      0       0   \n",
       "2          3  ...        3         1       4       9      0      0       0   \n",
       "3          3  ...        3         1       3       7      0      0       0   \n",
       "4          3  ...        1         1       2       4      0      0       1   \n",
       "...      ...  ...      ...       ...     ...     ...    ...    ...     ...   \n",
       "6389       3  ...        1         1       2       3      0      0       0   \n",
       "6390       4  ...        1         1       3       6      0      0       0   \n",
       "6391       3  ...        1         1       1       2      0      0       0   \n",
       "6392       2  ...        5         1       4       9      0      0       0   \n",
       "6393       3  ...        1         0       3       5      0      0       1   \n",
       "\n",
       "      PPT1317  PPT18OV  PCTLT200FPL  \n",
       "0           0        1            0  \n",
       "1           0        2            0  \n",
       "2           1        2            1  \n",
       "3           0        1            0  \n",
       "4           0        4            1  \n",
       "...       ...      ...          ...  \n",
       "6389        1        2           -5  \n",
       "6390        0        3           -5  \n",
       "6391        0        2            0  \n",
       "6392        0        2            0  \n",
       "6393        0        2           -5  \n",
       "\n",
       "[6394 rows x 213 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>fpl</th>\n",
       "      <th>SWB_1</th>\n",
       "      <th>SWB_2</th>\n",
       "      <th>SWB_3</th>\n",
       "      <th>FWBscore</th>\n",
       "      <th>FWB1_1</th>\n",
       "      <th>FWB1_2</th>\n",
       "      <th>FWB1_3</th>\n",
       "      <th>FWB1_4</th>\n",
       "      <th>...</th>\n",
       "      <th>PPMARIT</th>\n",
       "      <th>PPMSACAT</th>\n",
       "      <th>PPREG4</th>\n",
       "      <th>PPREG9</th>\n",
       "      <th>PPT01</th>\n",
       "      <th>PPT25</th>\n",
       "      <th>PPT612</th>\n",
       "      <th>PPT1317</th>\n",
       "      <th>PPT18OV</th>\n",
       "      <th>PCTLT200FPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 213 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:49.127036Z",
     "start_time": "2024-11-10T22:35:48.965435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the distribution of the target variable\n",
    "y.value_counts().plot(kind='bar')"
   ],
   "id": "5985d666b7fa9fce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='PRODUSE_3'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dummify the categorical variables",
   "id": "991fb3c9b83c3b1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:49.470381Z",
     "start_time": "2024-11-10T22:35:49.312233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dummify any integer columns\n",
    "df_categorical = X.astype('object')\n",
    "\n",
    "# dummify the categorical variables\n",
    "X = pd.get_dummies(df_categorical, drop_first=True)\n",
    "X"
   ],
   "id": "5750372aa00eb141",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      sample_2  sample_3  fpl_2  fpl_3  SWB_1_-1  SWB_1_1  SWB_1_2  SWB_1_3  \\\n",
       "0         True     False  False   True     False    False    False    False   \n",
       "1        False     False  False   True     False    False    False    False   \n",
       "2        False     False  False   True     False    False    False    False   \n",
       "3        False     False  False   True     False    False    False    False   \n",
       "4        False     False  False   True     False    False    False    False   \n",
       "...        ...       ...    ...    ...       ...      ...      ...      ...   \n",
       "6389     False      True  False   True     False    False    False    False   \n",
       "6390     False      True   True  False     False    False    False    False   \n",
       "6391     False     False  False   True     False    False    False    False   \n",
       "6392     False     False  False   True     False    False    False    False   \n",
       "6393     False      True   True  False     False    False    False    False   \n",
       "\n",
       "      SWB_1_4  SWB_1_5  ...  PPREG9_9  PPT01_1  PPT25_1  PPT612_1  PPT1317_1  \\\n",
       "0       False     True  ...     False    False    False     False      False   \n",
       "1       False    False  ...     False    False    False     False      False   \n",
       "2        True    False  ...      True    False    False     False       True   \n",
       "3       False    False  ...     False    False    False     False      False   \n",
       "4        True    False  ...     False    False    False      True      False   \n",
       "...       ...      ...  ...       ...      ...      ...       ...        ...   \n",
       "6389    False    False  ...     False    False    False     False       True   \n",
       "6390    False    False  ...     False    False    False     False      False   \n",
       "6391    False     True  ...     False    False    False     False      False   \n",
       "6392    False     True  ...      True    False    False     False      False   \n",
       "6393     True    False  ...     False    False    False      True      False   \n",
       "\n",
       "      PPT18OV_2  PPT18OV_3  PPT18OV_4  PCTLT200FPL_0  PCTLT200FPL_1  \n",
       "0         False      False      False           True          False  \n",
       "1          True      False      False           True          False  \n",
       "2          True      False      False          False           True  \n",
       "3         False      False      False           True          False  \n",
       "4         False      False       True          False           True  \n",
       "...         ...        ...        ...            ...            ...  \n",
       "6389       True      False      False          False          False  \n",
       "6390      False       True      False          False          False  \n",
       "6391       True      False      False           True          False  \n",
       "6392       True      False      False           True          False  \n",
       "6393       True      False      False          False          False  \n",
       "\n",
       "[6394 rows x 991 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>fpl_3</th>\n",
       "      <th>SWB_1_-1</th>\n",
       "      <th>SWB_1_1</th>\n",
       "      <th>SWB_1_2</th>\n",
       "      <th>SWB_1_3</th>\n",
       "      <th>SWB_1_4</th>\n",
       "      <th>SWB_1_5</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT01_1</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_2</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_0</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 991 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:35:49.608139Z",
     "start_time": "2024-11-10T22:35:49.558928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert the one-hot encoded data to integers\n",
    "X = X.astype('float64')\n",
    "X"
   ],
   "id": "9603119c80ac19c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      sample_2  sample_3  fpl_2  fpl_3  SWB_1_-1  SWB_1_1  SWB_1_2  SWB_1_3  \\\n",
       "0          1.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "1          0.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "2          0.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "3          0.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "4          0.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "...        ...       ...    ...    ...       ...      ...      ...      ...   \n",
       "6389       0.0       1.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "6390       0.0       1.0    1.0    0.0       0.0      0.0      0.0      0.0   \n",
       "6391       0.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "6392       0.0       0.0    0.0    1.0       0.0      0.0      0.0      0.0   \n",
       "6393       0.0       1.0    1.0    0.0       0.0      0.0      0.0      0.0   \n",
       "\n",
       "      SWB_1_4  SWB_1_5  ...  PPREG9_9  PPT01_1  PPT25_1  PPT612_1  PPT1317_1  \\\n",
       "0         0.0      1.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "1         0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "2         1.0      0.0  ...       1.0      0.0      0.0       0.0        1.0   \n",
       "3         0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "4         1.0      0.0  ...       0.0      0.0      0.0       1.0        0.0   \n",
       "...       ...      ...  ...       ...      ...      ...       ...        ...   \n",
       "6389      0.0      0.0  ...       0.0      0.0      0.0       0.0        1.0   \n",
       "6390      0.0      0.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "6391      0.0      1.0  ...       0.0      0.0      0.0       0.0        0.0   \n",
       "6392      0.0      1.0  ...       1.0      0.0      0.0       0.0        0.0   \n",
       "6393      1.0      0.0  ...       0.0      0.0      0.0       1.0        0.0   \n",
       "\n",
       "      PPT18OV_2  PPT18OV_3  PPT18OV_4  PCTLT200FPL_0  PCTLT200FPL_1  \n",
       "0           0.0        0.0        0.0            1.0            0.0  \n",
       "1           1.0        0.0        0.0            1.0            0.0  \n",
       "2           1.0        0.0        0.0            0.0            1.0  \n",
       "3           0.0        0.0        0.0            1.0            0.0  \n",
       "4           0.0        0.0        1.0            0.0            1.0  \n",
       "...         ...        ...        ...            ...            ...  \n",
       "6389        1.0        0.0        0.0            0.0            0.0  \n",
       "6390        0.0        1.0        0.0            0.0            0.0  \n",
       "6391        1.0        0.0        0.0            1.0            0.0  \n",
       "6392        1.0        0.0        0.0            1.0            0.0  \n",
       "6393        1.0        0.0        0.0            0.0            0.0  \n",
       "\n",
       "[6394 rows x 991 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>fpl_3</th>\n",
       "      <th>SWB_1_-1</th>\n",
       "      <th>SWB_1_1</th>\n",
       "      <th>SWB_1_2</th>\n",
       "      <th>SWB_1_3</th>\n",
       "      <th>SWB_1_4</th>\n",
       "      <th>SWB_1_5</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT01_1</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_2</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_0</th>\n",
       "      <th>PCTLT200FPL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 991 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove Highly Correlated Features",
   "id": "425f5fd84aeb5e2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:38:43.265307Z",
     "start_time": "2024-11-10T22:35:49.766129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove columns with high multicollinearity\n",
    "X_vif = utils.calculate_vif(X, correlation_threshold=0.85, variance_threshold=0.05)\n",
    "X_vif"
   ],
   "id": "654a84e8c6c13885",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed highly correlated variables: ['EARNERS_2', 'MATHARDSHIP_6_2', 'BENEFITS_2_1', 'SNAP_1', 'MATHARDSHIP_5_2', 'PAIDHELP_0', 'EMPLOY1_2_1', 'FINSOC2_5_1', 'ON1correct_1', 'FK3correct_1', 'KH1correct_1', 'KHKNOWL6_2', 'FINSOC2_1_1', 'REJECTED_2_1', 'KH7correct_1', 'BENEFITS_4_1', 'KH8correct_1', 'FK1correct_1', 'KH5correct_1', 'BENEFITS_1_1', 'PCTLT200FPL_1', 'EMPLOY1_8_1', 'SOCSEC2_-2', 'FINSOC2_7_1', 'KH4correct_1', 'REJECTED_1_1', 'BENEFITS_5_1', 'MILITARY_1', 'KH2correct_1', 'FINSOC2_6_1', 'FK2correct_1', 'KH9correct_1', 'DISCOUNT_2', 'Military_Status_5', 'BENEFITS_3_1', 'EMPLOY1_4_1', 'KHKNOWL4_2', 'FINSOC2_4_1', 'FINSOC2_3_1', 'KHKNOWL5_2', 'FINSOC2_2_1', 'MEMLOSS_1', 'BORROW_1_1', 'KHKNOWL9_2', 'FINGOALS_1', 'KH3correct_1', 'CONSPROTECT3_1', 'BORROW_2_1', 'EMPLOY1_3_1', 'SOCSEC3_-2', 'KH6correct_1', 'FINKNOWL3_2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Removing high VIF and correlated variables', max=505.0, s…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d8c507e69b8432c805c844f9001524f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed variable: PPREG4_4 with VIF: 303483905881195.50\n",
      "Removed variable: FWB2_2_3 with VIF: 3286.93\n",
      "Removed variable: LMscore_3 with VIF: 2024.04\n",
      "Removed variable: FWB1_4_3 with VIF: 1321.79\n",
      "Removed variable: FWB2_1_2 with VIF: 1109.24\n",
      "Removed variable: MANAGE1_3_5 with VIF: 556.76\n",
      "Removed variable: FWB1_5_3 with VIF: 512.32\n",
      "Removed variable: FWB2_4_3 with VIF: 419.39\n",
      "Removed variable: FWB1_1_3 with VIF: 347.08\n",
      "Removed variable: FS1_5_3 with VIF: 276.68\n",
      "Removed variable: FWB1_2_3 with VIF: 262.27\n",
      "Removed variable: KHKNOWL1_3 with VIF: 245.82\n",
      "Removed variable: KHscore_0.712 with VIF: 222.08\n",
      "Removed variable: FINKNOWL2_3 with VIF: 211.52\n",
      "Removed variable: SOCSEC1_1 with VIF: 140.23\n",
      "Removed variable: KIDS_4_0 with VIF: 121.51\n",
      "Removed variable: KHKNOWL2_3 with VIF: 118.16\n",
      "Removed variable: HOUSING_1 with VIF: 89.80\n",
      "Removed variable: DISTRESS_3 with VIF: 73.04\n",
      "Removed variable: KHKNOWL8_2 with VIF: 72.38\n",
      "Removed variable: OUTLOOK_1_4 with VIF: 71.71\n",
      "Removed variable: FRAUD2_0 with VIF: 70.17\n",
      "Removed variable: FINKNOWL1_1 with VIF: 61.53\n",
      "Removed variable: CONSPROTECT2_1 with VIF: 56.17\n",
      "Removed variable: ENDSMEET_1 with VIF: 54.88\n",
      "Removed variable: SUBNUMERACY2_4 with VIF: 40.28\n",
      "Removed variable: generation_4 with VIF: 40.07\n",
      "Removed variable: MANAGE2_3 with VIF: 37.71\n",
      "Removed variable: PAREDUC_2 with VIF: 36.53\n",
      "Removed variable: FS2_1_4 with VIF: 31.63\n",
      "Removed variable: VOLATILITY_1 with VIF: 30.50\n",
      "Removed variable: PROPPLAN_2_4 with VIF: 29.69\n",
      "Removed variable: KHKNOWL3_2 with VIF: 28.75\n",
      "Removed variable: PROPPLAN_3_4 with VIF: 26.07\n",
      "Removed variable: OUTLOOK_2_4 with VIF: 25.98\n",
      "Removed variable: AUTOMATED_1_1 with VIF: 24.76\n",
      "Removed variable: SCFHORIZON_3 with VIF: 24.30\n",
      "Removed variable: ACT1_2_4 with VIF: 24.00\n",
      "Removed variable: FS1_6_4 with VIF: 23.64\n",
      "Removed variable: FS1_1_4 with VIF: 22.51\n",
      "Removed variable: PPHHSIZE_5 with VIF: 21.47\n",
      "Removed variable: AUTOMATED_2_1 with VIF: 19.11\n",
      "Removed variable: FS1_7_4 with VIF: 18.13\n",
      "Removed variable: GOALCONF_4 with VIF: 17.40\n",
      "Removed variable: agecat_6 with VIF: 16.86\n",
      "Removed variable: FS2_2_4 with VIF: 16.34\n",
      "Removed variable: SELFCONTROL_3_3 with VIF: 14.62\n",
      "Removed variable: FS1_4_3 with VIF: 13.37\n",
      "Removed variable: LIVINGARRANGEMENT_2 with VIF: 13.23\n",
      "Removed variable: MATERIALISM_3_2 with VIF: 13.01\n",
      "Removed variable: PROPPLAN_1_4 with VIF: 12.62\n",
      "Removed variable: FWB2_3_1 with VIF: 12.56\n",
      "Removed variable: HHEDUC_5 with VIF: 12.05\n",
      "Removed variable: fpl_3 with VIF: 12.04\n",
      "Removed variable: EMPLOY_8 with VIF: 11.71\n",
      "Removed variable: HOUSING_2 with VIF: 11.43\n",
      "Removed variable: HEALTH_4 with VIF: 10.91\n",
      "Removed variable: MATHARDSHIP_1_1 with VIF: 10.50\n",
      "Removed variable: PPREG4_3 with VIF: 10.46\n",
      "Removed variable: HOUSESAT_4 with VIF: 10.37\n",
      "Removed variable: ACT1_1_5 with VIF: 10.36\n",
      "Removed variable: SELFCONTROL_2_3 with VIF: 10.19\n",
      "Removed variable: KIDS_NoChildren_0 with VIF: 9.94\n",
      "Removed variable: ASK1_1_4 with VIF: 9.93\n",
      "Removed variable: FS1_2_4 with VIF: 9.62\n",
      "Removed variable: CONSPROTECT1_1 with VIF: 9.50\n",
      "Removed variable: FS2_3_2 with VIF: 9.29\n",
      "Removed variable: PPT18OV_2 with VIF: 8.96\n",
      "Removed variable: FS1_3_3 with VIF: 8.51\n",
      "Removed variable: SAVEHABIT_6 with VIF: 8.39\n",
      "Removed variable: SELFCONTROL_1_2 with VIF: 8.37\n",
      "Removed variable: OBJNUMERACY1_2 with VIF: 7.94\n",
      "Removed variable: MANAGE1_1_5 with VIF: 7.93\n",
      "Removed variable: PROPPLAN_4_3 with VIF: 7.90\n",
      "Removed variable: MILITARY_0 with VIF: 7.89\n",
      "Removed variable: FRUGALITY_6 with VIF: 7.80\n",
      "Removed variable: ABSORBSHOCK_4 with VIF: 7.70\n",
      "Removed variable: MANAGE1_2_4 with VIF: 7.55\n",
      "Removed variable: MATHARDSHIP_2_1 with VIF: 7.17\n",
      "Removed variable: MATERIALISM_1_3 with VIF: 7.06\n",
      "Removed variable: KHKNOWL7_4 with VIF: 7.05\n",
      "Removed variable: generation_3 with VIF: 6.97\n",
      "Removed variable: PPEDUC_3 with VIF: 6.88\n",
      "Removed variable: SAVINGSRANGES_5 with VIF: 6.75\n",
      "Removed variable: MATHARDSHIP_4_1 with VIF: 6.33\n",
      "Removed variable: ASK1_2_3 with VIF: 6.03\n",
      "Removed variable: CHANGEABLE_4 with VIF: 5.93\n",
      "Removed variable: KIDS_3_0 with VIF: 5.73\n",
      "Removed variable: COVERCOSTS_2 with VIF: 5.67\n",
      "Removed variable: MORTGAGE_1 with VIF: 5.53\n",
      "Removed variable: SUBNUMERACY1_6 with VIF: 5.48\n",
      "Removed variable: KIDS_1_0 with VIF: 5.41\n",
      "Removed variable: SWB_1_7 with VIF: 5.38\n",
      "Removed variable: PEM_5 with VIF: 5.23\n",
      "Removed variable: KIDS_2_0 with VIF: 5.16\n",
      "Removed variable: HOUSERANGES_5 with VIF: 5.01\n",
      "\n",
      "Removed variables with high VIF:\n",
      "PPREG4_4: 303483905881195.50\n",
      "FWB2_2_3: 3286.93\n",
      "LMscore_3: 2024.04\n",
      "FWB1_4_3: 1321.79\n",
      "FWB2_1_2: 1109.24\n",
      "MANAGE1_3_5: 556.76\n",
      "FWB1_5_3: 512.32\n",
      "FWB2_4_3: 419.39\n",
      "FWB1_1_3: 347.08\n",
      "FS1_5_3: 276.68\n",
      "FWB1_2_3: 262.27\n",
      "KHKNOWL1_3: 245.82\n",
      "KHscore_0.712: 222.08\n",
      "FINKNOWL2_3: 211.52\n",
      "SOCSEC1_1: 140.23\n",
      "KIDS_4_0: 121.51\n",
      "KHKNOWL2_3: 118.16\n",
      "HOUSING_1: 89.80\n",
      "DISTRESS_3: 73.04\n",
      "KHKNOWL8_2: 72.38\n",
      "OUTLOOK_1_4: 71.71\n",
      "FRAUD2_0: 70.17\n",
      "FINKNOWL1_1: 61.53\n",
      "CONSPROTECT2_1: 56.17\n",
      "ENDSMEET_1: 54.88\n",
      "SUBNUMERACY2_4: 40.28\n",
      "generation_4: 40.07\n",
      "MANAGE2_3: 37.71\n",
      "PAREDUC_2: 36.53\n",
      "FS2_1_4: 31.63\n",
      "VOLATILITY_1: 30.50\n",
      "PROPPLAN_2_4: 29.69\n",
      "KHKNOWL3_2: 28.75\n",
      "PROPPLAN_3_4: 26.07\n",
      "OUTLOOK_2_4: 25.98\n",
      "AUTOMATED_1_1: 24.76\n",
      "SCFHORIZON_3: 24.30\n",
      "ACT1_2_4: 24.00\n",
      "FS1_6_4: 23.64\n",
      "FS1_1_4: 22.51\n",
      "PPHHSIZE_5: 21.47\n",
      "AUTOMATED_2_1: 19.11\n",
      "FS1_7_4: 18.13\n",
      "GOALCONF_4: 17.40\n",
      "agecat_6: 16.86\n",
      "FS2_2_4: 16.34\n",
      "SELFCONTROL_3_3: 14.62\n",
      "FS1_4_3: 13.37\n",
      "LIVINGARRANGEMENT_2: 13.23\n",
      "MATERIALISM_3_2: 13.01\n",
      "PROPPLAN_1_4: 12.62\n",
      "FWB2_3_1: 12.56\n",
      "HHEDUC_5: 12.05\n",
      "fpl_3: 12.04\n",
      "EMPLOY_8: 11.71\n",
      "HOUSING_2: 11.43\n",
      "HEALTH_4: 10.91\n",
      "MATHARDSHIP_1_1: 10.50\n",
      "PPREG4_3: 10.46\n",
      "HOUSESAT_4: 10.37\n",
      "ACT1_1_5: 10.36\n",
      "SELFCONTROL_2_3: 10.19\n",
      "KIDS_NoChildren_0: 9.94\n",
      "ASK1_1_4: 9.93\n",
      "FS1_2_4: 9.62\n",
      "CONSPROTECT1_1: 9.50\n",
      "FS2_3_2: 9.29\n",
      "PPT18OV_2: 8.96\n",
      "FS1_3_3: 8.51\n",
      "SAVEHABIT_6: 8.39\n",
      "SELFCONTROL_1_2: 8.37\n",
      "OBJNUMERACY1_2: 7.94\n",
      "MANAGE1_1_5: 7.93\n",
      "PROPPLAN_4_3: 7.90\n",
      "MILITARY_0: 7.89\n",
      "FRUGALITY_6: 7.80\n",
      "ABSORBSHOCK_4: 7.70\n",
      "MANAGE1_2_4: 7.55\n",
      "MATHARDSHIP_2_1: 7.17\n",
      "MATERIALISM_1_3: 7.06\n",
      "KHKNOWL7_4: 7.05\n",
      "generation_3: 6.97\n",
      "PPEDUC_3: 6.88\n",
      "SAVINGSRANGES_5: 6.75\n",
      "MATHARDSHIP_4_1: 6.33\n",
      "ASK1_2_3: 6.03\n",
      "CHANGEABLE_4: 5.93\n",
      "KIDS_3_0: 5.73\n",
      "COVERCOSTS_2: 5.67\n",
      "MORTGAGE_1: 5.53\n",
      "SUBNUMERACY1_6: 5.48\n",
      "KIDS_1_0: 5.41\n",
      "SWB_1_7: 5.38\n",
      "PEM_5: 5.23\n",
      "KIDS_2_0: 5.16\n",
      "HOUSERANGES_5: 5.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      sample_2  sample_3  fpl_2  SWB_1_4  SWB_1_5  SWB_1_6  SWB_2_4  SWB_2_5  \\\n",
       "0          1.0       0.0    0.0      0.0      1.0      0.0      0.0      1.0   \n",
       "1          0.0       0.0    0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "2          0.0       0.0    0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "3          0.0       0.0    0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "4          0.0       0.0    0.0      1.0      0.0      0.0      1.0      0.0   \n",
       "...        ...       ...    ...      ...      ...      ...      ...      ...   \n",
       "6389       0.0       1.0    0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "6390       0.0       1.0    1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "6391       0.0       0.0    0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "6392       0.0       0.0    0.0      0.0      1.0      0.0      0.0      1.0   \n",
       "6393       0.0       1.0    1.0      1.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      SWB_2_6  SWB_2_7  ...  PPREG9_5  PPREG9_7  PPREG9_8  PPREG9_9  PPT25_1  \\\n",
       "0         0.0      0.0  ...       0.0       0.0       1.0       0.0      0.0   \n",
       "1         1.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "2         0.0      0.0  ...       0.0       0.0       0.0       1.0      0.0   \n",
       "3         1.0      0.0  ...       0.0       1.0       0.0       0.0      0.0   \n",
       "4         0.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...      ...   \n",
       "6389      0.0      1.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "6390      0.0      1.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "6391      1.0      0.0  ...       0.0       0.0       0.0       0.0      0.0   \n",
       "6392      0.0      0.0  ...       0.0       0.0       0.0       1.0      0.0   \n",
       "6393      1.0      0.0  ...       1.0       0.0       0.0       0.0      0.0   \n",
       "\n",
       "      PPT612_1  PPT1317_1  PPT18OV_3  PPT18OV_4  PCTLT200FPL_0  \n",
       "0          0.0        0.0        0.0        0.0            1.0  \n",
       "1          0.0        0.0        0.0        0.0            1.0  \n",
       "2          0.0        1.0        0.0        0.0            0.0  \n",
       "3          0.0        0.0        0.0        0.0            1.0  \n",
       "4          1.0        0.0        0.0        1.0            0.0  \n",
       "...        ...        ...        ...        ...            ...  \n",
       "6389       0.0        1.0        0.0        0.0            0.0  \n",
       "6390       0.0        0.0        1.0        0.0            0.0  \n",
       "6391       0.0        0.0        0.0        0.0            1.0  \n",
       "6392       0.0        0.0        0.0        0.0            1.0  \n",
       "6393       1.0        0.0        0.0        0.0            0.0  \n",
       "\n",
       "[6394 rows x 409 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "      <th>fpl_2</th>\n",
       "      <th>SWB_1_4</th>\n",
       "      <th>SWB_1_5</th>\n",
       "      <th>SWB_1_6</th>\n",
       "      <th>SWB_2_4</th>\n",
       "      <th>SWB_2_5</th>\n",
       "      <th>SWB_2_6</th>\n",
       "      <th>SWB_2_7</th>\n",
       "      <th>...</th>\n",
       "      <th>PPREG9_5</th>\n",
       "      <th>PPREG9_7</th>\n",
       "      <th>PPREG9_8</th>\n",
       "      <th>PPREG9_9</th>\n",
       "      <th>PPT25_1</th>\n",
       "      <th>PPT612_1</th>\n",
       "      <th>PPT1317_1</th>\n",
       "      <th>PPT18OV_3</th>\n",
       "      <th>PPT18OV_4</th>\n",
       "      <th>PCTLT200FPL_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 409 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split the Data",
   "id": "58c746770d12d4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:38:43.878046Z",
     "start_time": "2024-11-10T22:38:43.761131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vif, y, test_size=0.2, stratify=y, random_state=42)"
   ],
   "id": "464bbbae65d1f38",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression to Find Important Features",
   "id": "bd2155617d4b81ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:46:26.258665Z",
     "start_time": "2024-11-10T22:38:44.032604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "logit_model_reg = sm.Logit(y_train, X_train_const).fit_regularized(method='l1', alpha=1)\n",
    "print(logit_model_reg.summary())"
   ],
   "id": "29e905fd7bee60d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.2301615715542186\n",
      "            Iterations: 402\n",
      "            Function evaluations: 403\n",
      "            Gradient evaluations: 402\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              PRODUSE_3   No. Observations:                 5115\n",
      "Model:                          Logit   Df Residuals:                     4767\n",
      "Method:                           MLE   Df Model:                          347\n",
      "Date:                Sun, 10 Nov 2024   Pseudo R-squ.:                  0.2622\n",
      "Time:                        17:46:26   Log-Likelihood:                -1120.5\n",
      "converged:                       True   LL-Null:                       -1518.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.322e-37\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    -1.7425      0.813     -2.144      0.032      -3.336      -0.149\n",
      "sample_2                 -0.1645      0.207     -0.795      0.426      -0.570       0.241\n",
      "sample_3                  0.2184      0.221      0.987      0.324      -0.215       0.652\n",
      "fpl_2                    -0.0305      0.177     -0.172      0.863      -0.378       0.317\n",
      "SWB_1_4                   0.0252      0.178      0.141      0.888      -0.325       0.375\n",
      "SWB_1_5                        0        nan        nan        nan         nan         nan\n",
      "SWB_1_6                        0        nan        nan        nan         nan         nan\n",
      "SWB_2_4                        0        nan        nan        nan         nan         nan\n",
      "SWB_2_5                   0.3568      0.181      1.969      0.049       0.002       0.712\n",
      "SWB_2_6                   0.1684      0.198      0.849      0.396      -0.220       0.557\n",
      "SWB_2_7                  -0.0040      0.199     -0.020      0.984      -0.393       0.385\n",
      "SWB_3_4                        0        nan        nan        nan         nan         nan\n",
      "SWB_3_5                  -0.3512      0.175     -2.003      0.045      -0.695      -0.008\n",
      "SWB_3_6                  -0.2293      0.162     -1.414      0.157      -0.547       0.088\n",
      "SWB_3_7                        0        nan        nan        nan         nan         nan\n",
      "FWB1_1_1                 -0.0616      0.237     -0.260      0.795      -0.526       0.402\n",
      "FWB1_1_2                 -0.1306      0.194     -0.672      0.502      -0.512       0.250\n",
      "FWB1_1_4                 -0.0422      0.194     -0.217      0.828      -0.423       0.338\n",
      "FWB1_1_5                 -0.0939      0.279     -0.336      0.737      -0.641       0.453\n",
      "FWB1_2_1                 -0.0030      0.256     -0.012      0.991      -0.504       0.498\n",
      "FWB1_2_2                  0.0555      0.192      0.289      0.772      -0.321       0.432\n",
      "FWB1_2_4                  0.0971      0.193      0.505      0.614      -0.280       0.475\n",
      "FWB1_2_5                  0.2802      0.275      1.019      0.308      -0.259       0.819\n",
      "FWB1_3_1                  0.0564      0.209      0.269      0.788      -0.354       0.467\n",
      "FWB1_3_2                       0        nan        nan        nan         nan         nan\n",
      "FWB1_3_3                 -0.0956      0.177     -0.540      0.589      -0.443       0.251\n",
      "FWB1_3_4                 -0.0252      0.232     -0.108      0.914      -0.481       0.430\n",
      "FWB1_3_5                  0.0337      0.274      0.123      0.902      -0.503       0.571\n",
      "FWB1_4_1                       0        nan        nan        nan         nan         nan\n",
      "FWB1_4_2                  0.0356      0.185      0.192      0.848      -0.327       0.399\n",
      "FWB1_4_4                  0.1672      0.187      0.893      0.372      -0.200       0.534\n",
      "FWB1_4_5                  0.0070      0.286      0.025      0.980      -0.553       0.567\n",
      "FWB1_5_1                       0        nan        nan        nan         nan         nan\n",
      "FWB1_5_2                 -0.1792      0.180     -0.993      0.321      -0.533       0.175\n",
      "FWB1_5_4                  0.2245      0.167      1.342      0.180      -0.103       0.552\n",
      "FWB1_5_5                 -0.0935      0.201     -0.464      0.643      -0.488       0.301\n",
      "FWB1_6_1                  0.0793      0.278      0.285      0.775      -0.466       0.624\n",
      "FWB1_6_2                       0        nan        nan        nan         nan         nan\n",
      "FWB1_6_3                  0.2368      0.188      1.257      0.209      -0.132       0.606\n",
      "FWB1_6_4                 -0.0585      0.233     -0.252      0.801      -0.515       0.398\n",
      "FWB1_6_5                 -0.0488      0.255     -0.191      0.848      -0.549       0.452\n",
      "FWB2_1_1                  0.0626      0.195      0.321      0.748      -0.319       0.445\n",
      "FWB2_1_3                       0        nan        nan        nan         nan         nan\n",
      "FWB2_1_4                 -0.0204      0.212     -0.096      0.923      -0.435       0.394\n",
      "FWB2_1_5                 -0.1709      0.268     -0.637      0.524      -0.697       0.355\n",
      "FWB2_2_1                 -0.0599      0.257     -0.233      0.816      -0.564       0.444\n",
      "FWB2_2_2                 -0.3157      0.189     -1.666      0.096      -0.687       0.056\n",
      "FWB2_2_4                 -0.2969      0.195     -1.521      0.128      -0.680       0.086\n",
      "FWB2_2_5                 -0.2383      0.231     -1.034      0.301      -0.690       0.213\n",
      "FWB2_3_2                 -0.0115      0.148     -0.078      0.938      -0.301       0.278\n",
      "FWB2_3_3                       0        nan        nan        nan         nan         nan\n",
      "FWB2_3_4                  0.5946      0.214      2.775      0.006       0.175       1.015\n",
      "FWB2_4_1                 -0.1797      0.235     -0.766      0.444      -0.640       0.280\n",
      "FWB2_4_2                 -0.0233      0.170     -0.137      0.891      -0.356       0.309\n",
      "FWB2_4_4                 -0.0260      0.188     -0.138      0.890      -0.394       0.342\n",
      "FWB2_4_5                  0.0710      0.245      0.289      0.772      -0.410       0.552\n",
      "FSscore_42               -0.2799      0.271     -1.032      0.302      -0.811       0.252\n",
      "FS1_1_2                   0.0099      0.243      0.041      0.967      -0.466       0.485\n",
      "FS1_1_3                        0        nan        nan        nan         nan         nan\n",
      "FS1_1_5                        0        nan        nan        nan         nan         nan\n",
      "FS1_2_2                  -0.1623      0.230     -0.705      0.481      -0.613       0.289\n",
      "FS1_2_3                   0.0230      0.155      0.148      0.882      -0.281       0.327\n",
      "FS1_2_5                  -0.2924      0.218     -1.342      0.179      -0.719       0.135\n",
      "FS1_3_2                   0.1307      0.187      0.698      0.485      -0.236       0.498\n",
      "FS1_3_4                   0.0276      0.177      0.156      0.876      -0.319       0.374\n",
      "FS1_3_5                   0.0905      0.279      0.325      0.745      -0.456       0.637\n",
      "FS1_4_2                  -0.2870      0.205     -1.399      0.162      -0.689       0.115\n",
      "FS1_4_4                  -0.3029      0.169     -1.787      0.074      -0.635       0.029\n",
      "FS1_4_5                        0        nan        nan        nan         nan         nan\n",
      "FS1_5_1                        0        nan        nan        nan         nan         nan\n",
      "FS1_5_2                  -0.1363      0.177     -0.772      0.440      -0.482       0.210\n",
      "FS1_5_4                  -0.1211      0.178     -0.681      0.496      -0.470       0.227\n",
      "FS1_5_5                  -0.4742      0.321     -1.477      0.140      -1.103       0.155\n",
      "FS1_6_2                  -0.3654      0.287     -1.271      0.204      -0.929       0.198\n",
      "FS1_6_3                  -0.1637      0.166     -0.985      0.325      -0.489       0.162\n",
      "FS1_6_5                  -0.2041      0.205     -0.993      0.321      -0.607       0.199\n",
      "FS1_7_2                   0.2163      0.260      0.833      0.405      -0.293       0.726\n",
      "FS1_7_3                   0.2255      0.177      1.277      0.202      -0.121       0.572\n",
      "FS1_7_5                   0.4289      0.213      2.014      0.044       0.012       0.846\n",
      "FS2_1_2                   0.2748      0.258      1.066      0.286      -0.230       0.780\n",
      "FS2_1_3                  -0.0338      0.157     -0.215      0.830      -0.342       0.274\n",
      "FS2_1_5                  -0.0994      0.207     -0.480      0.631      -0.505       0.307\n",
      "FS2_2_2                   0.1952      0.239      0.817      0.414      -0.273       0.664\n",
      "FS2_2_3                   0.0098      0.158      0.062      0.950      -0.299       0.319\n",
      "FS2_2_5                  -0.0001      0.212     -0.000      1.000      -0.415       0.415\n",
      "FS2_3_1                   0.0645      0.261      0.247      0.805      -0.448       0.576\n",
      "FS2_3_3                   0.2312      0.147      1.577      0.115      -0.056       0.518\n",
      "FS2_3_4                   0.1831      0.203      0.903      0.366      -0.214       0.580\n",
      "SUBKNOWL1_3               0.3444      0.200      1.724      0.085      -0.047       0.736\n",
      "SUBKNOWL1_4                    0        nan        nan        nan         nan         nan\n",
      "SUBKNOWL1_5                    0        nan        nan        nan         nan         nan\n",
      "SUBKNOWL1_6               0.0518      0.185      0.280      0.779      -0.310       0.414\n",
      "ACT1_1_3                  0.2826      0.187      1.509      0.131      -0.084       0.650\n",
      "ACT1_1_4                  0.0119      0.153      0.077      0.938      -0.289       0.312\n",
      "ACT1_2_2                 -0.0161      0.229     -0.070      0.944      -0.465       0.433\n",
      "ACT1_2_3                       0        nan        nan        nan         nan         nan\n",
      "ACT1_2_5                 -0.1311      0.217     -0.605      0.545      -0.556       0.294\n",
      "FINGOALS_0               -0.2994      0.140     -2.146      0.032      -0.573      -0.026\n",
      "PROPPLAN_1_2             -0.1655      0.252     -0.656      0.512      -0.660       0.329\n",
      "PROPPLAN_1_3              0.0489      0.172      0.284      0.776      -0.288       0.386\n",
      "PROPPLAN_1_5              0.1652      0.188      0.878      0.380      -0.204       0.534\n",
      "PROPPLAN_2_2             -0.1289      0.259     -0.498      0.618      -0.636       0.378\n",
      "PROPPLAN_2_3                   0        nan        nan        nan         nan         nan\n",
      "PROPPLAN_2_5              0.2969      0.224      1.323      0.186      -0.143       0.737\n",
      "PROPPLAN_3_2              0.3034      0.271      1.117      0.264      -0.229       0.835\n",
      "PROPPLAN_3_3              0.0118      0.171      0.069      0.945      -0.324       0.348\n",
      "PROPPLAN_3_5             -0.1694      0.234     -0.725      0.469      -0.628       0.289\n",
      "PROPPLAN_4_2             -0.1623      0.204     -0.796      0.426      -0.562       0.237\n",
      "PROPPLAN_4_4              0.4967      0.161      3.089      0.002       0.181       0.812\n",
      "PROPPLAN_4_5              0.0271      0.306      0.089      0.929      -0.573       0.627\n",
      "MANAGE1_1_3              -0.0654      0.227     -0.289      0.773      -0.509       0.379\n",
      "MANAGE1_1_4               0.2470      0.169      1.462      0.144      -0.084       0.578\n",
      "MANAGE1_2_2                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_2_3              -0.0222      0.156     -0.142      0.887      -0.328       0.283\n",
      "MANAGE1_2_5               0.1735      0.174      0.999      0.318      -0.167       0.514\n",
      "MANAGE1_3_1              -0.1763      0.210     -0.839      0.402      -0.588       0.236\n",
      "MANAGE1_3_2              -0.1295      0.242     -0.536      0.592      -0.603       0.344\n",
      "MANAGE1_3_3               0.2411      0.207      1.166      0.244      -0.164       0.647\n",
      "MANAGE1_3_4              -0.3162      0.218     -1.452      0.147      -0.743       0.111\n",
      "MANAGE1_4_3                    0        nan        nan        nan         nan         nan\n",
      "MANAGE1_4_4               0.1606      0.178      0.902      0.367      -0.189       0.510\n",
      "MANAGE1_4_5              -0.0440      0.183     -0.240      0.810      -0.403       0.315\n",
      "SAVEHABIT_2                    0        nan        nan        nan         nan         nan\n",
      "SAVEHABIT_3              -0.3389      0.215     -1.578      0.115      -0.760       0.082\n",
      "SAVEHABIT_4               0.0604      0.175      0.345      0.730      -0.283       0.404\n",
      "SAVEHABIT_5              -0.0141      0.163     -0.086      0.931      -0.334       0.306\n",
      "FRUGALITY_4              -0.1462      0.201     -0.729      0.466      -0.539       0.247\n",
      "FRUGALITY_5              -0.0900      0.139     -0.646      0.518      -0.363       0.183\n",
      "AUTOMATED_1_0            -0.1942      0.178     -1.089      0.276      -0.544       0.155\n",
      "AUTOMATED_1_7            -0.2350      0.214     -1.100      0.271      -0.654       0.184\n",
      "AUTOMATED_2_0            -0.0296      0.153     -0.194      0.846      -0.329       0.269\n",
      "AUTOMATED_2_7            -0.0194      0.194     -0.100      0.920      -0.399       0.360\n",
      "ASK1_1_2                  0.1970      0.242      0.814      0.416      -0.277       0.671\n",
      "ASK1_1_3                  0.1455      0.153      0.948      0.343      -0.155       0.446\n",
      "ASK1_1_5                  0.0753      0.169      0.445      0.657      -0.257       0.407\n",
      "ASK1_2_1                 -0.0208      0.209     -0.099      0.921      -0.431       0.389\n",
      "ASK1_2_2                 -0.0597      0.166     -0.360      0.719      -0.385       0.265\n",
      "ASK1_2_4                  0.1471      0.161      0.916      0.360      -0.168       0.462\n",
      "SUBNUMERACY2_1           -0.2230      0.192     -1.160      0.246      -0.600       0.154\n",
      "SUBNUMERACY2_2           -0.1784      0.243     -0.735      0.462      -0.654       0.297\n",
      "SUBNUMERACY2_3           -0.1058      0.179     -0.590      0.556      -0.457       0.246\n",
      "SUBNUMERACY2_5            0.0299      0.201      0.149      0.882      -0.363       0.423\n",
      "SUBNUMERACY2_6           -0.2195      0.204     -1.075      0.282      -0.620       0.181\n",
      "SUBNUMERACY1_1            0.1364      0.233      0.586      0.558      -0.319       0.592\n",
      "SUBNUMERACY1_3                 0        nan        nan        nan         nan         nan\n",
      "SUBNUMERACY1_4           -0.1431      0.139     -1.031      0.303      -0.415       0.129\n",
      "SUBNUMERACY1_5                 0        nan        nan        nan         nan         nan\n",
      "CHANGEABLE_1                   0        nan        nan        nan         nan         nan\n",
      "CHANGEABLE_2             -0.1063      0.192     -0.552      0.581      -0.484       0.271\n",
      "CHANGEABLE_3             -0.1162      0.192     -0.605      0.545      -0.493       0.260\n",
      "CHANGEABLE_5             -0.0200      0.166     -0.121      0.904      -0.346       0.306\n",
      "CHANGEABLE_6              0.0840      0.195      0.432      0.666      -0.297       0.465\n",
      "GOALCONF_2                0.1147      0.187      0.612      0.541      -0.253       0.482\n",
      "GOALCONF_3                     0        nan        nan        nan         nan         nan\n",
      "LMscore_1                 0.1141      0.251      0.455      0.649      -0.377       0.605\n",
      "LMscore_2                -0.0194      0.165     -0.118      0.906      -0.343       0.304\n",
      "FINKNOWL1_2                    0        nan        nan        nan         nan         nan\n",
      "FINKNOWL1_3                    0        nan        nan        nan         nan         nan\n",
      "FINKNOWL2_1              -0.1736      0.226     -0.768      0.442      -0.617       0.269\n",
      "FINKNOWL2_2              -0.1858      0.204     -0.912      0.362      -0.585       0.214\n",
      "FINKNOWL3_1              -0.0157      0.177     -0.089      0.929      -0.363       0.331\n",
      "KHscore_-1.215            0.0519      0.225      0.231      0.817      -0.388       0.492\n",
      "KHscore_-0.909            0.3294      0.189      1.742      0.082      -0.041       0.700\n",
      "KHscore_-0.57                  0        nan        nan        nan         nan         nan\n",
      "KHscore_-0.188           -0.0120      0.188     -0.064      0.949      -0.380       0.356\n",
      "KHscore_0.242             0.0934      0.195      0.479      0.632      -0.289       0.476\n",
      "KHscore_1.267             0.0704      0.310      0.227      0.820      -0.537       0.678\n",
      "KHKNOWL1_1                0.0306      0.207      0.148      0.882      -0.375       0.436\n",
      "KHKNOWL1_2                0.2591      0.138      1.871      0.061      -0.012       0.530\n",
      "KHKNOWL2_1                0.1172      0.217      0.541      0.589      -0.308       0.542\n",
      "KHKNOWL2_2                0.0363      0.198      0.184      0.854      -0.351       0.424\n",
      "KHKNOWL3_1                0.4085      0.159      2.562      0.010       0.096       0.721\n",
      "KHKNOWL3_3                0.0444      0.180      0.246      0.805      -0.309       0.398\n",
      "KHKNOWL4_1               -0.1488      0.150     -0.990      0.322      -0.443       0.146\n",
      "KHKNOWL5_1               -0.1428      0.136     -1.049      0.294      -0.410       0.124\n",
      "KHKNOWL6_1               -0.0169      0.196     -0.086      0.931      -0.402       0.368\n",
      "KHKNOWL7_2                0.1015      0.154      0.660      0.509      -0.200       0.403\n",
      "KHKNOWL7_3               -0.2103      0.151     -1.393      0.164      -0.506       0.086\n",
      "KHKNOWL8_1               -0.0319      0.166     -0.192      0.847      -0.357       0.293\n",
      "KHKNOWL8_3               -0.2077      0.203     -1.025      0.305      -0.605       0.190\n",
      "KHKNOWL8_4                0.1717      0.172      1.000      0.317      -0.165       0.508\n",
      "KHKNOWL9_1                0.1661      0.176      0.944      0.345      -0.179       0.511\n",
      "ENDSMEET_2                0.0035      0.174      0.020      0.984      -0.337       0.344\n",
      "ENDSMEET_3                0.2543      0.260      0.978      0.328      -0.255       0.764\n",
      "HOUSING_3                 0.1510      0.220      0.686      0.493      -0.281       0.583\n",
      "LIVINGARRANGEMENT_1      -0.1527      0.218     -0.700      0.484      -0.580       0.275\n",
      "LIVINGARRANGEMENT_3            0        nan        nan        nan         nan         nan\n",
      "LIVINGARRANGEMENT_4            0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_1            -0.1383      0.196     -0.705      0.481      -0.523       0.246\n",
      "HOUSERANGES_2                  0        nan        nan        nan         nan         nan\n",
      "HOUSERANGES_3             0.0054      0.185      0.029      0.977      -0.356       0.367\n",
      "HOUSERANGES_4             0.1431      0.189      0.756      0.450      -0.228       0.514\n",
      "HOUSERANGES_6            -0.3470      0.291     -1.194      0.232      -0.917       0.222\n",
      "HOUSERANGES_7             0.0746      0.291      0.257      0.797      -0.495       0.644\n",
      "HOUSERANGES_99           -0.1490      0.256     -0.582      0.560      -0.650       0.352\n",
      "IMPUTATION_FLAG_1         0.1103      0.211      0.522      0.602      -0.304       0.524\n",
      "VALUERANGES_1            -0.1512      0.202     -0.750      0.453      -0.546       0.244\n",
      "VALUERANGES_2            -0.1325      0.227     -0.584      0.559      -0.577       0.312\n",
      "VALUERANGES_3            -0.0464      0.232     -0.200      0.842      -0.502       0.409\n",
      "VALUERANGES_4                  0        nan        nan        nan         nan         nan\n",
      "MORTGAGE_2               -0.4692      0.214     -2.195      0.028      -0.888      -0.050\n",
      "MORTGAGE_3               -0.2785      0.321     -0.868      0.385      -0.907       0.350\n",
      "MORTGAGE_99               0.1442      0.271      0.533      0.594      -0.386       0.674\n",
      "SAVINGSRANGES_1           0.5182      0.242      2.142      0.032       0.044       0.992\n",
      "SAVINGSRANGES_2           0.2378      0.260      0.915      0.360      -0.272       0.747\n",
      "SAVINGSRANGES_3           0.0319      0.207      0.154      0.877      -0.374       0.438\n",
      "SAVINGSRANGES_4          -0.0121      0.199     -0.060      0.952      -0.403       0.379\n",
      "SAVINGSRANGES_6                0        nan        nan        nan         nan         nan\n",
      "SAVINGSRANGES_7           0.2596      0.242      1.074      0.283      -0.214       0.733\n",
      "SAVINGSRANGES_99               0        nan        nan        nan         nan         nan\n",
      "PRODHAVE_1_1             -0.5367      0.156     -3.442      0.001      -0.842      -0.231\n",
      "PRODHAVE_2_1             -0.2691      0.141     -1.911      0.056      -0.545       0.007\n",
      "PRODHAVE_3_1              0.1139      0.145      0.783      0.434      -0.171       0.399\n",
      "PRODHAVE_4_1             -0.2062      0.179     -1.154      0.248      -0.556       0.144\n",
      "PRODHAVE_5_1              0.1896      0.181      1.050      0.294      -0.164       0.543\n",
      "PRODHAVE_6_1              0.4640      0.173      2.682      0.007       0.125       0.803\n",
      "PRODHAVE_7_1             -0.1242      0.305     -0.407      0.684      -0.723       0.474\n",
      "PRODHAVE_8_1             -0.0538      0.186     -0.290      0.772      -0.418       0.310\n",
      "PRODUSE_5_1              -0.0150      0.197     -0.076      0.939      -0.400       0.370\n",
      "CONSPROTECT1_2                 0        nan        nan        nan         nan         nan\n",
      "CONSPROTECT1_3         2.065e-17      0.158    1.3e-16      1.000      -0.310       0.310\n",
      "CONSPROTECT2_2            0.2853      0.132      2.164      0.030       0.027       0.544\n",
      "CONSPROTECT2_3            0.4851      0.222      2.182      0.029       0.049       0.921\n",
      "CONSPROTECT3_0            0.0330      0.211      0.156      0.876      -0.380       0.446\n",
      "EARNERS_1                -0.0456      0.153     -0.298      0.766      -0.345       0.254\n",
      "EARNERS_3                -0.2316      0.256     -0.905      0.365      -0.733       0.270\n",
      "VOLATILITY_2              0.2037      0.144      1.419      0.156      -0.078       0.485\n",
      "VOLATILITY_3              0.0995      0.214      0.466      0.641      -0.319       0.518\n",
      "SNAP_0                   -0.2407      0.173     -1.391      0.164      -0.580       0.099\n",
      "MATHARDSHIP_1_2           0.3504      0.191      1.837      0.066      -0.023       0.724\n",
      "MATHARDSHIP_2_2           0.0031      0.204      0.015      0.988      -0.398       0.404\n",
      "MATHARDSHIP_3_1                0        nan        nan        nan         nan         nan\n",
      "MATHARDSHIP_3_2           0.0196      0.219      0.090      0.928      -0.409       0.449\n",
      "MATHARDSHIP_4_2          -0.1638      0.183     -0.897      0.370      -0.522       0.194\n",
      "MATHARDSHIP_5_1           0.1707      0.177      0.965      0.335      -0.176       0.517\n",
      "MATHARDSHIP_6_1                0        nan        nan        nan         nan         nan\n",
      "COLLECT_0                -0.0789      0.250     -0.316      0.752      -0.568       0.410\n",
      "COLLECT_1                 0.1065      0.272      0.392      0.695      -0.426       0.639\n",
      "REJECTED_1_0                   0        nan        nan        nan         nan         nan\n",
      "REJECTED_2_0             -0.2249      0.167     -1.350      0.177      -0.551       0.102\n",
      "ABSORBSHOCK_1            -0.0081      0.224     -0.036      0.971      -0.448       0.432\n",
      "ABSORBSHOCK_2             0.1319      0.236      0.560      0.576      -0.330       0.594\n",
      "ABSORBSHOCK_3             0.2317      0.182      1.276      0.202      -0.124       0.588\n",
      "BENEFITS_1_0             -0.3039      0.154     -1.973      0.049      -0.606      -0.002\n",
      "BENEFITS_2_0              0.0933      0.175      0.534      0.594      -0.249       0.436\n",
      "BENEFITS_3_0             -0.1452      0.172     -0.845      0.398      -0.482       0.192\n",
      "BENEFITS_4_0              0.6004      0.207      2.896      0.004       0.194       1.007\n",
      "BENEFITS_5_0              0.2387      0.179      1.334      0.182      -0.112       0.589\n",
      "FRAUD2_1                  0.2322      0.143      1.623      0.105      -0.048       0.513\n",
      "FRAUD2_8                 -0.1776      0.208     -0.855      0.393      -0.585       0.230\n",
      "COVERCOSTS_1              0.1209      0.154      0.784      0.433      -0.181       0.423\n",
      "COVERCOSTS_3             -0.0308      0.180     -0.171      0.864      -0.384       0.323\n",
      "BORROW_1_0               -0.1303      0.125     -1.041      0.298      -0.376       0.115\n",
      "BORROW_2_0               -0.1292      0.126     -1.025      0.306      -0.376       0.118\n",
      "SHOCKS_1_1                0.0640      0.218      0.293      0.769      -0.364       0.492\n",
      "SHOCKS_2_1                     0        nan        nan        nan         nan         nan\n",
      "SHOCKS_4_1                0.1864      0.157      1.187      0.235      -0.121       0.494\n",
      "SHOCKS_5_1                0.2099      0.168      1.249      0.211      -0.119       0.539\n",
      "SHOCKS_9_1                0.0715      0.263      0.272      0.785      -0.443       0.586\n",
      "SHOCKS_11_1               0.0089      0.177      0.050      0.960      -0.338       0.356\n",
      "SHOCKS_12_1              -0.3361      0.174     -1.930      0.054      -0.677       0.005\n",
      "MANAGE2_1                -0.0078      0.204     -0.038      0.970      -0.408       0.393\n",
      "MANAGE2_2                 0.0393      0.150      0.263      0.793      -0.254       0.333\n",
      "HSLOC_1                  -0.3270      0.177     -1.847      0.065      -0.674       0.020\n",
      "HSLOC_2                  -0.2641      0.301     -0.876      0.381      -0.855       0.327\n",
      "PAREDUC_1                -0.2097      0.203     -1.035      0.301      -0.607       0.188\n",
      "PAREDUC_3                 0.0034      0.166      0.020      0.984      -0.322       0.328\n",
      "PAREDUC_4                 0.2019      0.224      0.903      0.366      -0.236       0.640\n",
      "PAREDUC_5                      0        nan        nan        nan         nan         nan\n",
      "FINSOC2_1_0               0.1386      0.150      0.925      0.355      -0.155       0.432\n",
      "FINSOC2_2_0               0.0204      0.161      0.126      0.899      -0.296       0.336\n",
      "FINSOC2_3_0               0.0908      0.151      0.602      0.547      -0.205       0.386\n",
      "FINSOC2_4_0              -0.2366      0.155     -1.527      0.127      -0.540       0.067\n",
      "FINSOC2_5_0              -0.2149      0.172     -1.247      0.212      -0.553       0.123\n",
      "FINSOC2_6_0              -0.0569      0.135     -0.423      0.672      -0.321       0.207\n",
      "FINSOC2_7_0               0.0179      0.145      0.124      0.902      -0.266       0.302\n",
      "OBJNUMERACY1_1            0.2541      0.196      1.299      0.194      -0.129       0.637\n",
      "OBJNUMERACY1_3            0.3916      0.169      2.316      0.021       0.060       0.723\n",
      "ON2correct_1             -0.2385      0.132     -1.806      0.071      -0.497       0.020\n",
      "MATERIALISM_1_1          -0.0102      0.212     -0.048      0.962      -0.426       0.406\n",
      "MATERIALISM_1_2          -0.1080      0.161     -0.670      0.503      -0.424       0.208\n",
      "MATERIALISM_1_4          -0.1561      0.185     -0.842      0.400      -0.520       0.207\n",
      "MATERIALISM_2_1           0.4247      0.252      1.688      0.091      -0.069       0.918\n",
      "MATERIALISM_2_2                0        nan        nan        nan         nan         nan\n",
      "MATERIALISM_2_3          -0.0318      0.158     -0.201      0.841      -0.342       0.278\n",
      "MATERIALISM_2_4          -0.0293      0.176     -0.166      0.868      -0.375       0.316\n",
      "MATERIALISM_3_1          -0.3775      0.199     -1.898      0.058      -0.767       0.012\n",
      "MATERIALISM_3_3          -0.2676      0.156     -1.715      0.086      -0.573       0.038\n",
      "MATERIALISM_3_4          -0.4230      0.230     -1.836      0.066      -0.875       0.029\n",
      "CONNECT_50               -0.1033      0.176     -0.587      0.557      -0.448       0.242\n",
      "CONNECT_75                     0        nan        nan        nan         nan         nan\n",
      "CONNECT_80               -0.3118      0.254     -1.228      0.220      -0.810       0.186\n",
      "CONNECT_90               -0.3015      0.232     -1.297      0.195      -0.757       0.154\n",
      "CONNECT_100              -0.2955      0.171     -1.731      0.084      -0.630       0.039\n",
      "HEALTH_2                  0.3565      0.186      1.913      0.056      -0.009       0.722\n",
      "HEALTH_3                  0.0800      0.139      0.574      0.566      -0.193       0.353\n",
      "HEALTH_5              -2.984e-17      0.221  -1.35e-16      1.000      -0.433       0.433\n",
      "SCFHORIZON_1              0.1934      0.173      1.117      0.264      -0.146       0.533\n",
      "SCFHORIZON_2             -0.1010      0.190     -0.532      0.594      -0.473       0.271\n",
      "SCFHORIZON_4              0.1587      0.171      0.928      0.353      -0.177       0.494\n",
      "SCFHORIZON_5              0.0346      0.207      0.167      0.867      -0.371       0.440\n",
      "DISCOUNT_1                0.2157      0.129      1.676      0.094      -0.037       0.468\n",
      "MEMLOSS_0                -0.0202      0.176     -0.114      0.909      -0.365       0.325\n",
      "DISTRESS_1                     0        nan        nan        nan         nan         nan\n",
      "DISTRESS_2                0.1087      0.165      0.661      0.509      -0.214       0.431\n",
      "DISTRESS_4                0.1220      0.145      0.842      0.400      -0.162       0.406\n",
      "DISTRESS_5                     0        nan        nan        nan         nan         nan\n",
      "SELFCONTROL_1_1           0.0342      0.148      0.231      0.817      -0.255       0.324\n",
      "SELFCONTROL_1_3           0.1641      0.152      1.077      0.281      -0.135       0.463\n",
      "SELFCONTROL_2_2                0        nan        nan        nan         nan         nan\n",
      "SELFCONTROL_2_4          -0.0224      0.179     -0.125      0.900      -0.373       0.329\n",
      "SELFCONTROL_3_2           0.1712      0.173      0.991      0.321      -0.167       0.510\n",
      "SELFCONTROL_3_4          -0.0067      0.176     -0.038      0.970      -0.352       0.339\n",
      "OUTLOOK_1_1               0.3881      0.265      1.465      0.143      -0.131       0.908\n",
      "OUTLOOK_1_2                    0        nan        nan        nan         nan         nan\n",
      "OUTLOOK_1_3               0.0142      0.152      0.094      0.925      -0.284       0.313\n",
      "OUTLOOK_1_5               0.4351      0.169      2.579      0.010       0.104       0.766\n",
      "OUTLOOK_2_1              -0.0566      0.257     -0.221      0.825      -0.560       0.447\n",
      "OUTLOOK_2_2               0.3130      0.213      1.469      0.142      -0.104       0.730\n",
      "OUTLOOK_2_3               0.2476      0.168      1.474      0.141      -0.082       0.577\n",
      "OUTLOOK_2_5               0.1370      0.192      0.713      0.476      -0.240       0.514\n",
      "INTERCONNECTIONS_1_1     -0.0891      0.167     -0.532      0.595      -0.417       0.239\n",
      "INTERCONNECTIONS_2_1      0.0169      0.157      0.108      0.914      -0.290       0.324\n",
      "INTERCONNECTIONS_3_1      0.1154      0.168      0.688      0.492      -0.213       0.444\n",
      "INTERCONNECTIONS_4_1      0.2275      0.245      0.928      0.353      -0.253       0.708\n",
      "INTERCONNECTIONS_5_1      0.0307      0.150      0.205      0.838      -0.263       0.325\n",
      "INTERCONNECTIONS_7_1      0.0595      0.161      0.369      0.712      -0.257       0.376\n",
      "INTERCONNECTIONS_8_1     -0.0092      0.168     -0.055      0.956      -0.338       0.320\n",
      "INTERCONNECTIONS_10_1    -0.2314      0.201     -1.151      0.250      -0.626       0.163\n",
      "PEM_2                    -0.0551      0.242     -0.228      0.820      -0.529       0.419\n",
      "PEM_3                          0        nan        nan        nan         nan         nan\n",
      "PEM_4                    -0.3186      0.210     -1.519      0.129      -0.730       0.093\n",
      "PEM_6                     0.0280      0.159      0.177      0.860      -0.283       0.339\n",
      "PEM_7                     0.1732      0.196      0.882      0.378      -0.212       0.558\n",
      "HOUSESAT_2                0.0527      0.208      0.254      0.800      -0.355       0.460\n",
      "HOUSESAT_3                0.0377      0.136      0.278      0.781      -0.229       0.304\n",
      "SOCSEC1_0                 0.3131      0.323      0.968      0.333      -0.321       0.947\n",
      "SOCSEC2_62                0.0581      0.264      0.220      0.826      -0.460       0.576\n",
      "SOCSEC2_65                0.0617      0.280      0.220      0.826      -0.488       0.611\n",
      "SOCSEC3_61                0.0564      0.228      0.247      0.805      -0.391       0.504\n",
      "SOCSEC3_62                0.0093      0.282      0.033      0.974      -0.543       0.562\n",
      "SOCSEC3_65               -0.0570      0.185     -0.308      0.758      -0.420       0.306\n",
      "SOCSEC3_67               -0.3403      0.317     -1.074      0.283      -0.961       0.281\n",
      "SOCSEC3_70                     0        nan        nan        nan         nan         nan\n",
      "SOCSEC3_71                0.1559      0.256      0.608      0.543      -0.347       0.658\n",
      "LIFEEXPECT_50            -0.0267      0.176     -0.151      0.880      -0.372       0.319\n",
      "LIFEEXPECT_75            -0.1580      0.281     -0.562      0.574      -0.709       0.393\n",
      "LIFEEXPECT_80                  0        nan        nan        nan         nan         nan\n",
      "LIFEEXPECT_90                  0        nan        nan        nan         nan         nan\n",
      "LIFEEXPECT_100                 0        nan        nan        nan         nan         nan\n",
      "HHEDUC_2                 -0.0218      0.193     -0.113      0.910      -0.401       0.357\n",
      "HHEDUC_3                 -0.0627      0.174     -0.359      0.720      -0.405       0.279\n",
      "HHEDUC_4                       0        nan        nan        nan         nan         nan\n",
      "KIDS_NoChildren_1         0.0784      0.169      0.464      0.642      -0.253       0.409\n",
      "KIDS_1_1                  0.0401      0.257      0.156      0.876      -0.463       0.544\n",
      "KIDS_2_1                  0.0270      0.232      0.116      0.907      -0.428       0.483\n",
      "KIDS_3_1                       0        nan        nan        nan         nan         nan\n",
      "KIDS_4_1                  0.1887      0.245      0.771      0.440      -0.291       0.668\n",
      "KIDS_4_2                  0.2228      0.299      0.746      0.455      -0.362       0.808\n",
      "EMPLOY_2                  0.0500      0.200      0.250      0.803      -0.342       0.442\n",
      "EMPLOY_3                  0.2484      0.238      1.045      0.296      -0.217       0.714\n",
      "EMPLOY_4                 -0.3457      0.297     -1.165      0.244      -0.928       0.236\n",
      "EMPLOY1_1_1               0.1934      0.229      0.845      0.398      -0.255       0.642\n",
      "RETIRE_1                 -0.2966      0.268     -1.105      0.269      -0.823       0.229\n",
      "RETIRE_2                 -0.2117      0.267     -0.793      0.428      -0.735       0.311\n",
      "Military_Status_2         0.1278      0.214      0.597      0.551      -0.292       0.547\n",
      "Military_Status_4         0.1455      0.284      0.512      0.608      -0.411       0.702\n",
      "agecat_2                  0.4625      0.236      1.962      0.050       0.000       0.925\n",
      "agecat_3                 -0.0115      0.265     -0.043      0.966      -0.531       0.508\n",
      "agecat_4                  0.0086      0.254      0.034      0.973      -0.489       0.506\n",
      "agecat_5                 -0.1977      0.310     -0.638      0.524      -0.805       0.410\n",
      "agecat_7                       0        nan        nan        nan         nan         nan\n",
      "agecat_8                  0.3774      0.275      1.375      0.169      -0.161       0.915\n",
      "generation_2             -0.0450      0.212     -0.212      0.832      -0.461       0.371\n",
      "PPEDUC_2                       0        nan        nan        nan         nan         nan\n",
      "PPEDUC_4                 -0.2984      0.239     -1.251      0.211      -0.766       0.169\n",
      "PPEDUC_5                 -0.1088      0.235     -0.462      0.644      -0.570       0.352\n",
      "PPETHM_2                  0.1448      0.188      0.772      0.440      -0.223       0.513\n",
      "PPETHM_4                       0        nan        nan        nan         nan         nan\n",
      "PPGENDER_2               -0.2540      0.139     -1.829      0.067      -0.526       0.018\n",
      "PPHHSIZE_2               -0.2252      0.179     -1.259      0.208      -0.576       0.125\n",
      "PPHHSIZE_3                0.1294      0.214      0.604      0.546      -0.290       0.549\n",
      "PPHHSIZE_4               -0.0952      0.209     -0.455      0.649      -0.505       0.315\n",
      "PPINCIMP_2                0.1713      0.222      0.773      0.440      -0.263       0.606\n",
      "PPINCIMP_3                0.0266      0.209      0.128      0.898      -0.382       0.435\n",
      "PPINCIMP_4               -0.0501      0.233     -0.215      0.830      -0.507       0.407\n",
      "PPINCIMP_5                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_6               -0.0910      0.221     -0.412      0.680      -0.523       0.341\n",
      "PPINCIMP_7               -0.0875      0.201     -0.435      0.664      -0.482       0.307\n",
      "PPINCIMP_8                     0        nan        nan        nan         nan         nan\n",
      "PPINCIMP_9               -0.7226      0.284     -2.541      0.011      -1.280      -0.165\n",
      "PPMARIT_2                 0.2848      0.292      0.977      0.329      -0.287       0.856\n",
      "PPMARIT_3                 0.2613      0.216      1.211      0.226      -0.161       0.684\n",
      "PPMARIT_4                 0.1471      0.223      0.660      0.509      -0.289       0.584\n",
      "PPMARIT_5                 0.0405      0.263      0.154      0.878      -0.475       0.556\n",
      "PPMSACAT_1               -0.1555      0.182     -0.857      0.392      -0.511       0.200\n",
      "PPREG4_2                       0        nan        nan        nan         nan         nan\n",
      "PPREG9_2                 -0.0164      0.207     -0.079      0.937      -0.422       0.389\n",
      "PPREG9_3                 -0.2919      0.206     -1.420      0.156      -0.695       0.111\n",
      "PPREG9_4                  0.2401      0.258      0.932      0.351      -0.265       0.745\n",
      "PPREG9_5                  0.0232      0.177      0.131      0.896      -0.324       0.370\n",
      "PPREG9_7                       0        nan        nan        nan         nan         nan\n",
      "PPREG9_8                 -0.5693      0.284     -2.004      0.045      -1.126      -0.012\n",
      "PPREG9_9                 -0.3661      0.207     -1.768      0.077      -0.772       0.040\n",
      "PPT25_1                  -0.2575      0.253     -1.016      0.310      -0.754       0.239\n",
      "PPT612_1                       0        nan        nan        nan         nan         nan\n",
      "PPT1317_1                 0.3306      0.187      1.764      0.078      -0.037       0.698\n",
      "PPT18OV_3                -0.3427      0.222     -1.544      0.123      -0.778       0.092\n",
      "PPT18OV_4                 0.1688      0.241      0.702      0.483      -0.303       0.640\n",
      "PCTLT200FPL_0            -0.3472      0.146     -2.385      0.017      -0.633      -0.062\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:40.794050Z",
     "start_time": "2024-11-10T22:55:40.594901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the coefficients and p-values\n",
    "coefficients = logit_model_reg.params\n",
    "p_values = logit_model_reg.pvalues\n",
    "\n",
    "# Create a DataFrame to hold coefficients and p-values for easier processing\n",
    "coef_df = pd.DataFrame({\n",
    "    'Coefficient': coefficients,\n",
    "    'P-Value': p_values\n",
    "})\n",
    "\n",
    "# Filter out statistically significant coefficients (e.g., p-value < 0.05)\n",
    "significant_coefs = coef_df[coef_df['P-Value'] < 0.05]\n",
    "\n",
    "# Sort coefficients by absolute value (to find the top 20 largest), keeping the sign\n",
    "top_coefs = significant_coefs['Coefficient'].abs().sort_values(ascending=False).head(21).index\n",
    "\n",
    "# Filter the original coefficients DataFrame to get the top 20 largest coefficients (with signs)\n",
    "top_coefs_with_signs = significant_coefs.loc[top_coefs]\n",
    "\n",
    "# Plot the top 20 largest coefficients with their signs\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_coefs_with_signs['Coefficient'].plot(kind='barh', color=['skyblue' if coeff >= 0 else 'salmon' for coeff in\n",
    "                                                             top_coefs_with_signs['Coefficient']])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Top Statistically Significant Coefficients')\n",
    "plt.show()"
   ],
   "id": "8e1621ed75389387",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# take the top coefficients and create a new dataframe\n",
    "top_features = top_coefs_with_signs.index\n",
    "\n",
    "# drop the constant column\n",
    "top_features = top_features.drop('const')"
   ],
   "id": "1cafb4b1a69ac1e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:45.041836Z",
     "start_time": "2024-11-10T22:55:45.007031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_features = top_features.drop(['FINGOALS_0', 'BENEFITS_1_0', 'SWB_3_5', 'SWB_2_5'])\n",
    "\n",
    "X_train_top = X_train[top_features]\n",
    "X_test_top = X_test[top_features]\n",
    "\n",
    "# reset the index\n",
    "X_train_top.reset_index(drop=True, inplace=True)\n",
    "X_test_top.reset_index(drop=True, inplace=True)\n",
    "X_train_top"
   ],
   "id": "22164219614a80ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      PPINCIMP_9  BENEFITS_4_0  FWB2_3_4  PPREG9_8  PRODHAVE_1_1  \\\n",
       "0            0.0           1.0       0.0       0.0           1.0   \n",
       "1            0.0           1.0       0.0       0.0           0.0   \n",
       "2            0.0           1.0       0.0       0.0           1.0   \n",
       "3            0.0           1.0       0.0       0.0           1.0   \n",
       "4            1.0           1.0       0.0       0.0           1.0   \n",
       "...          ...           ...       ...       ...           ...   \n",
       "5110         0.0           1.0       0.0       0.0           1.0   \n",
       "5111         0.0           1.0       1.0       0.0           1.0   \n",
       "5112         0.0           0.0       0.0       0.0           1.0   \n",
       "5113         0.0           0.0       0.0       0.0           1.0   \n",
       "5114         0.0           0.0       0.0       1.0           1.0   \n",
       "\n",
       "      SAVINGSRANGES_1  PROPPLAN_4_4  CONSPROTECT2_3  MORTGAGE_2  PRODHAVE_6_1  \\\n",
       "0                 0.0           0.0             0.0         0.0           1.0   \n",
       "1                 0.0           0.0             0.0         0.0           1.0   \n",
       "2                 0.0           0.0             0.0         0.0           0.0   \n",
       "3                 0.0           0.0             0.0         0.0           0.0   \n",
       "4                 0.0           1.0             0.0         1.0           1.0   \n",
       "...               ...           ...             ...         ...           ...   \n",
       "5110              0.0           1.0             0.0         0.0           1.0   \n",
       "5111              0.0           0.0             0.0         0.0           1.0   \n",
       "5112              0.0           0.0             0.0         1.0           0.0   \n",
       "5113              0.0           0.0             0.0         0.0           1.0   \n",
       "5114              0.0           1.0             0.0         0.0           0.0   \n",
       "\n",
       "      agecat_2  OUTLOOK_1_5  FS1_7_5  KHKNOWL3_1  OBJNUMERACY1_3  SWB_2_5  \\\n",
       "0          0.0          0.0      0.0         0.0             0.0      0.0   \n",
       "1          0.0          0.0      1.0         0.0             0.0      0.0   \n",
       "2          0.0          0.0      0.0         0.0             0.0      0.0   \n",
       "3          0.0          0.0      0.0         0.0             0.0      1.0   \n",
       "4          0.0          0.0      0.0         0.0             0.0      0.0   \n",
       "...        ...          ...      ...         ...             ...      ...   \n",
       "5110       0.0          0.0      0.0         0.0             0.0      0.0   \n",
       "5111       0.0          0.0      0.0         0.0             0.0      0.0   \n",
       "5112       0.0          0.0      0.0         0.0             0.0      0.0   \n",
       "5113       0.0          1.0      1.0         1.0             0.0      0.0   \n",
       "5114       1.0          0.0      0.0         0.0             0.0      0.0   \n",
       "\n",
       "      SWB_3_5  PCTLT200FPL_0  BENEFITS_1_0  FINGOALS_0  \n",
       "0         0.0            0.0           0.0         0.0  \n",
       "1         0.0            0.0           0.0         0.0  \n",
       "2         0.0            1.0           0.0         0.0  \n",
       "3         1.0            1.0           0.0         0.0  \n",
       "4         0.0            1.0           0.0         0.0  \n",
       "...       ...            ...           ...         ...  \n",
       "5110      0.0            1.0           0.0         0.0  \n",
       "5111      0.0            0.0           1.0         1.0  \n",
       "5112      0.0            0.0           0.0         1.0  \n",
       "5113      0.0            1.0           0.0         0.0  \n",
       "5114      0.0            1.0           0.0         0.0  \n",
       "\n",
       "[5115 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPINCIMP_9</th>\n",
       "      <th>BENEFITS_4_0</th>\n",
       "      <th>FWB2_3_4</th>\n",
       "      <th>PPREG9_8</th>\n",
       "      <th>PRODHAVE_1_1</th>\n",
       "      <th>SAVINGSRANGES_1</th>\n",
       "      <th>PROPPLAN_4_4</th>\n",
       "      <th>CONSPROTECT2_3</th>\n",
       "      <th>MORTGAGE_2</th>\n",
       "      <th>PRODHAVE_6_1</th>\n",
       "      <th>agecat_2</th>\n",
       "      <th>OUTLOOK_1_5</th>\n",
       "      <th>FS1_7_5</th>\n",
       "      <th>KHKNOWL3_1</th>\n",
       "      <th>OBJNUMERACY1_3</th>\n",
       "      <th>SWB_2_5</th>\n",
       "      <th>SWB_3_5</th>\n",
       "      <th>PCTLT200FPL_0</th>\n",
       "      <th>BENEFITS_1_0</th>\n",
       "      <th>FINGOALS_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5115 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Building",
   "id": "d95d8b565b832dc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scoring and Cross-Validation",
   "id": "a9f48986580df6d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:47.477498Z",
     "start_time": "2024-11-10T22:55:47.453896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a custom scorer\n",
    "scorer = make_scorer(f1_score)"
   ],
   "id": "90dc4be2e51aa209",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:47.841520Z",
     "start_time": "2024-11-10T22:55:47.815750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a stratified k-fold object to ensure class balance across folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ],
   "id": "e1d1bd52a978f9f7",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression",
   "id": "8875547d2fc4d351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:48.675624Z",
     "start_time": "2024-11-10T22:55:48.556766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_top, y_train)"
   ],
   "id": "524cec388ebd0adc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ],
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:48.978395Z",
     "start_time": "2024-11-10T22:55:48.911391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with default hyperparameters\n",
    "y_pred_lr = lr_model.predict(X_test_top)"
   ],
   "id": "9514cb71e29322e9",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:49.174119Z",
     "start_time": "2024-11-10T22:55:49.127603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist_lr = {\n",
    "    'penalty': [None],  # Regularization type\n",
    "    'C': loguniform(1e-4, 1e4),  # Regularization strength (inverse of alpha)\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],  # Solver options\n",
    "    #'l1_ratio': [0.1, 0.5, 0.9],  # ElasticNet mixing (only for 'elasticnet' penalty)\n",
    "    'max_iter': randint(100, 5000)  # Max iterations\n",
    "}\n"
   ],
   "id": "a81b29a3ad211441",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RandomizedSearchCV",
   "id": "e27a016e25967dcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:52.293857Z",
     "start_time": "2024-11-10T22:55:49.404698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform GridSearchCV\n",
    "# Create a GridSearchCV object\n",
    "logit_random_search = RandomizedSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_distributions=param_dist_lr,\n",
    "    n_iter=100,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "logit_random_search.fit(X_train_top, y_train)"
   ],
   "id": "2ea6a6d7799703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "155 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "155 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 80, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.05000554        nan 0.05000554 0.05000554 0.05000554 0.05000554\n",
      "        nan 0.05000554 0.05000554 0.05000554        nan 0.05000554\n",
      "        nan 0.05000554 0.05000554        nan 0.05000554 0.05000554\n",
      " 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554\n",
      "        nan        nan        nan        nan 0.05000554 0.05000554\n",
      "        nan 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554\n",
      "        nan 0.05000554 0.05000554 0.05000554        nan 0.05000554\n",
      " 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554\n",
      " 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554        nan\n",
      "        nan 0.05000554        nan        nan        nan 0.05000554\n",
      " 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554        nan\n",
      "        nan 0.05000554 0.05000554 0.05000554 0.05000554 0.05000554\n",
      " 0.05000554        nan        nan        nan 0.05000554 0.05000554\n",
      " 0.05000554 0.05000554 0.05000554        nan 0.05000554 0.05000554\n",
      "        nan        nan 0.05000554        nan 0.05000554 0.05000554\n",
      " 0.05000554 0.05000554        nan        nan 0.05000554        nan\n",
      "        nan 0.05000554        nan 0.05000554]\n",
      "  warnings.warn(\n",
      "/Users/garrinshieh/anaconda3/envs/FINA4390/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=42), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x34a727650>,\n",
       "                                        'max_iter': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x3169d4550>,\n",
       "                                        'penalty': [None],\n",
       "                                        'solver': ['liblinear', 'saga',\n",
       "                                                   'lbfgs']},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method='predict'),\n",
       "                   verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=42), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x34a727650&gt;,\n",
       "                                        &#x27;max_iter&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x3169d4550&gt;,\n",
       "                                        &#x27;penalty&#x27;: [None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;,\n",
       "                                                   &#x27;lbfgs&#x27;]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=42), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x34a727650&gt;,\n",
       "                                        &#x27;max_iter&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x3169d4550&gt;,\n",
       "                                        &#x27;penalty&#x27;: [None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;,\n",
       "                                                   &#x27;lbfgs&#x27;]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.09915644566638401, max_iter=960, penalty=None,\n",
       "                   random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.09915644566638401, max_iter=960, penalty=None,\n",
       "                   random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best Parameters and Best Score",
   "id": "8ab7ad1e1f0ed2aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:52.391982Z",
     "start_time": "2024-11-10T22:55:52.340907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Parameters: \", logit_random_search.best_params_)\n",
    "print(\"Best Score: \", logit_random_search.best_score_)"
   ],
   "id": "8b390e6f94c2b2c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.09915644566638401, 'max_iter': 960, 'penalty': None, 'solver': 'lbfgs'}\n",
      "Best Score:  0.05000554262276909\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:52.531748Z",
     "start_time": "2024-11-10T22:55:52.486865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with the best hyperparameters\n",
    "y_pred_lr_hyper = logit_random_search.predict(X_test_top)"
   ],
   "id": "1dc0fb228bdc3f72",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classification Report",
   "id": "b7499306d45c8078"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:52.731960Z",
     "start_time": "2024-11-10T22:55:52.685367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_lr_hyper))"
   ],
   "id": "7dc990b639abe1dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1167\n",
      "           1       0.43      0.03      0.05       112\n",
      "\n",
      "    accuracy                           0.91      1279\n",
      "   macro avg       0.67      0.51      0.50      1279\n",
      "weighted avg       0.87      0.91      0.87      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Threshold Optimization",
   "id": "18a3a9f0fac214b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:52.848496Z",
     "start_time": "2024-11-10T22:55:52.779570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the optimal threshold\n",
    "y_prob = logit_random_search.predict_proba(X_test_top)[:, 1]\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# Choose a threshold based on the desired balance of precision and recall\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print(f\"Optimal threshold for best F1-score: {best_threshold}\")"
   ],
   "id": "d845f5e71d225626",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for best F1-score: 0.10388448044504278\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:53.013411Z",
     "start_time": "2024-11-10T22:55:52.954308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model with the optimal threshold\n",
    "y_pred_lr_optimal = (y_prob >= best_threshold).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_lr_optimal))"
   ],
   "id": "aec76ec46bf00f19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.73      0.82      1167\n",
      "           1       0.17      0.56      0.26       112\n",
      "\n",
      "    accuracy                           0.72      1279\n",
      "   macro avg       0.56      0.65      0.54      1279\n",
      "weighted avg       0.88      0.72      0.77      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "3dbbba579cf0125c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:53.301505Z",
     "start_time": "2024-11-10T22:55:53.094043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_top, y_train)"
   ],
   "id": "fb4d8cb2c3f7fa03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ],
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:53.376151Z",
     "start_time": "2024-11-10T22:55:53.340261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with default hyperparameters\n",
    "y_pred_rf = rf_model.predict(X_test_top)"
   ],
   "id": "859524929029afa5",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:55:53.471241Z",
     "start_time": "2024-11-10T22:55:53.446494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(200, 1200),  # Number of trees in the forest\n",
    "    'max_depth': randint(5, 15),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 20),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 20),  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None]  # Weights associated with classes\n",
    "}"
   ],
   "id": "31405c39823c6146",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RandomizedSearchCV",
   "id": "c4bd8cbe7e7d7228"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:08.872076Z",
     "start_time": "2024-11-10T22:55:53.480576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=100,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_random_search.fit(X_train_top, y_train)"
   ],
   "id": "412bf70000556fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'class_weight': ['balanced',\n",
       "                                                         'balanced_subsample',\n",
       "                                                         None],\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34a725b50>,\n",
       "                                        'max_features'...\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x322399350>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34b095d50>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34e9e8bd0>},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method='predict'),\n",
       "                   verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;,\n",
       "                                                         &#x27;balanced_subsample&#x27;,\n",
       "                                                         None],\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34a725b50&gt;,\n",
       "                                        &#x27;max_features&#x27;...\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x322399350&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34b095d50&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34e9e8bd0&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;,\n",
       "                                                         &#x27;balanced_subsample&#x27;,\n",
       "                                                         None],\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34a725b50&gt;,\n",
       "                                        &#x27;max_features&#x27;...\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x322399350&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34b095d50&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34e9e8bd0&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=13,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_leaf=10,\n",
       "                       min_samples_split=4, n_estimators=462, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=13,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_leaf=10,\n",
       "                       min_samples_split=4, n_estimators=462, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best Parameters and Best Score",
   "id": "ab27b51ccfbe1a86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:09.124187Z",
     "start_time": "2024-11-10T22:58:08.973238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Parameters: \", rf_random_search.best_params_)\n",
    "print(\"Best Score: \", rf_random_search.best_score_)"
   ],
   "id": "35e13a226ff200ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 13, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 462}\n",
      "Best Score:  0.28344217692911083\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:09.240037Z",
     "start_time": "2024-11-10T22:58:09.166757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with the best hyperparameters\n",
    "y_pred_rf_hyper = rf_random_search.predict(X_test_top)"
   ],
   "id": "a3b8bafae902199b",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classification Report",
   "id": "f6581945250ccb16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:09.324077Z",
     "start_time": "2024-11-10T22:58:09.290540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_rf_hyper))"
   ],
   "id": "e8873f795c6d0356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      1167\n",
      "           1       0.14      0.43      0.22       112\n",
      "\n",
      "    accuracy                           0.73      1279\n",
      "   macro avg       0.54      0.59      0.52      1279\n",
      "weighted avg       0.86      0.73      0.78      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost",
   "id": "1303c63da30789c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:09.598547Z",
     "start_time": "2024-11-10T22:58:09.367254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_top, y_train)"
   ],
   "id": "254d95c2d034bdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ],
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:09.733634Z",
     "start_time": "2024-11-10T22:58:09.700432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with default hyperparameters\n",
    "y_pred_xgb = xgb_model.predict(X_test_top)"
   ],
   "id": "330f6dd7883bc058",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:09.770046Z",
     "start_time": "2024-11-10T22:58:09.738900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter distribution for GridSearchCV\n",
    "param_distributions_xgb = {\n",
    "    'n_estimators': randint(50, 1000),  # Number of boosting rounds\n",
    "    'learning_rate': uniform(0.01, 0.5),  # Step size shrinkage\n",
    "    'max_depth': randint(3, 10),  # Maximum depth of a tree\n",
    "    'min_child_weight': randint(1, 6),  # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'gamma': uniform(0, 1),  # Minimum loss reduction to make a split\n",
    "    'subsample': uniform(0.1, 0.9),  # Subsample ratio of the training data\n",
    "    'colsample_bytree': uniform(0.1, 0.9),  # Subsample ratio of columns when constructing each tree\n",
    "    'scale_pos_weight': randint(1, 10),  # Controls the balance of positive and negative classes\n",
    "}"
   ],
   "id": "f7ec186df532afad",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RandomizedSearchCV",
   "id": "1b5759573ff8c773"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:26.659214Z",
     "start_time": "2024-11-10T22:58:09.812764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions_xgb,\n",
    "    n_iter=100,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_random_search.fit(X_train_top, y_train, verbose=False)"
   ],
   "id": "85f66c8003ad48fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END C=0.09915644566638401, max_iter=960, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00014610865886287216, max_iter=869, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.004997040685255816, max_iter=1284, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0023130924416844114, max_iter=2535, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0023130924416844114, max_iter=2535, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=5309.5322690092235, max_iter=341, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5309.5322690092235, max_iter=341, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=462.9768693362657, max_iter=134, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.13442649050633507, max_iter=1685, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.13442649050633507, max_iter=1685, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.13442649050633507, max_iter=1685, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.00039482545946332466, max_iter=2668, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00039482545946332466, max_iter=2668, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00039482545946332466, max_iter=2668, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00039482545946332466, max_iter=2668, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005798036325243074, max_iter=4698, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0005798036325243074, max_iter=4698, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=22.42487450512773, max_iter=904, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=22.42487450512773, max_iter=904, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=22.42487450512773, max_iter=904, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=22.42487450512773, max_iter=904, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=22.42487450512773, max_iter=904, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=5.3750474398489265, max_iter=2873, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0019488135833929646, max_iter=2725, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=291.7178717777821, max_iter=3160, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=291.7178717777821, max_iter=3160, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=291.7178717777821, max_iter=3160, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=291.7178717777821, max_iter=3160, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=291.7178717777821, max_iter=3160, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.44903124731460686, max_iter=3727, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.44903124731460686, max_iter=3727, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=735.9875002714882, max_iter=2911, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=735.9875002714882, max_iter=2911, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=735.9875002714882, max_iter=2911, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=735.9875002714882, max_iter=2911, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005780007214833219, max_iter=1469, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005780007214833219, max_iter=1469, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005780007214833219, max_iter=1469, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005780007214833219, max_iter=1469, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005780007214833219, max_iter=1469, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=299.23222999157946, max_iter=3319, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=299.23222999157946, max_iter=3319, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=299.23222999157946, max_iter=3319, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=299.23222999157946, max_iter=3319, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=299.23222999157946, max_iter=3319, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.002482741090341399, max_iter=3076, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.002482741090341399, max_iter=3076, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=20.32423242820728, max_iter=3061, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=2.453976022270101, max_iter=2969, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2.453976022270101, max_iter=2969, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=16.43198674858493, max_iter=4167, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0026951421352983487, max_iter=1627, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0026951421352983487, max_iter=1627, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=12.321425216715298, max_iter=1145, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5.235603875213307, max_iter=3536, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1368.9022629064273, max_iter=3454, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=4.123168440141702, max_iter=1059, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=4.123168440141702, max_iter=1059, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.003647068348712155, max_iter=915, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=9044.906595724933, max_iter=2305, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9044.906595724933, max_iter=2305, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01723783559661766, max_iter=2665, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=95.88489371365603, max_iter=1160, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=95.88489371365603, max_iter=1160, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.26636256387062246, max_iter=4376, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.26636256387062246, max_iter=4376, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=613; total time=   3.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=12, min_samples_split=13, n_estimators=1056; total time=   2.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=19, min_samples_split=8, n_estimators=220; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=14, min_samples_split=19, n_estimators=976; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=7, min_samples_split=13, n_estimators=708; total time=   2.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=401; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=401; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=8, min_samples_split=17, n_estimators=948; total time=   2.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=7, min_samples_split=10, n_estimators=543; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=10, n_estimators=227; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=17, n_estimators=702; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1142; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=14, min_samples_split=8, n_estimators=994; total time=   1.3s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=13, min_samples_split=8, n_estimators=440; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=948; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=755; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=558; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=558; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1018; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=18, n_estimators=812; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=935; total time=   1.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=None, min_samples_leaf=11, min_samples_split=18, n_estimators=966; total time=   5.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=1019; total time=   3.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=None, min_samples_leaf=18, min_samples_split=9, n_estimators=840; total time=   3.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=1, min_samples_split=12, n_estimators=824; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=709; total time=   1.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=9, min_samples_split=5, n_estimators=360; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=839; total time=   4.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=298; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=298; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=298; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=327; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=585; total time=   3.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=585; total time=   3.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=19, n_estimators=1120; total time=   6.8s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=11, n_estimators=1037; total time=   5.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=13, min_samples_split=16, n_estimators=1066; total time=   1.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=5, min_samples_split=10, n_estimators=1107; total time=   6.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=None, min_samples_leaf=5, min_samples_split=4, n_estimators=275; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=14, min_samples_split=6, n_estimators=246; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=sqrt, min_samples_leaf=12, min_samples_split=17, n_estimators=417; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=957; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=19, n_estimators=874; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=19, min_samples_split=12, n_estimators=812; total time=   1.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=sqrt, min_samples_leaf=10, min_samples_split=3, n_estimators=314; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=18, min_samples_split=14, n_estimators=274; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=16, min_samples_split=5, n_estimators=1177; total time=   3.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=997; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=8, max_features=sqrt, min_samples_leaf=13, min_samples_split=18, n_estimators=811; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=12, min_samples_split=10, n_estimators=654; total time=   3.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=None, min_samples_leaf=4, min_samples_split=17, n_estimators=768; total time=   4.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=15, n_estimators=422; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=None, min_samples_leaf=11, min_samples_split=12, n_estimators=857; total time=   4.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=7, n_estimators=538; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=17, min_samples_split=8, n_estimators=416; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=14, n_estimators=852; total time=   4.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=17, min_samples_split=2, n_estimators=1133; total time=   5.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=17, n_estimators=670; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=17, n_estimators=670; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=18, min_samples_split=6, n_estimators=240; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=6, min_samples_split=19, n_estimators=1082; total time=   1.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=6, min_samples_split=19, n_estimators=1082; total time=   1.8s\n",
      "[CV] END C=0.09915644566638401, max_iter=960, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0017707168643537846, max_iter=566, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00029152036385288323, max_iter=3544, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00029152036385288323, max_iter=3544, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00014610865886287216, max_iter=869, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.004997040685255816, max_iter=1284, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1.5777981883365035, max_iter=4943, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.02137140731637301, max_iter=1182, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.02137140731637301, max_iter=1182, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001306023180353164, max_iter=2847, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.4452048365748854, max_iter=2834, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.02734702913886812, max_iter=2712, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=29.775853025212687, max_iter=1578, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.251910921126085, max_iter=2713, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.251910921126085, max_iter=2713, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.251910921126085, max_iter=2713, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=3.4801873377804284, max_iter=1600, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.04005370050283179, max_iter=437, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.04005370050283179, max_iter=437, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.04005370050283179, max_iter=437, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.04005370050283179, max_iter=437, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=209.6062963490913, max_iter=4574, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=209.6062963490913, max_iter=4574, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=209.6062963490913, max_iter=4574, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=2572.805930249553, max_iter=3199, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2572.805930249553, max_iter=3199, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2572.805930249553, max_iter=3199, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2572.805930249553, max_iter=3199, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2572.805930249553, max_iter=3199, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00017841587142327403, max_iter=2890, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00017841587142327403, max_iter=2890, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00017841587142327403, max_iter=2890, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00017841587142327403, max_iter=2890, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00017841587142327403, max_iter=2890, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03272260339283022, max_iter=4291, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.03272260339283022, max_iter=4291, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.03272260339283022, max_iter=4291, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0020760931004560686, max_iter=4844, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0020760931004560686, max_iter=4844, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0020760931004560686, max_iter=4844, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0020760931004560686, max_iter=4844, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.005982221423148767, max_iter=4879, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005982221423148767, max_iter=4879, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005982221423148767, max_iter=4879, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005982221423148767, max_iter=4879, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.002482741090341399, max_iter=3076, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.002482741090341399, max_iter=3076, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.002482741090341399, max_iter=3076, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3117.740107483627, max_iter=4836, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3117.740107483627, max_iter=4836, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3117.740107483627, max_iter=4836, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3117.740107483627, max_iter=4836, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3117.740107483627, max_iter=4836, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.05352181202453728, max_iter=4161, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.05352181202453728, max_iter=4161, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.05352181202453728, max_iter=4161, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.05352181202453728, max_iter=4161, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.05352181202453728, max_iter=4161, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.011575320420690604, max_iter=723, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.011575320420690604, max_iter=723, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.011575320420690604, max_iter=723, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=2.1893835185601165, max_iter=1054, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=12.321425216715298, max_iter=1145, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5.235603875213307, max_iter=3536, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1368.9022629064273, max_iter=3454, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1368.9022629064273, max_iter=3454, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=228.29186095635177, max_iter=4993, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=613; total time=   3.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=12, min_samples_split=13, n_estimators=1056; total time=   2.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=19, min_samples_split=8, n_estimators=220; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=14, min_samples_split=19, n_estimators=976; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=7, min_samples_split=13, n_estimators=708; total time=   2.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=401; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=401; total time=   0.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=8, min_samples_split=17, n_estimators=948; total time=   3.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=618; total time=   1.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=10, n_estimators=227; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=13, n_estimators=1071; total time=   3.2s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=14, min_samples_split=8, n_estimators=994; total time=   1.3s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=13, min_samples_split=8, n_estimators=440; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=sqrt, min_samples_leaf=7, min_samples_split=3, n_estimators=881; total time=   1.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=755; total time=   2.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=None, min_samples_leaf=7, min_samples_split=2, n_estimators=584; total time=   3.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=17, min_samples_split=18, n_estimators=641; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=18, n_estimators=812; total time=   1.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=13, n_estimators=929; total time=   1.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=None, min_samples_leaf=11, min_samples_split=18, n_estimators=966; total time=   5.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=1019; total time=   3.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=4, n_estimators=462; total time=   0.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=4, n_estimators=462; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=503; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=1, min_samples_split=12, n_estimators=824; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=709; total time=   1.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=9, min_samples_split=5, n_estimators=360; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=839; total time=   4.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=16, min_samples_split=5, n_estimators=746; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=17, min_samples_split=15, n_estimators=380; total time=   0.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=327; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=585; total time=   3.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=9, min_samples_split=12, n_estimators=445; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=9, min_samples_split=12, n_estimators=445; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=9, min_samples_split=12, n_estimators=445; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=219; total time=   1.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=219; total time=   1.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=15, min_samples_split=3, n_estimators=1033; total time=   4.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=13, n_estimators=819; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=13, n_estimators=819; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=13, n_estimators=819; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=5, min_samples_split=10, n_estimators=1107; total time=   5.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=None, min_samples_leaf=5, min_samples_split=4, n_estimators=275; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=None, min_samples_leaf=5, min_samples_split=4, n_estimators=275; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=957; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=19, n_estimators=874; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=19, min_samples_split=12, n_estimators=812; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=sqrt, min_samples_leaf=19, min_samples_split=19, n_estimators=234; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=sqrt, min_samples_leaf=10, min_samples_split=3, n_estimators=314; total time=   0.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1068; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=12, max_features=None, min_samples_leaf=5, min_samples_split=13, n_estimators=568; total time=   2.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=997; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=12, min_samples_split=10, n_estimators=654; total time=   4.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=None, min_samples_leaf=4, min_samples_split=17, n_estimators=768; total time=   3.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=15, n_estimators=422; total time=   0.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=15, n_estimators=422; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=None, min_samples_leaf=11, min_samples_split=12, n_estimators=857; total time=   3.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=7, n_estimators=538; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=17, min_samples_split=8, n_estimators=416; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=12, min_samples_split=8, n_estimators=290; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END C=71.77141927992021, max_iter=3872, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.02137140731637301, max_iter=1182, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001306023180353164, max_iter=2847, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.4452048365748854, max_iter=2834, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.4452048365748854, max_iter=2834, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5309.5322690092235, max_iter=341, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5309.5322690092235, max_iter=341, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=3.4801873377804284, max_iter=1600, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.4801873377804284, max_iter=1600, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.4801873377804284, max_iter=1600, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.4801873377804284, max_iter=1600, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.003697114486625516, max_iter=1116, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.003697114486625516, max_iter=1116, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.003697114486625516, max_iter=1116, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.04005370050283179, max_iter=437, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.44903124731460686, max_iter=3727, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.44903124731460686, max_iter=3727, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.44903124731460686, max_iter=3727, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1164.7750823541105, max_iter=1763, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1164.7750823541105, max_iter=1763, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1164.7750823541105, max_iter=1763, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1164.7750823541105, max_iter=1763, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1164.7750823541105, max_iter=1763, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.011575320420690604, max_iter=723, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.011575320420690604, max_iter=723, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.358585985052758, max_iter=2149, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.358585985052758, max_iter=2149, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.358585985052758, max_iter=2149, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.358585985052758, max_iter=2149, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.358585985052758, max_iter=2149, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005556766432156766, max_iter=3823, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005556766432156766, max_iter=3823, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005556766432156766, max_iter=3823, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005556766432156766, max_iter=3823, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005556766432156766, max_iter=3823, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1597.1454085256732, max_iter=4190, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1597.1454085256732, max_iter=4190, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1597.1454085256732, max_iter=4190, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1597.1454085256732, max_iter=4190, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3055.483577045257, max_iter=1545, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.00011846127780587221, max_iter=2657, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00011846127780587221, max_iter=2657, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00011846127780587221, max_iter=2657, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00011846127780587221, max_iter=2657, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=20.32423242820728, max_iter=3061, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=20.32423242820728, max_iter=3061, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.0026951421352983487, max_iter=1627, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=58.54898815922259, max_iter=4835, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=58.54898815922259, max_iter=4835, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=2.1893835185601165, max_iter=1054, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2.1893835185601165, max_iter=1054, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=5.235603875213307, max_iter=3536, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=4.123168440141702, max_iter=1059, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.003647068348712155, max_iter=915, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.767329390130771, max_iter=3220, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01723783559661766, max_iter=2665, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=95.88489371365603, max_iter=1160, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=95.88489371365603, max_iter=1160, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.26636256387062246, max_iter=4376, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=7, min_samples_split=12, n_estimators=658; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=12, min_samples_split=13, n_estimators=1056; total time=   2.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=15, min_samples_split=13, n_estimators=766; total time=   3.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=14, min_samples_split=19, n_estimators=976; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=17, min_samples_split=5, n_estimators=761; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=5, n_estimators=1021; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=8, min_samples_split=17, n_estimators=948; total time=   2.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=618; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=17, n_estimators=702; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1142; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=14, min_samples_split=8, n_estimators=994; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=13, min_samples_split=8, n_estimators=440; total time=   0.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=sqrt, min_samples_leaf=7, min_samples_split=3, n_estimators=881; total time=   1.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=755; total time=   2.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=None, min_samples_leaf=7, min_samples_split=2, n_estimators=584; total time=   3.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=17, min_samples_split=18, n_estimators=641; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=18, n_estimators=812; total time=   2.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=None, min_samples_leaf=11, min_samples_split=18, n_estimators=966; total time=   5.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=6, min_samples_split=17, n_estimators=548; total time=   3.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=None, min_samples_leaf=18, min_samples_split=9, n_estimators=840; total time=   3.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=503; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=9, min_samples_split=10, n_estimators=298; total time=   1.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=709; total time=   1.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=9, min_samples_split=5, n_estimators=360; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=429; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=429; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=483; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=16, min_samples_split=5, n_estimators=746; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=298; total time=   0.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=17, min_samples_split=15, n_estimators=380; total time=   0.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=327; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=585; total time=   3.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=585; total time=   3.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=219; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=15, min_samples_split=3, n_estimators=1033; total time=   3.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=15, min_samples_split=3, n_estimators=1033; total time=   4.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=13, n_estimators=819; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=log2, min_samples_leaf=19, min_samples_split=18, n_estimators=319; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=log2, min_samples_leaf=19, min_samples_split=18, n_estimators=319; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=log2, min_samples_leaf=19, min_samples_split=18, n_estimators=319; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=1, min_samples_split=16, n_estimators=1001; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=1, min_samples_split=16, n_estimators=1001; total time=   3.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1084; total time=   2.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=sqrt, min_samples_leaf=12, min_samples_split=17, n_estimators=417; total time=   1.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=10, min_samples_split=2, n_estimators=524; total time=   2.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=19, min_samples_split=12, n_estimators=812; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=242; total time=   0.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=sqrt, min_samples_leaf=19, min_samples_split=19, n_estimators=234; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=sqrt, min_samples_leaf=10, min_samples_split=3, n_estimators=314; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1068; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=16, min_samples_split=5, n_estimators=1177; total time=   3.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=8, max_features=sqrt, min_samples_leaf=13, min_samples_split=18, n_estimators=811; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=12, min_samples_split=10, n_estimators=654; total time=   4.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=15, min_samples_split=17, n_estimators=1084; total time=   5.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=None, min_samples_leaf=11, min_samples_split=12, n_estimators=857; total time=   4.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=7, n_estimators=538; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=17, min_samples_split=8, n_estimators=416; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=14, n_estimators=852; total time=   4.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=17, min_samples_split=2, n_estimators=1133; total time=   5.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=17, n_estimators=670; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=9, n_estimators=321; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=9, n_estimators=321; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=10, n_estimators=1128; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.5133240027692805, gamma=0.33370861113902184, learning_rate=0.08143340896097039, max_depth=5, min_child_weight=5, n_estimators=819, scale_pos_weight=8, subsample=0.8491983767203796; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6506676052501416, gamma=0.13949386065204183, learning_rate=0.15607232426760909, max_depth=9, min_child_weight=3, n_estimators=925, scale_pos_weight=7, subsample=0.9849077972261093; total time=   0.5s\n",
      "[CV] END C=0.09915644566638401, max_iter=960, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00029152036385288323, max_iter=3544, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00029152036385288323, max_iter=3544, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00014610865886287216, max_iter=869, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.0039572205641009274, max_iter=1367, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0039572205641009274, max_iter=1367, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=29.775853025212687, max_iter=1578, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=29.775853025212687, max_iter=1578, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=462.9768693362657, max_iter=134, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=462.9768693362657, max_iter=134, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=462.9768693362657, max_iter=134, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=462.9768693362657, max_iter=134, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5.3750474398489265, max_iter=2873, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=5.3750474398489265, max_iter=2873, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=5.3750474398489265, max_iter=2873, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=5.3750474398489265, max_iter=2873, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.08992121928131, max_iter=2790, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=3.08992121928131, max_iter=2790, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=3.08992121928131, max_iter=2790, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=3.08992121928131, max_iter=2790, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00421201392089098, max_iter=1822, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00421201392089098, max_iter=1822, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00421201392089098, max_iter=1822, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00421201392089098, max_iter=1822, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0019488135833929646, max_iter=2725, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0019488135833929646, max_iter=2725, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0019488135833929646, max_iter=2725, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0019488135833929646, max_iter=2725, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=9592.324903033117, max_iter=798, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9592.324903033117, max_iter=798, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=6500.094142148198, max_iter=954, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=6500.094142148198, max_iter=954, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=6500.094142148198, max_iter=954, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=6500.094142148198, max_iter=954, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=6500.094142148198, max_iter=954, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.05761956619023542, max_iter=3574, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.05761956619023542, max_iter=3574, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.05761956619023542, max_iter=3574, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.05761956619023542, max_iter=3574, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.05761956619023542, max_iter=3574, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0014426433452224832, max_iter=1807, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0014426433452224832, max_iter=1807, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.0014426433452224832, max_iter=1807, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.0014426433452224832, max_iter=1807, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=2.1893835185601165, max_iter=1054, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=12.321425216715298, max_iter=1145, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=228.29186095635177, max_iter=4993, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=4.123168440141702, max_iter=1059, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=4.123168440141702, max_iter=1059, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.003647068348712155, max_iter=915, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.003647068348712155, max_iter=915, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.767329390130771, max_iter=3220, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9044.906595724933, max_iter=2305, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9044.906595724933, max_iter=2305, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9044.906595724933, max_iter=2305, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01723783559661766, max_iter=2665, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=613; total time=   3.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=15, min_samples_split=13, n_estimators=766; total time=   3.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=14, min_samples_split=19, n_estimators=976; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=17, min_samples_split=5, n_estimators=761; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=17, min_samples_split=5, n_estimators=761; total time=   1.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=401; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=8, min_samples_split=17, n_estimators=948; total time=   2.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=7, min_samples_split=10, n_estimators=543; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=10, n_estimators=227; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=17, n_estimators=702; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1142; total time=   2.0s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=14, min_samples_split=8, n_estimators=994; total time=   1.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=13, min_samples_split=8, n_estimators=440; total time=   0.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=sqrt, min_samples_leaf=7, min_samples_split=3, n_estimators=881; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=sqrt, min_samples_leaf=7, min_samples_split=3, n_estimators=881; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=None, min_samples_leaf=7, min_samples_split=2, n_estimators=584; total time=   3.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=17, min_samples_split=18, n_estimators=641; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=18, n_estimators=812; total time=   1.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=935; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=None, min_samples_leaf=11, min_samples_split=18, n_estimators=966; total time=   5.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=6, min_samples_split=17, n_estimators=548; total time=   3.3s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=None, min_samples_leaf=18, min_samples_split=9, n_estimators=840; total time=   3.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=9, min_samples_split=10, n_estimators=298; total time=   1.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=1, min_samples_split=12, n_estimators=824; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=18, min_samples_split=15, n_estimators=537; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=9, min_samples_split=5, n_estimators=360; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=429; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=483; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=483; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=298; total time=   0.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=17, min_samples_split=15, n_estimators=380; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=9, n_estimators=885; total time=   6.8s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=19, n_estimators=1120; total time=   6.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=15, min_samples_split=3, n_estimators=1033; total time=   4.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=13, n_estimators=819; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=13, min_samples_split=16, n_estimators=1066; total time=   1.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=1, min_samples_split=16, n_estimators=1001; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=1, min_samples_split=16, n_estimators=1001; total time=   3.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1084; total time=   2.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=sqrt, min_samples_leaf=12, min_samples_split=17, n_estimators=417; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=10, min_samples_split=2, n_estimators=524; total time=   2.3s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=19, n_estimators=874; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=242; total time=   0.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=sqrt, min_samples_leaf=19, min_samples_split=19, n_estimators=234; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=sqrt, min_samples_leaf=10, min_samples_split=3, n_estimators=314; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1068; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=16, min_samples_split=5, n_estimators=1177; total time=   3.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=997; total time=   2.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=12, min_samples_split=10, n_estimators=654; total time=   4.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=None, min_samples_leaf=4, min_samples_split=17, n_estimators=768; total time=   3.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=None, min_samples_leaf=11, min_samples_split=12, n_estimators=857; total time=   3.8s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=12, max_features=log2, min_samples_leaf=9, min_samples_split=19, n_estimators=994; total time=   2.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=12, min_samples_split=8, n_estimators=290; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=14, n_estimators=852; total time=   5.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=13, min_samples_split=16, n_estimators=348; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=426; total time=   2.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=18, n_estimators=725; total time=   2.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=18, min_samples_split=6, n_estimators=240; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=6, min_samples_split=19, n_estimators=1082; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=19, n_estimators=450; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=19, n_estimators=450; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=19, n_estimators=450; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5133240027692805, gamma=0.33370861113902184, learning_rate=0.08143340896097039, max_depth=5, min_child_weight=5, n_estimators=819, scale_pos_weight=8, subsample=0.8491983767203796; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6506676052501416, gamma=0.13949386065204183, learning_rate=0.15607232426760909, max_depth=9, min_child_weight=3, n_estimators=925, scale_pos_weight=7, subsample=0.9849077972261093; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.849875420562548, gamma=0.17336465350777208, learning_rate=0.2055303037866204, max_depth=4, min_child_weight=4, n_estimators=51, scale_pos_weight=6, subsample=0.28714749658136995; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.849875420562548, gamma=0.17336465350777208, learning_rate=0.2055303037866204, max_depth=4, min_child_weight=4, n_estimators=51, scale_pos_weight=6, subsample=0.28714749658136995; total time=   0.1s\n",
      "[CV] END C=0.09915644566638401, max_iter=960, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=71.77141927992021, max_iter=3872, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=71.77141927992021, max_iter=3872, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0017707168643537846, max_iter=566, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0017707168643537846, max_iter=566, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0017707168643537846, max_iter=566, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00014610865886287216, max_iter=869, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.004997040685255816, max_iter=1284, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.02137140731637301, max_iter=1182, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001306023180353164, max_iter=2847, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0039572205641009274, max_iter=1367, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0039572205641009274, max_iter=1367, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0039572205641009274, max_iter=1367, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00023528990899815348, max_iter=3990, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0023130924416844114, max_iter=2535, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0023130924416844114, max_iter=2535, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0023130924416844114, max_iter=2535, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=5309.5322690092235, max_iter=341, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=29.775853025212687, max_iter=1578, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=29.775853025212687, max_iter=1578, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.13442649050633507, max_iter=1685, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.13442649050633507, max_iter=1685, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.251910921126085, max_iter=2713, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.251910921126085, max_iter=2713, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=631.4058805139143, max_iter=4975, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=631.4058805139143, max_iter=4975, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=631.4058805139143, max_iter=4975, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=631.4058805139143, max_iter=4975, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=631.4058805139143, max_iter=4975, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0005798036325243074, max_iter=4698, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0005798036325243074, max_iter=4698, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0005798036325243074, max_iter=4698, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.005982221423148767, max_iter=4879, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0022198740653171906, max_iter=3843, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0022198740653171906, max_iter=3843, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0022198740653171906, max_iter=3843, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0022198740653171906, max_iter=3843, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0022198740653171906, max_iter=3843, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1700941465386248, max_iter=1953, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1700941465386248, max_iter=1953, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1700941465386248, max_iter=1953, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1700941465386248, max_iter=1953, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.1700941465386248, max_iter=1953, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.010747892437840835, max_iter=1391, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.010747892437840835, max_iter=1391, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.010747892437840835, max_iter=1391, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.010747892437840835, max_iter=1391, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.010747892437840835, max_iter=1391, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=37.19068544473705, max_iter=1736, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=37.19068544473705, max_iter=1736, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=37.19068544473705, max_iter=1736, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=37.19068544473705, max_iter=1736, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=37.19068544473705, max_iter=1736, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9592.324903033117, max_iter=798, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9592.324903033117, max_iter=798, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=9592.324903033117, max_iter=798, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=3055.483577045257, max_iter=1545, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.00011846127780587221, max_iter=2657, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=20.32423242820728, max_iter=3061, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=2.453976022270101, max_iter=2969, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=16.43198674858493, max_iter=4167, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00013950921947169655, max_iter=4593, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00013950921947169655, max_iter=4593, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0026951421352983487, max_iter=1627, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0026951421352983487, max_iter=1627, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=58.54898815922259, max_iter=4835, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01723783559661766, max_iter=2665, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.26636256387062246, max_iter=4376, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=7, min_samples_split=12, n_estimators=658; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=12, min_samples_split=13, n_estimators=1056; total time=   2.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=15, min_samples_split=13, n_estimators=766; total time=   3.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=7, min_samples_split=13, n_estimators=708; total time=   2.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=5, n_estimators=1021; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=8, min_samples_split=17, n_estimators=948; total time=   3.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=618; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=17, n_estimators=702; total time=   1.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=13, n_estimators=1071; total time=   3.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=13, min_samples_split=8, n_estimators=440; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=948; total time=   1.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=755; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=558; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=558; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1018; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=18, n_estimators=812; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=13, n_estimators=929; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=6, min_samples_split=12, n_estimators=710; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=6, min_samples_split=12, n_estimators=710; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=6, min_samples_split=17, n_estimators=548; total time=   3.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=None, min_samples_leaf=18, min_samples_split=9, n_estimators=840; total time=   3.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=4, n_estimators=462; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=503; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=9, min_samples_split=10, n_estimators=298; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=1, min_samples_split=12, n_estimators=824; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=18, min_samples_split=15, n_estimators=537; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=839; total time=   4.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=16, min_samples_split=5, n_estimators=746; total time=   1.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=17, min_samples_split=15, n_estimators=380; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=9, n_estimators=885; total time=   6.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=9, min_samples_split=12, n_estimators=445; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=19, n_estimators=1120; total time=   7.1s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=11, n_estimators=1037; total time=   5.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=13, min_samples_split=16, n_estimators=1066; total time=   1.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=1, min_samples_split=16, n_estimators=1001; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1084; total time=   2.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1084; total time=   2.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=957; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=10, min_samples_split=2, n_estimators=524; total time=   2.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=242; total time=   0.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=sqrt, min_samples_leaf=19, min_samples_split=19, n_estimators=234; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=18, min_samples_split=14, n_estimators=274; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=18, min_samples_split=14, n_estimators=274; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=16, min_samples_split=5, n_estimators=1177; total time=   3.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=12, max_features=None, min_samples_leaf=5, min_samples_split=13, n_estimators=568; total time=   2.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=8, max_features=sqrt, min_samples_leaf=13, min_samples_split=18, n_estimators=811; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=15, min_samples_split=17, n_estimators=1084; total time=   5.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=None, min_samples_leaf=4, min_samples_split=17, n_estimators=768; total time=   3.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=18, n_estimators=452; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=12, max_features=log2, min_samples_leaf=9, min_samples_split=19, n_estimators=994; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=7, n_estimators=538; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=17, min_samples_split=8, n_estimators=416; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=12, min_samples_split=8, n_estimators=290; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=17, min_samples_split=2, n_estimators=1133; total time=   6.3s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=18, n_estimators=725; total time=   2.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=17, n_estimators=670; total time=   1.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=9, n_estimators=321; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=10, n_estimators=1128; total time=   6.1s\n",
      "[CV] END C=0.09915644566638401, max_iter=960, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0017707168643537846, max_iter=566, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00029152036385288323, max_iter=3544, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00014610865886287216, max_iter=869, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=547.3664780991485, max_iter=261, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1440.8501080722583, max_iter=3442, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1440.8501080722583, max_iter=3442, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1440.8501080722583, max_iter=3442, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=426.4813784432929, max_iter=4093, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=426.4813784432929, max_iter=4093, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=426.4813784432929, max_iter=4093, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=426.4813784432929, max_iter=4093, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=426.4813784432929, max_iter=4093, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.017679748286442643, max_iter=479, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.017679748286442643, max_iter=479, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.017679748286442643, max_iter=479, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.017679748286442643, max_iter=479, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.017679748286442643, max_iter=479, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0013408920002835425, max_iter=2162, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0013408920002835425, max_iter=2162, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0013408920002835425, max_iter=2162, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0013408920002835425, max_iter=2162, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0013408920002835425, max_iter=2162, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00039482545946332466, max_iter=2668, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.003887992802407561, max_iter=1595, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=333.9576740674947, max_iter=491, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=333.9576740674947, max_iter=491, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=333.9576740674947, max_iter=491, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=333.9576740674947, max_iter=491, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=333.9576740674947, max_iter=491, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=209.6062963490913, max_iter=4574, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=209.6062963490913, max_iter=4574, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03272260339283022, max_iter=4291, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.03272260339283022, max_iter=4291, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0013021218760556994, max_iter=1778, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0013021218760556994, max_iter=1778, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0013021218760556994, max_iter=1778, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0013021218760556994, max_iter=1778, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0013021218760556994, max_iter=1778, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00421201392089098, max_iter=1822, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0014426433452224832, max_iter=1807, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=7677.213757517439, max_iter=3610, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=7677.213757517439, max_iter=3610, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=7677.213757517439, max_iter=3610, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=7677.213757517439, max_iter=3610, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=7677.213757517439, max_iter=3610, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.09062241853992614, max_iter=4596, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.09062241853992614, max_iter=4596, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.09062241853992614, max_iter=4596, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.09062241853992614, max_iter=4596, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.09062241853992614, max_iter=4596, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=266.14484032100796, max_iter=3031, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=266.14484032100796, max_iter=3031, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=266.14484032100796, max_iter=3031, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=266.14484032100796, max_iter=3031, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=266.14484032100796, max_iter=3031, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=12.321425216715298, max_iter=1145, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=5.235603875213307, max_iter=3536, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=5.235603875213307, max_iter=3536, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1368.9022629064273, max_iter=3454, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=228.29186095635177, max_iter=4993, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=228.29186095635177, max_iter=4993, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=95.88489371365603, max_iter=1160, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.26636256387062246, max_iter=4376, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=7, min_samples_split=12, n_estimators=658; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=12, min_samples_split=13, n_estimators=1056; total time=   2.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=15, min_samples_split=13, n_estimators=766; total time=   3.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=7, min_samples_split=13, n_estimators=708; total time=   3.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=5, n_estimators=1021; total time=   2.2s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=13, min_samples_split=10, n_estimators=356; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=13, min_samples_split=10, n_estimators=356; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=7, min_samples_split=10, n_estimators=543; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=618; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=13, n_estimators=1071; total time=   3.2s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1142; total time=   2.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=948; total time=   1.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=755; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=558; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1018; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=17, min_samples_split=18, n_estimators=641; total time=   1.3s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=935; total time=   1.3s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=13, n_estimators=929; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=11, max_features=None, min_samples_leaf=11, min_samples_split=18, n_estimators=966; total time=   5.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=1019; total time=   4.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=None, min_samples_leaf=18, min_samples_split=9, n_estimators=840; total time=   3.3s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=1, min_samples_split=12, n_estimators=824; total time=   1.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=18, min_samples_split=15, n_estimators=537; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=18, min_samples_split=15, n_estimators=537; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=839; total time=   4.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=16, min_samples_split=5, n_estimators=746; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=17, min_samples_split=15, n_estimators=380; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=9, n_estimators=885; total time=   6.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=9, min_samples_split=12, n_estimators=445; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=219; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=219; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=15, min_samples_split=3, n_estimators=1033; total time=   4.1s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=11, n_estimators=1037; total time=   5.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=log2, min_samples_leaf=19, min_samples_split=18, n_estimators=319; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=log2, min_samples_leaf=19, min_samples_split=18, n_estimators=319; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=5, min_samples_split=10, n_estimators=1107; total time=   5.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=None, min_samples_leaf=5, min_samples_split=4, n_estimators=275; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=14, min_samples_split=6, n_estimators=246; total time=   0.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=14, min_samples_split=6, n_estimators=246; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=sqrt, min_samples_leaf=12, min_samples_split=17, n_estimators=417; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=10, min_samples_split=2, n_estimators=524; total time=   2.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=19, n_estimators=874; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=242; total time=   0.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=242; total time=   0.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=sqrt, min_samples_leaf=19, min_samples_split=19, n_estimators=234; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=18, min_samples_split=14, n_estimators=274; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=16, min_samples_split=5, n_estimators=1177; total time=   3.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=12, max_features=None, min_samples_leaf=5, min_samples_split=13, n_estimators=568; total time=   3.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=8, max_features=sqrt, min_samples_leaf=13, min_samples_split=18, n_estimators=811; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=15, min_samples_split=17, n_estimators=1084; total time=   5.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=15, n_estimators=422; total time=   0.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=15, n_estimators=422; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=None, min_samples_leaf=11, min_samples_split=12, n_estimators=857; total time=   3.9s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=12, max_features=log2, min_samples_leaf=9, min_samples_split=19, n_estimators=994; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=12, min_samples_split=8, n_estimators=290; total time=   0.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=14, n_estimators=852; total time=   4.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=13, min_samples_split=16, n_estimators=348; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=13, min_samples_split=16, n_estimators=348; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=426; total time=   2.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=17, n_estimators=670; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=9, n_estimators=321; total time=   0.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=18, min_samples_split=6, n_estimators=240; total time=   0.6s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=10, n_estimators=1128; total time=   5.6s\n",
      "[CV] END C=71.77141927992021, max_iter=3872, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004997040685255816, max_iter=1284, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1.5777981883365035, max_iter=4943, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.5777981883365035, max_iter=4943, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001306023180353164, max_iter=2847, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.4452048365748854, max_iter=2834, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.00023528990899815348, max_iter=3990, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00023528990899815348, max_iter=3990, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.02734702913886812, max_iter=2712, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.02734702913886812, max_iter=2712, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1440.8501080722583, max_iter=3442, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1440.8501080722583, max_iter=3442, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.003697114486625516, max_iter=1116, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.003697114486625516, max_iter=1116, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.003887992802407561, max_iter=1595, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.003887992802407561, max_iter=1595, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.003887992802407561, max_iter=1595, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.003887992802407561, max_iter=1595, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.011182697629026503, max_iter=4588, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.011182697629026503, max_iter=4588, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.011182697629026503, max_iter=4588, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.2632256136809146, max_iter=1584, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.2632256136809146, max_iter=1584, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.2632256136809146, max_iter=1584, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.2632256136809146, max_iter=1584, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.2632256136809146, max_iter=1584, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0007593034903208885, max_iter=1406, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0007593034903208885, max_iter=1406, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.00010096317884554843, max_iter=1382, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00010096317884554843, max_iter=1382, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00010096317884554843, max_iter=1382, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00010096317884554843, max_iter=1382, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00010096317884554843, max_iter=1382, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0020760931004560686, max_iter=4844, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=11.701396243779081, max_iter=2030, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=11.701396243779081, max_iter=2030, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=11.701396243779081, max_iter=2030, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=11.701396243779081, max_iter=2030, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=11.701396243779081, max_iter=2030, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0005276162470390146, max_iter=708, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005276162470390146, max_iter=708, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005276162470390146, max_iter=708, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005276162470390146, max_iter=708, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0005276162470390146, max_iter=708, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03683329062823529, max_iter=3497, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03683329062823529, max_iter=3497, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03683329062823529, max_iter=3497, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03683329062823529, max_iter=3497, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03683329062823529, max_iter=3497, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=735.9875002714882, max_iter=2911, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3055.483577045257, max_iter=1545, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=3055.483577045257, max_iter=1545, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=3055.483577045257, max_iter=1545, penalty=None, solver=saga; total time=   0.1s\n",
      "[CV] END C=20.32423242820728, max_iter=3061, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=2.453976022270101, max_iter=2969, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=2.453976022270101, max_iter=2969, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=16.43198674858493, max_iter=4167, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=16.43198674858493, max_iter=4167, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=16.43198674858493, max_iter=4167, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00013950921947169655, max_iter=4593, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00013950921947169655, max_iter=4593, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00013950921947169655, max_iter=4593, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=58.54898815922259, max_iter=4835, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=58.54898815922259, max_iter=4835, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=2.1893835185601165, max_iter=1054, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=12.321425216715298, max_iter=1145, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1368.9022629064273, max_iter=3454, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=228.29186095635177, max_iter=4993, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.003647068348712155, max_iter=915, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=7, min_samples_split=12, n_estimators=658; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=613; total time=   3.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=19, min_samples_split=8, n_estimators=220; total time=   0.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=19, min_samples_split=8, n_estimators=220; total time=   0.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=19, min_samples_split=8, n_estimators=220; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=14, min_samples_split=19, n_estimators=976; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=7, min_samples_split=13, n_estimators=708; total time=   3.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=5, n_estimators=1021; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=13, min_samples_split=10, n_estimators=356; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=13, min_samples_split=10, n_estimators=356; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=7, min_samples_split=10, n_estimators=543; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=10, n_estimators=227; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=7, min_samples_split=10, n_estimators=227; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=13, n_estimators=1071; total time=   3.0s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1142; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=948; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=sqrt, min_samples_leaf=7, min_samples_split=3, n_estimators=881; total time=   1.7s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=None, min_samples_leaf=7, min_samples_split=2, n_estimators=584; total time=   3.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1018; total time=   2.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=935; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=13, n_estimators=929; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=6, min_samples_split=12, n_estimators=710; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=6, min_samples_split=17, n_estimators=548; total time=   3.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=1019; total time=   3.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=4, n_estimators=462; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=503; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=9, min_samples_split=10, n_estimators=298; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=709; total time=   1.9s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=sqrt, min_samples_leaf=18, min_samples_split=15, n_estimators=537; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=839; total time=   4.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=16, min_samples_split=5, n_estimators=746; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=327; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=9, n_estimators=885; total time=   6.6s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=19, n_estimators=1120; total time=   7.2s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=11, n_estimators=1037; total time=   5.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=13, min_samples_split=16, n_estimators=1066; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=5, min_samples_split=10, n_estimators=1107; total time=   5.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=None, min_samples_leaf=5, min_samples_split=4, n_estimators=275; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=14, min_samples_split=6, n_estimators=246; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=14, min_samples_split=6, n_estimators=246; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=957; total time=   2.3s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=10, min_samples_split=2, n_estimators=524; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=19, min_samples_split=12, n_estimators=812; total time=   1.3s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=18, min_samples_split=14, n_estimators=274; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1068; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=12, max_features=None, min_samples_leaf=5, min_samples_split=13, n_estimators=568; total time=   2.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=997; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=12, min_samples_split=10, n_estimators=654; total time=   4.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=15, min_samples_split=17, n_estimators=1084; total time=   6.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=18, n_estimators=452; total time=   0.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=18, n_estimators=452; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=12, max_features=log2, min_samples_leaf=9, min_samples_split=19, n_estimators=994; total time=   2.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=17, min_samples_split=8, n_estimators=416; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=12, min_samples_split=8, n_estimators=290; total time=   0.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=17, min_samples_split=2, n_estimators=1133; total time=   6.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=426; total time=   2.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=18, n_estimators=725; total time=   2.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=9, n_estimators=321; total time=   0.6s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=10, n_estimators=1128; total time=   5.9s\n",
      "[CV] END C=71.77141927992021, max_iter=3872, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004997040685255816, max_iter=1284, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1.5777981883365035, max_iter=4943, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=1.5777981883365035, max_iter=4943, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.02137140731637301, max_iter=1182, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001306023180353164, max_iter=2847, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.4452048365748854, max_iter=2834, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.00023528990899815348, max_iter=3990, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.00023528990899815348, max_iter=3990, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.02734702913886812, max_iter=2712, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.02734702913886812, max_iter=2712, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=547.3664780991485, max_iter=261, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=547.3664780991485, max_iter=261, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=547.3664780991485, max_iter=261, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=547.3664780991485, max_iter=261, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=3.08992121928131, max_iter=2790, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=59.406801363778335, max_iter=602, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=59.406801363778335, max_iter=602, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=59.406801363778335, max_iter=602, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=59.406801363778335, max_iter=602, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=59.406801363778335, max_iter=602, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.011182697629026503, max_iter=4588, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.011182697629026503, max_iter=4588, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.0009477714836650369, max_iter=3402, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0009477714836650369, max_iter=3402, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0009477714836650369, max_iter=3402, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0009477714836650369, max_iter=3402, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0009477714836650369, max_iter=3402, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0007593034903208885, max_iter=1406, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0007593034903208885, max_iter=1406, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.0007593034903208885, max_iter=1406, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=1597.1454085256732, max_iter=4190, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.051551146491965065, max_iter=3270, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.051551146491965065, max_iter=3270, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.051551146491965065, max_iter=3270, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.051551146491965065, max_iter=3270, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.051551146491965065, max_iter=3270, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=64.21632248858042, max_iter=1254, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=64.21632248858042, max_iter=1254, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=64.21632248858042, max_iter=1254, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=64.21632248858042, max_iter=1254, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=64.21632248858042, max_iter=1254, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END C=173.38214313606568, max_iter=4091, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=173.38214313606568, max_iter=4091, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=173.38214313606568, max_iter=4091, penalty=None, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=173.38214313606568, max_iter=4091, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=173.38214313606568, max_iter=4091, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=3.767329390130771, max_iter=3220, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=3.767329390130771, max_iter=3220, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=3.767329390130771, max_iter=3220, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.01723783559661766, max_iter=2665, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=sqrt, min_samples_leaf=7, min_samples_split=12, n_estimators=658; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=613; total time=   3.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=15, min_samples_split=13, n_estimators=766; total time=   3.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=17, min_samples_split=5, n_estimators=761; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=17, min_samples_split=5, n_estimators=761; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=5, n_estimators=1021; total time=   2.2s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=9, max_features=log2, min_samples_leaf=13, min_samples_split=10, n_estimators=356; total time=   1.0s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=7, min_samples_split=10, n_estimators=543; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=618; total time=   1.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=17, n_estimators=702; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=13, n_estimators=1071; total time=   2.8s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=14, min_samples_split=8, n_estimators=994; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=948; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=14, max_features=None, min_samples_leaf=7, min_samples_split=2, n_estimators=584; total time=   3.7s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1018; total time=   2.3s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=17, min_samples_split=18, n_estimators=641; total time=   1.3s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=935; total time=   1.4s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=13, n_estimators=929; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=6, min_samples_split=12, n_estimators=710; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=8, max_features=log2, min_samples_leaf=6, min_samples_split=12, n_estimators=710; total time=   1.4s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=None, min_samples_leaf=6, min_samples_split=17, n_estimators=548; total time=   3.4s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=1019; total time=   3.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=4, n_estimators=462; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=503; total time=   1.3s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=9, max_features=None, min_samples_leaf=9, min_samples_split=10, n_estimators=298; total time=   1.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=709; total time=   1.8s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=sqrt, min_samples_leaf=9, min_samples_split=5, n_estimators=360; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=429; total time=   0.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=7, max_features=log2, min_samples_leaf=14, min_samples_split=7, n_estimators=429; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=483; total time=   2.3s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=483; total time=   2.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=327; total time=   1.0s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=9, n_estimators=885; total time=   6.7s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=19, n_estimators=1120; total time=   7.1s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=10, max_features=None, min_samples_leaf=17, min_samples_split=11, n_estimators=1037; total time=   5.5s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=8, max_features=log2, min_samples_leaf=13, min_samples_split=16, n_estimators=1066; total time=   1.8s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=14, max_features=None, min_samples_leaf=5, min_samples_split=10, n_estimators=1107; total time=   5.6s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1084; total time=   2.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=8, max_features=sqrt, min_samples_leaf=12, min_samples_split=17, n_estimators=417; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=957; total time=   2.2s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=6, max_features=sqrt, min_samples_leaf=12, min_samples_split=19, n_estimators=874; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=19, min_samples_split=12, n_estimators=812; total time=   1.2s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=sqrt, min_samples_leaf=10, min_samples_split=3, n_estimators=314; total time=   0.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=9, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1068; total time=   2.0s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=12, max_features=None, min_samples_leaf=5, min_samples_split=13, n_estimators=568; total time=   2.6s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=997; total time=   2.1s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=8, max_features=sqrt, min_samples_leaf=13, min_samples_split=18, n_estimators=811; total time=   1.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=8, max_features=None, min_samples_leaf=15, min_samples_split=17, n_estimators=1084; total time=   5.6s\n",
      "[CV] END bootstrap=True, class_weight=None, max_depth=13, max_features=None, min_samples_leaf=4, min_samples_split=17, n_estimators=768; total time=   3.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=18, n_estimators=452; total time=   0.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=14, max_features=log2, min_samples_leaf=12, min_samples_split=18, n_estimators=452; total time=   0.9s\n",
      "[CV] END bootstrap=False, class_weight=None, max_depth=12, max_features=log2, min_samples_leaf=9, min_samples_split=19, n_estimators=994; total time=   2.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=7, n_estimators=538; total time=   1.2s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=14, n_estimators=852; total time=   4.8s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=13, min_samples_split=16, n_estimators=348; total time=   1.7s\n",
      "[CV] END bootstrap=True, class_weight=balanced_subsample, max_depth=14, max_features=sqrt, min_samples_leaf=13, min_samples_split=16, n_estimators=348; total time=   1.1s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=9, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=426; total time=   2.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=18, n_estimators=725; total time=   2.5s\n",
      "[CV] END bootstrap=False, class_weight=balanced_subsample, max_depth=12, max_features=log2, min_samples_leaf=18, min_samples_split=6, n_estimators=240; total time=   0.5s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=6, min_samples_split=19, n_estimators=1082; total time=   1.9s\n",
      "[CV] END bootstrap=True, class_weight=balanced, max_depth=7, max_features=sqrt, min_samples_leaf=6, min_samples_split=19, n_estimators=1082; total time=   1.9s\n",
      "[CV] END bootstrap=False, class_weight=balanced, max_depth=13, max_features=log2, min_samples_leaf=10, min_samples_split=19, n_estimators=450; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.4370861069626263, gamma=0.9507143064099162, learning_rate=0.37599697090570255, max_depth=7, min_child_weight=5, n_estimators=664, scale_pos_weight=3, subsample=0.18997742423620262; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.29110519961044856, gamma=0.18182496720710062, learning_rate=0.1017022549267169, max_depth=6, min_child_weight=2, n_estimators=71, scale_pos_weight=9, subsample=0.36210622617823773; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.29110519961044856, gamma=0.18182496720710062, learning_rate=0.1017022549267169, max_depth=6, min_child_weight=2, n_estimators=71, scale_pos_weight=9, subsample=0.36210622617823773; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6506676052501416, gamma=0.13949386065204183, learning_rate=0.15607232426760909, max_depth=9, min_child_weight=3, n_estimators=925, scale_pos_weight=7, subsample=0.9849077972261093; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.827557613304815, gamma=0.3046137691733707, learning_rate=0.05883605700319194, max_depth=6, min_child_weight=4, n_estimators=416, scale_pos_weight=7, subsample=0.6489969920043588; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6280760490974634, gamma=0.965255307264138, learning_rate=0.31351712384334235, max_depth=7, min_child_weight=1, n_estimators=206, scale_pos_weight=1, subsample=0.11407276606707455; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importan...\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34ea44210>,\n",
       "                                        'scale_pos_weight': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34ebbe450>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x34ea89c50>},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method='predict'),\n",
       "                   verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importan...\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34ea44210&gt;,\n",
       "                                        &#x27;scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34ebbe450&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x34ea89c50&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importan...\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34ea44210&gt;,\n",
       "                                        &#x27;scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x34ebbe450&gt;,\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x34ea89c50&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.14633087612499043, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.27864646423661144,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.46413294298332686,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=102, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.14633087612499043, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.27864646423661144,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.46413294298332686,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=102, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Best Parameters and Best Score",
   "id": "aabbb72d1b6a56a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:26.851125Z",
     "start_time": "2024-11-10T22:58:26.801332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Parameters: \", xgb_random_search.best_params_)\n",
    "print(\"Best Score: \", xgb_random_search.best_score_)"
   ],
   "id": "dcd8287cdb3e1a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'colsample_bytree': 0.14633087612499043, 'gamma': 0.27864646423661144, 'learning_rate': 0.46413294298332686, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 102, 'scale_pos_weight': 6, 'subsample': 0.3178497443603504}\n",
      "Best Score:  0.285212016665505\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:26.886101Z",
     "start_time": "2024-11-10T22:58:26.857125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model with the best hyperparameters\n",
    "y_pred_xgb_hyper = xgb_random_search.predict(X_test_top)"
   ],
   "id": "86df415a4daf3016",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classification Report",
   "id": "29d585ba54893191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:26.996455Z",
     "start_time": "2024-11-10T22:58:26.965915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_xgb_hyper))"
   ],
   "id": "ba3cb5ff9b12feca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1167\n",
      "           1       0.17      0.38      0.24       112\n",
      "\n",
      "    accuracy                           0.78      1279\n",
      "   macro avg       0.55      0.60      0.55      1279\n",
      "weighted avg       0.87      0.78      0.82      1279\n",
      "\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "5f183b0329632921"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:27.097284Z",
     "start_time": "2024-11-10T22:58:27.014421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
    "predictions_base = [y_pred_lr, y_pred_rf, y_pred_xgb]\n",
    "predictions_hyper = [y_pred_lr_hyper, y_pred_rf_hyper, y_pred_xgb_hyper]\n",
    "\n",
    "results = utils.evaluate_models(models=models, predictions_base=predictions_base, predictions_hyper=predictions_hyper,\n",
    "                                X=X_test_top, y_test=y_test)\n",
    "results"
   ],
   "id": "b46f81581d06e64c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         Logistic Regression Random Forest  \\\n",
       "Metric             Type                                                      \n",
       "Accuracy           Base                             0.912432      0.899922   \n",
       "Precision          Base                                  0.5      0.214286   \n",
       "Recall             Base                             0.026786      0.053571   \n",
       "F1 Score           Base                             0.050847      0.085714   \n",
       "Positive Precision Base                                  0.5      0.214286   \n",
       "Negative Precision Base                             0.914375      0.915268   \n",
       "Positive Recall    Base                             0.026786      0.053571   \n",
       "Negative Recall    Base                             0.997429      0.981148   \n",
       "Positive F1 Score  Base                             0.050847      0.085714   \n",
       "Negative F1 Score  Base                             0.954098      0.947064   \n",
       "Accuracy           Hyperparameter Tuning             0.91165      0.726349   \n",
       "Precision          Hyperparameter Tuning            0.428571      0.143713   \n",
       "Recall             Hyperparameter Tuning            0.026786      0.428571   \n",
       "F1 Score           Hyperparameter Tuning             0.05042      0.215247   \n",
       "Positive Precision Hyperparameter Tuning            0.428571      0.143713   \n",
       "Negative Precision Hyperparameter Tuning            0.914308      0.932275   \n",
       "Positive Recall    Hyperparameter Tuning            0.026786      0.428571   \n",
       "Negative Recall    Hyperparameter Tuning            0.996572      0.754927   \n",
       "Positive F1 Score  Hyperparameter Tuning             0.05042      0.215247   \n",
       "Negative F1 Score  Hyperparameter Tuning             0.95367       0.83428   \n",
       "\n",
       "                                           XGBoost           Best Model  \\\n",
       "Metric             Type                                                   \n",
       "Accuracy           Base                   0.899922  Logistic Regression   \n",
       "Precision          Base                       0.25  Logistic Regression   \n",
       "Recall             Base                   0.071429        Random Forest   \n",
       "F1 Score           Base                   0.111111              XGBoost   \n",
       "Positive Precision Base                       0.25  Logistic Regression   \n",
       "Negative Precision Base                     0.9166              XGBoost   \n",
       "Positive Recall    Base                   0.071429        Random Forest   \n",
       "Negative Recall    Base                   0.979434  Logistic Regression   \n",
       "Positive F1 Score  Base                   0.111111              XGBoost   \n",
       "Negative F1 Score  Base                   0.946976  Logistic Regression   \n",
       "Accuracy           Hyperparameter Tuning  0.781861  Logistic Regression   \n",
       "Precision          Hyperparameter Tuning   0.16996  Logistic Regression   \n",
       "Recall             Hyperparameter Tuning  0.383929        Random Forest   \n",
       "F1 Score           Hyperparameter Tuning  0.235616              XGBoost   \n",
       "Positive Precision Hyperparameter Tuning   0.16996  Logistic Regression   \n",
       "Negative Precision Hyperparameter Tuning  0.932749              XGBoost   \n",
       "Positive Recall    Hyperparameter Tuning  0.383929        Random Forest   \n",
       "Negative Recall    Hyperparameter Tuning  0.820051  Logistic Regression   \n",
       "Positive F1 Score  Hyperparameter Tuning  0.235616              XGBoost   \n",
       "Negative F1 Score  Hyperparameter Tuning  0.872777  Logistic Regression   \n",
       "\n",
       "                                          Best Value  \n",
       "Metric             Type                               \n",
       "Accuracy           Base                     0.912432  \n",
       "Precision          Base                     0.500000  \n",
       "Recall             Base                     0.428571  \n",
       "F1 Score           Base                     0.235616  \n",
       "Positive Precision Base                     0.500000  \n",
       "Negative Precision Base                     0.932749  \n",
       "Positive Recall    Base                     0.428571  \n",
       "Negative Recall    Base                     0.997429  \n",
       "Positive F1 Score  Base                     0.235616  \n",
       "Negative F1 Score  Base                     0.954098  \n",
       "Accuracy           Hyperparameter Tuning    0.912432  \n",
       "Precision          Hyperparameter Tuning    0.500000  \n",
       "Recall             Hyperparameter Tuning    0.428571  \n",
       "F1 Score           Hyperparameter Tuning    0.235616  \n",
       "Positive Precision Hyperparameter Tuning    0.500000  \n",
       "Negative Precision Hyperparameter Tuning    0.932749  \n",
       "Positive Recall    Hyperparameter Tuning    0.428571  \n",
       "Negative Recall    Hyperparameter Tuning    0.997429  \n",
       "Positive F1 Score  Hyperparameter Tuning    0.235616  \n",
       "Negative F1 Score  Hyperparameter Tuning    0.954098  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Best Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.912432</td>\n",
       "      <td>0.899922</td>\n",
       "      <td>0.899922</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.912432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Precision</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.915268</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.932749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Recall</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.997429</td>\n",
       "      <td>0.981148</td>\n",
       "      <td>0.979434</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.997429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive F1 Score</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative F1 Score</th>\n",
       "      <th>Base</th>\n",
       "      <td>0.954098</td>\n",
       "      <td>0.947064</td>\n",
       "      <td>0.946976</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.954098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.91165</td>\n",
       "      <td>0.726349</td>\n",
       "      <td>0.781861</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.912432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.16996</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.05042</td>\n",
       "      <td>0.215247</td>\n",
       "      <td>0.235616</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.16996</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Precision</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.914308</td>\n",
       "      <td>0.932275</td>\n",
       "      <td>0.932749</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.932749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Recall</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.996572</td>\n",
       "      <td>0.754927</td>\n",
       "      <td>0.820051</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.997429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive F1 Score</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.05042</td>\n",
       "      <td>0.215247</td>\n",
       "      <td>0.235616</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative F1 Score</th>\n",
       "      <th>Hyperparameter Tuning</th>\n",
       "      <td>0.95367</td>\n",
       "      <td>0.83428</td>\n",
       "      <td>0.872777</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.954098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:58:27.155199Z",
     "start_time": "2024-11-10T22:58:27.152875Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f6ea090536c8de8e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
